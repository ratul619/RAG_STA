{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratul619/RAG_STA/blob/main/RAG_STA_reports_codellama1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0QCOTLkdZZ3",
        "outputId": "313ee2df-729a-48f6-fa5d-2b7ca3e87b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.56.2\n",
            "Uninstalling transformers-4.56.2:\n",
            "  Successfully uninstalled transformers-4.56.2\n",
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: accelerate 1.10.1\n",
            "Uninstalling accelerate-1.10.1:\n",
            "  Successfully uninstalled accelerate-1.10.1\n",
            "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: sentence-transformers 5.1.1\n",
            "Uninstalling sentence-transformers-5.1.1:\n",
            "  Successfully uninstalled sentence-transformers-5.1.1\n",
            "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.0 (from versions: 2.2.0+cu118, 2.2.1+cu118, 2.2.2+cu118, 2.3.0+cu118, 2.3.1+cu118, 2.4.0+cu118, 2.4.1+cu118, 2.5.0+cu118, 2.5.1+cu118, 2.6.0+cu118, 2.7.0+cu118, 2.7.1+cu118)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting transformers==4.35.0\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.1/123.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (2.32.4)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.35.0)\n",
            "  Downloading tokenizers-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (1.1.10)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.35.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.35.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.35.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.35.0) (2025.8.3)\n",
            "Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.35.3\n",
            "    Uninstalling huggingface-hub-0.35.3:\n",
            "      Successfully uninstalled huggingface-hub-0.35.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.17.1 requires accelerate>=0.21.0, which is not installed.\n",
            "peft 0.17.1 requires torch>=1.13.0, which is not installed.\n",
            "timm 1.0.20 requires torch, which is not installed.\n",
            "timm 1.0.20 requires torchvision, which is not installed.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "gradio-client 1.13.3 requires huggingface-hub<2.0,>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "gradio 5.47.2 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "diffusers 0.35.1 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.17.3 tokenizers-0.14.1 transformers-4.35.0\n",
            "Collecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (4.35.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
            "Collecting torch>=1.6.0 (from sentence-transformers==2.2.2)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision (from sentence-transformers==2.2.2)\n",
            "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (1.16.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (0.2.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.19.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.32.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.27.3)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->sentence-transformers==2.2.2) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->sentence-transformers==2.2.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->sentence-transformers==2.2.2) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.8.3)\n",
            "Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m153.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=d8b641b05d27cd81a7f6ee029e24f6f077c4e55d57a75947c9e0893d2ffe42e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/3b/21/aa025e9c81a6cda4b8358756a756677b0969b4bc69be6dd5da\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, torchvision, sentence-transformers\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.17.1 requires accelerate>=0.21.0, which is not installed.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sentence-transformers-2.2.2 torch-2.8.0 torchvision-0.23.0\n",
            "Collecting accelerate==0.24.0\n",
            "  Downloading accelerate-0.24.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.24.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.24.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.24.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.24.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.24.0) (2.8.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate==0.24.0) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.24.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.24.0) (4.67.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.24.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.24.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.24.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.24.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.24.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.24.0) (2025.8.3)\n",
            "Downloading accelerate-0.24.0-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.24.0\n",
            "Collecting bitsandbytes==0.41.0\n",
            "  Downloading bitsandbytes-0.41.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Downloading bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.0\n",
            "Collecting chromadb==0.4.15\n",
            "  Downloading chromadb-0.4.15-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (2.32.4)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (2.11.9)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb==0.4.15)\n",
            "  Downloading chroma-hnswlib-0.7.3.tar.gz (31 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (0.118.0)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.37.0)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.4.15)\n",
            "  Downloading posthog-6.7.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (4.15.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb==0.4.15)\n",
            "  Downloading pulsar_client-3.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.4.15)\n",
            "  Downloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.4.15)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (0.14.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb==0.4.15)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==0.4.15)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (0.19.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb==0.4.15)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (8.5.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb==0.4.15) (2.0.2)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.95.2->chromadb==0.4.15) (0.48.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (6.0.3)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb==0.4.15)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.4.15)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.15)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (25.9.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb==0.4.15) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.4.15)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog>=2.4.0->chromadb==0.4.15) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==0.4.15) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==0.4.15) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==0.4.15) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28->chromadb==0.4.15) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28->chromadb==0.4.15) (3.10)\n",
            "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb==0.4.15) (0.17.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==0.4.15) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==0.4.15) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==0.4.15) (13.9.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.16.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.4.15)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb==0.4.15)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.15)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.15) (3.19.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.15) (2025.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.15) (3.23.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (2.19.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.15) (4.11.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.15)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==0.4.15) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.15) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.15) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.6.1)\n",
            "Downloading chromadb-0.4.15-py3-none-any.whl (479 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.8/479.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading posthog-6.7.6-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulsar_client-3.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: chroma-hnswlib, pypika\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.3-cp312-cp312-linux_x86_64.whl size=2530625 sha256=75317ee1e20c2d53422e3104e957d57bfb78466eb61f53864025aa148980c26b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/14/b5/68c4f2e056600c0348a94efba92dc975686ab72b714e0ca3d6\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=08e8c3d53ace095c61d0797a7c1d4186dc9c81b941217e9a09263639ec84640f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built chroma-hnswlib pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pulsar-client, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, watchfiles, coloredlogs, posthog, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "Successfully installed backoff-2.2.1 bcrypt-5.0.0 chroma-hnswlib-0.7.3 chromadb-0.4.15 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-34.1.0 onnxruntime-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 posthog-6.7.6 pulsar-client-3.8.0 pypika-0.48.9 urllib3-2.3.0 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Requirement already satisfied: huggingface-hub==0.17.3 in /usr/local/lib/python3.12/dist-packages (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.17.3) (3.19.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.17.3) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.17.3) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.17.3) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.17.3) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.17.3) (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.17.3) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.17.3) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.17.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.17.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.17.3) (2025.8.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.14.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement safetensor (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for safetensor\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Clean installation for Google Colab - Run this FIRST\n",
        "!pip uninstall -y transformers torch torchvision accelerate bitsandbytes sentence-transformers\n",
        "!pip cache purge\n",
        "\n",
        "# Install compatible versions in correct order\n",
        "!pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers==4.35.0\n",
        "!pip install sentence-transformers==2.2.2\n",
        "!pip install accelerate==0.24.0\n",
        "!pip install bitsandbytes==0.41.0\n",
        "!pip install chromadb==0.4.15\n",
        "!pip install huggingface-hub==0.17.3\n",
        "!pip install numpy scipy tokenizers safetensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCw1xGLZe10h",
        "outputId": "f319b9e0-dc82-42f5-d327-605feec77abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ PyTorch: 2.8.0+cu128\n",
            "✅ CUDA available: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Transformers: 4.35.0\n",
            "✅ SentenceTransformers: Import successful\n",
            "✅ AutoTokenizer & AutoModelForCausalLM: Import successful\n",
            "✅ ChromaDB: Import successful\n",
            "\n",
            "🎉 All imports successful! Ready to run your code.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"✅ PyTorch: {torch.__version__}\")\n",
        "print(f\"✅ CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "import transformers\n",
        "print(f\"✅ Transformers: {transformers.__version__}\")\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "print(\"✅ SentenceTransformers: Import successful\")\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "print(\"✅ AutoTokenizer & AutoModelForCausalLM: Import successful\")\n",
        "\n",
        "import chromadb\n",
        "print(\"✅ ChromaDB: Import successful\")\n",
        "\n",
        "print(\"\\n🎉 All imports successful! Ready to run your code.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_PFSvOpfOul",
        "outputId": "119e59b0-86e2-4350-9830-a051a3bc809f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "\n",
        "print(\"✅ All imports successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "733083c1342549a19e60ee170c848063",
            "006983e2283348df8decc3b245098a9e",
            "d1c8aad90ab74af49d39c089c7499977",
            "75e44fa8152b4cad85b3543db7f8f33d",
            "45709e3fa69e4eff8dc4b4ce328eb0f5",
            "751a1b476d92462ba349eb90ab9c53e5",
            "0385d6b82b2b4c1aac4a92b2a8834470",
            "6f52d48c620c4b4fa7632a76d59bd411",
            "12c7ae7fce274d63a2121fbf40685c37",
            "500efb5040ac44a8bc693d96b86bbf18",
            "825f7300f39645ae9625a7308b41cb2b",
            "e03ef2f0c4ee4ea58225df77c9773065",
            "5e3ce944d0ec4d37baaa70149be71723",
            "d18ffd1a9cc74d25b07ecc02912c5bcf",
            "6c782cfaeb7441a8b82df67121dc0cab",
            "a9466d9f27734435918899f945dc1658",
            "60ee58c81cce4063af823f0c60eb157b",
            "40df0f841c374dc6af8494de498facb5",
            "18d40c303db54b4581293bcaff35271e",
            "afa02c3f82ad487d956662b9c9ac2094",
            "c2bf393d922343f084f0d2f57da366e4",
            "18efd71d5a7d4f4eae357a41cc1b6812",
            "041255dc0b4e4ea78f937dbab0f0072c",
            "7abb3c1c74ef4f0eb9447fcca47d5078",
            "510ef88b22de435e8c85d902994b8ae2",
            "2e03480b9b2841dd9aa1c2c747a10f00",
            "f80638e09b3a4e41b1c5bf558c6b84be",
            "ba09e40088314f3895ed5d987dab0fc0",
            "17ec9fba5f5548378f3f7bf1277a970b",
            "5509931c51f14f8ab5b523689f5c5363",
            "e8798fa091b54836b21c699de2b94caa",
            "62986736155646c98fd12512da90c59e",
            "f71de2b3646f430387d83ad4acd926fb",
            "01d5853bde6343579d878baed31869c0",
            "b9da3a46b747406a9e91f127048b5f7f",
            "8f766e1c1b9f4c558bb3320f4401ce35",
            "1a728dc0f25c4511a2afeff1cd46b580",
            "d1203b7cf74a4fc7a06be100424cc85e",
            "6a0b2edf2e2840959b709f6c4d3497da",
            "78d37f7e23e7487ea1dcee7182f16b1e",
            "686545a18256476f97e73cf2f6f278c9",
            "ab07433386d54fe2a740aac852347aab",
            "01466d495dfd444d9706a86429cb8b45",
            "2376d77a8e754d188e18421e36c403b2",
            "4e5e1a83f0164a86895b0bd45f974103",
            "052b04b5535a4115aaf828ffdf048080",
            "45ea6401b49f481aad71b5eaa7edfe73",
            "eb6a8b7f7ea2414a9702698b5d952757",
            "7f3bcfda0c9846df868fcd2eee7b756d",
            "f27ad9ae80b6471383524788bf0e8eef",
            "2e47d74ea4bc429984e78c3f25b975c4",
            "fde3235287d542ccaf3088af8bf78950",
            "12a0c8ca12a84e6995c247429d92cfb3",
            "94146c327cce471b867c01e6607528a2",
            "31f2a77ace8b4b2c9e4172e5553b1963",
            "783ae4f8af6a4ebc99d91febccf795d7",
            "343c252921964b04a7a4c5d526e8f738",
            "5c0832fab25e45c6859ea0806d868295",
            "95beaed903974f8cabbce873782adc39",
            "815a3d71498744398f5ca7e1449c0f23",
            "f3bbd5fdaf134ff2b927638250d380f9",
            "192a5bbe114b409f90d957da37eb66ba",
            "56447bf0c5ef4b228d47e5f36b3bf203",
            "40e3ab9e0351401e980691bfb49176bd",
            "475bd4a079a84878a0b43accedf931e9",
            "e6fb8361ff5d401bb49d449872742502",
            "e37484d541a9469baba662016dbebb76",
            "2c15ee18da4f46129a5831d7780273e2",
            "58ec4a45101c49e4b8080f5402c0e96d",
            "f3ae4f551c6a4d0db867741ce9974a5e",
            "002e895d943f4b84a4c7e9d94cb41932",
            "21a5744f19ec4930ae437cfff54ee607",
            "3593ecc1b0164833a6ef558459153a3b",
            "699e546383b349a3af744724c3ff89c7",
            "5ba4622a8f20464dae44bb332e7c0c82",
            "8614c733d1084fb5a9930834f7aa2ba2",
            "0ee279a8b0ff469da74a9f3ab3f51a6e",
            "d481955f95a44e608caea9be11110255",
            "fb1728c560894de48f9825c6e014c0d8",
            "b83a74572a58445f9c815e0894a82490",
            "0d744344f71f4cb6868bf77a6d68d546",
            "8345f09d1ca641f5b79ce585ee7e82ea",
            "dd3d50a45047459cb65302a8d04887fd",
            "253d80ccde82413abee06a8b90297089",
            "7959d64ee02843ae9f6a56daf8499c2b",
            "047b47e9c6b442ec821b6efbacc2b4b0",
            "89443b41d5db4be18d9e8850c65ba8ac",
            "53bd848993b84529862f194e2dc8a3f3",
            "1d513ed6fc454ad4954314f1ca43541b",
            "0aeb175563f14d4a8dbcefa61ca9f907",
            "4a91c572d4764158a2310617cf754117",
            "291f9367670e4567b770e5274cdd64e6",
            "a940e7d641354a1d95547634156ba97a",
            "f9924518b6c643408a9159985440101e",
            "04900d40e885491e8e3444a1df83b71f",
            "a6fc803b91b64208b71a91acad0d12d6",
            "e99d9f2d829f4777966be8355c5e8296",
            "11f465108f3345a7b9665df5a8665b3c",
            "5d25bb0fe02540aaba0df239b52828a2",
            "327eff2159a3461fbe519c4894b70ba8",
            "a2fc9d5d2a4e44c9b49d424992bab00a",
            "80a39524b9204b91ab800861a4200d55",
            "939f1df069354a649a152e43f455e496",
            "af41f782078f4bb39ec6c237fc4d5032",
            "b48e4e0514d847be8118837ad4986b23",
            "0bc24b20a2264709967772a4d5ce0690",
            "95f61a87ef87475b9cdbf54d915f03af",
            "e95e6163de9d4bd2af02f6e14140a648",
            "5dc3119051b449339ad4cb9c41de746a",
            "26adbb7f9f024c7aae2edf69f5d65501",
            "f3010c28daea47e9a3e1be7c0db0bc36",
            "ec981e5dc68d4f38ae8557461d07076e",
            "4b9c8a6cef124f5a97f6d383b0b722ab",
            "d126d69e537e42d08855da886c15fbbc",
            "cc40753724b644bebaefa73b4d8ed2c5",
            "9cca97c6ff0b4972beb76ac1e3ded196",
            "cd1729fc4c1d43de83c1333dcb05c19f",
            "5e9d63f81b8a4be0ad0f735b6c74f5fa",
            "65210dbaec354be19c1ea3665ece4428",
            "8523de1b618a4361ac5572df545f3c4b",
            "ad6f385ca6dc4c5a89036099202a43ed",
            "18eb640ba3614cf6b50a64162f984e91",
            "1a10e9c9989c4299bd6ab8e1ada121f2",
            "26ee7303465b48ab9ed988f7fb9154ea",
            "1d0b1ef3317b4ce6b033f1264ce4eaa9",
            "65f1c762bf004a24a5190a8f927a08b9",
            "7529a697abaf47a1a051d16fff23c43f",
            "f2a5c5dc07474abcbdac1d451f27ef85",
            "c403e92163824be797b2f48fef526a56",
            "808d5aab68054d74945a08abe54048ca",
            "f69e6f06ff1c4bbcb4909b33b7558a11",
            "3304bbfcb2054ea0bee2f98cc4ede818",
            "1d82f01287ef407d9e5ffad183dd4c50",
            "cdb2831ffedb4e10bdedc76e8ba790fd",
            "f93f7ba8f13c45ea86aaaa612af608c7",
            "c389fa85327b46ec90be8e750a9299df",
            "b9b6c6422b8d4fe684276a1c795241da",
            "725d5238593f4566bbf69d07f722a16e",
            "acb16da33e37436aa0558edd1773dc89",
            "6cf11fc63374447ca783b50233eec628",
            "55ed30864aff43249eb5f91861c4ec09",
            "f639c230d94740fc8ee1d6f3d08622c0",
            "e3f84880e2bf4501bea6e5f85a9f81cd",
            "b24ccff458944c769f3068df383802f7",
            "9d4098470dc04fe08c00bcbb057ee3bb",
            "e20bfe354e8c44578ddeb47bd7437b15",
            "7478600a44b9414e96bda1390664a8e1",
            "52a0b3b4fa38441296fc2552d6edce3b",
            "a1007687649a4dd5936de6da9ef79ec2",
            "ed37bfc8a4e64ea296ba8801ae0a2265",
            "7d4939a31c62489bb2e8f4111c101ae0",
            "1e20b9f3b0584a16a803e9be32fba740",
            "5c94a1a4a0254e38856ed973cce006ef",
            "a66ffd0b33ac4a86bdf7e854268ac420",
            "663bf456c10240ec8f8a620a95a3f653",
            "b72645b813ec4583adb4ee27e99a64de",
            "ee66aee457a94df09f79c82aad410448",
            "4b9589fb650946b7bd5fb0820e7c81a5",
            "81875e1af14347ecb19b8fd2a33bb885",
            "e9f0f1ae6e4b4d4d94e91051b1c0ff3a",
            "b5c4cf63366f42598e081be20a62bf4f",
            "324518d0142b439db303e7390345422e",
            "e878eb5c2afe4fab9f68af329e64bbad",
            "5be0cd6ca99c4d7fa85b7f5a7916e56a",
            "0264a2477a844750b3e24a4079046840",
            "e90d58d8bd694acf840a4bef39d8f409",
            "8e74a7d3fc8340d787d18341c7a0f6e8",
            "069c3f345da6404b9b89a58c7ebef338",
            "f18480a919f3499d8d757676e1c92f34",
            "de2f9f2cc0d149caa7063f4764ecf41d",
            "816be69662324de78e47781ffef30821",
            "fa3d4b8ebdef4d38aad4807306fb0d6a",
            "48bd0028bff84db6997ba523ea31f98f",
            "d22f23e2f874440ebd266a28202a945a",
            "0e9f9f10a8f74d7a8189db04779f3252",
            "b32709ad61b546ea973c61f877eec282",
            "0473f6921b124d278367031b4e6cccc6",
            "7d08c4ab70a94ddeaad6e541ea07d696",
            "1eca1f63b6774c709dcb9c086753100a",
            "2d26e686c23443c7902d933724cbd1fd",
            "4b663baf84c7423c8fa80355c7a432d3",
            "4abd00291eb9450dbddc550b4cf9879d",
            "3b1fdc1ddfad4f7c98eeb409171ccafd",
            "c0b641a653ff4a05931049e62eac9ff2",
            "8f9f6ed6063242a58cdfff65eda11f4d",
            "e26cc6e079ee402194a659075b5b44ca",
            "68480c61aed4496e8e0e047cae92a41e",
            "8a435c6552424d4cb418dc20ffc6a60d",
            "71807425abee499aac63e56fb74e8b4a",
            "925692e4a0f8448f891d7e76e4bd4d19",
            "62a92922ad8e4f1d838dbcf9599c9af7",
            "d75b71fc416d4b14bf881ec2ea2f6625",
            "d7edf2f104b84e17bfdb5453e8e18373",
            "70899f30168944829be0a6b95ba3961c",
            "9f0d6105c31d495a8920f17ae56140fd",
            "6e8a7c3db7da40a1be5dae34983d978a",
            "f3a3bb0e97594c74b5e6955f5a733fda",
            "b65a6cae7f924a9e9e49b76a62156472",
            "2340343870bb4f0da76a76e29b67fbff",
            "71bc66c81de34f1f920d1eab33c69f26",
            "9afe8bec4a2348868a64ab35a0406964",
            "70669f0858dc4608a04065ef73929dcd",
            "1b4a92f0da954c00b736be771e93e4c1",
            "f210aafa99964807aac81d5c48834022",
            "226efa4f5e014c73932d30403ddf3280",
            "b562496342a242dba17bd5466500db01",
            "d4394b606971409c8b7776feb3a3d311",
            "af13e5851d1d40a3a8d757fcb6558de8",
            "d08cc25135004577b893153308d46b59",
            "960be35de43b46e7a3dd4b564d404515",
            "3a0c0dc86aa14b4eb07586f6fa6c3b7c",
            "7c355b31995b47728b967637688d8ae6",
            "e9fb77a2f2364045b89c39d25314210a",
            "b7661b91ca9c4bdebf3e162d8ff82056",
            "7153d871d7584e8abab2e7fd3e9c818b",
            "11bd65590b784e6283d4520b63e2bd30",
            "9c45555a7cf047e887dfb74321b3a00e",
            "df3d02f826914a1ab61fc790de19a26c",
            "cdd34f895bc94b37b50e7869a0db0e21",
            "ec8516ddabe345dba6cfd280ee36e7cb",
            "cb12941792314e729e8473a8d1242760",
            "2cf0cc7e92e04fe49d13d36a323621f1",
            "787dde1d41714e559ef9e3788213347c",
            "3a26af61f2914c19ba4e9b39b94520b4",
            "73853d4b10334969baad4b5e8c86fec7",
            "962d8adef08244d8a7c2f8af9b111c39",
            "80860bf6bd6045109e03dbd3e329213a",
            "0c0fc3712d7b48848253cb48d48c87f0",
            "59b9bf579011464199b811f70bbb4338",
            "2869177037834e518078a39793148059",
            "4ce80f79104d412694fbd53bae4bf2ba",
            "4e461638844c4a6a8fa8d24d8b084afb",
            "1d07ccacbe554f88b21a41804c912c46",
            "2e487339d6be445cb0c698473ced7153",
            "4e86e5407f9444f09c728c3de6daf5c4",
            "19e3410076f74098bf8e012eab7b4297",
            "22a1143956f74e038fa4998be28a337e",
            "91cb931cf6444caea93b732391e470b6",
            "e91a22164c9849fda3a5c801f87ed172",
            "90c6c4a43903460db8d8309b84945f1a",
            "061698bfe5c143399227c68e1ea78bad",
            "89ba5b0e3dc64efb84e74d5031963c9b",
            "9879bb312a8f473db6a2c3d0f7b7d591",
            "e92ae0b68b1f4793abe203769cbd212b",
            "1038f092afe74b6caee07ff39dda54ed",
            "909c3d22969b4f30bd55a7091f01a602",
            "84ddfd7f0a89497c9ffea2dcd75f30f7",
            "fd50e03c6f9c4130a7a28e7f7a6189c5",
            "02d83a14e1974a02933b6fb84b8fee10",
            "7e1b969e780c47d2b263aec4479da1a9",
            "359f0f86786d4c66961924a25772a28e",
            "87b405bd85094656aa2509c03f4f5d19",
            "53f0b82f1eec484886c1236f1b56cb25",
            "cfb38ae65a0b4812941886d70ec0f7fb",
            "d0b4ac5597534572922a387927e9013f",
            "ffd2c837561443868a86d81432f9390f",
            "f6a1bd4ce3bf476cb136470450790323",
            "792321100b9b417298c848279cfd45e4",
            "3d5ff2dde3ea47c4b0048cb5c12f0747",
            "e8a7af47229d41f685887d9f52ff18cb",
            "50af68f3ea14412e96fbb59d9a565156",
            "b9fc753799c541f2b36b8a3ca199d8ff",
            "19c13990e4e94a5e811d33d23083bec8",
            "1e1c2210876045f9a157535f430e77a8",
            "224e3ef13e004f20b28e8b8067c97a35",
            "8d6124651d574631969bfa4ed2475fc4",
            "a41d777292a04015a59ba3688a49ed1c",
            "842f7ad81b4b4d34a468ec2c7bc593af",
            "b71eed38b31d42c1b79ff91be5038218",
            "6512af48d90248aea0820c0fceacb80f",
            "a0c42cc8c8c54039ba0c0db575ba2ba7",
            "4f495fcb342049f6a9cf3ddee0ca5f1e",
            "1e9a447b6137474089e934a2fa8b8c4e",
            "aa1b85075c1842b0ad5242383b6f6304",
            "5686639b6e994b14bf6170a20e279c89",
            "860ddec7a510474d99552521faa297cc",
            "2cab78e64c294f3b99946d9cd380d9df",
            "afdc7c5dc95b4b1a9b2135154ea9f9db",
            "6bf3f434fc244f6289eaa3c79ad7a491",
            "92e7960c3fc44fc98c31cdb2a7dbf857",
            "42a5b9499eee4e1aaf7619ccc369dfa7",
            "53f133fa47c948d1b0741de6db5429c4",
            "d7544e40cdbc487fa30047c35bc3cfbb",
            "6998656c848b4e84b9a7c273e191c663",
            "eaca4be07f1f40c3a8b60f82aec16d62",
            "97c53cc6744c43beb509a434830088e4",
            "eabbc30930fa453ebdd9ab4cb0b706b1",
            "54fe6814eb7f48f591d3e1b2297a2365",
            "549bad16e2414e5393280820e9890f68",
            "6515798838c442d0a9525f933549ed9c",
            "568bf7b486d447068a50c4f990d75249",
            "505873e0410442b88ab57ef057922802",
            "681df2ca6298455cb891ffc35bfc488c",
            "e39c8fd1ba2848c3965d11e7b5716a56",
            "db2abfcec55f419ab058097ef6434bef",
            "a9258f1f32ed4d5a940950a6e697419d",
            "4d921725438f4c7fa30fd6974145aa40",
            "f18372486ac14dd0a479706c27e64a95",
            "f54235a5d9b64a1b9855c37ae5d46e95",
            "0da947241d4b48e9b87d7bc6bf1d6451",
            "a62ecd41698f45d6bda57b260c3618e8",
            "32d590a30b584e2daaf35aa41415c652",
            "834809a1a8934fb0a4a3480329f96099",
            "9543f9fbdcc34a64b177a601021d9299",
            "5500a073bdd64810b725ae1ea420bde3",
            "67b40389042849758ce4451d1d54e9d6",
            "b7f004063c69475286230dd3b6b98553",
            "89808fb12ce64361aad08870c7fb076b",
            "44ada1b1e8184ebc8a3c8db91536ff06",
            "892effe1e0c3478e8dff05214991b4d9",
            "8dfe9997b94d4ebdbdc859e12f65bb86",
            "94ba8ad711814a0c826ff2de25cc3d47",
            "26f48dc181774720b3bcc7ecaf60a6bf",
            "c54114fd45444bc28167e2b653113fcc",
            "86131aa6e8ce430194a859c8eeadfeb2",
            "a80afb8ae6ec4e4391d2e4858353494f",
            "0bba852c316b48e4b754f115badf88f6",
            "1bde08b27f184040b3de094ebb3e7f0b",
            "7fd11956c43d483480e9e4716470d295",
            "6f71cb7ff318423c8e502ae4ce300d42",
            "9b69cb2942b749bbafb27ea2fd2475c5",
            "05d0627afc6c418fb2394e9a1b6955ba",
            "b4ef449386334628b503f62c1d6004e2",
            "a3ff196882fd428380198cfdba8a64d2",
            "be2cac4b1b4e4343ad0ee0fe88fd7fe8",
            "317b1c13bb4049b6ad9cb6d43e4f5dd3",
            "d83b5420acb84b3388abd7a825582ea2",
            "0d66ea4558a848abac380f878f9f166d",
            "0484abe01641433a9a37feaf38411d06",
            "a58eae67a18c418db1593eb933234681",
            "c822ced2a2da47c185e1608029b29837",
            "8a41fa3c7f2d47b78a55f27bc28e9b77",
            "2302721590ad430db61287b394c99d34",
            "f8002cd60614482aaf5262c3b5bfd2ae",
            "aa5ecb2245ca478db0e04feeeed9adfc",
            "8ebdf6c5a99e4638a2da4026bf82c275",
            "cf432bb484cc4615bcfa631fb6cd373d",
            "f828856d2f184015b2c122a481a3a052",
            "29ca52c7a48f4616961e4a2c6ce659b9",
            "4e281b1dff5e4afc86717302642dbf31",
            "f916f359870d421bb289c16ba4942046",
            "83cafcac35354ee7be49f86e9e8fbf48",
            "9708519f08334dd2b3aba1a51df69ece",
            "1e63608ad9624f8e8fe9a4fc2d519a7a",
            "3c759dccaa1048f38ba7560418ee2f00",
            "e33bb200e8b142f0855e5dbd0c64a803",
            "e954bf7c16e043cfb611531b47a4cdd3",
            "72de281e5da04fa68e3b7cf772a1cdbf",
            "ce96546c950a491eb8be7c3bf0309f2c",
            "e1150fffe081471783c7e103e1fc2031",
            "b91f97d687244e13b1c7021ef9ff0cc3",
            "8fb303fa79834a93ad65227011bc688f",
            "a495ee526539484ebb2b85633617732a",
            "ed8219c9458b4cd6af50fbc3c4215385",
            "47ae4f9641a449a8b7efb16a0a21fe2c",
            "17a48ac52f8f4e02b7ea9ba90923f1b1",
            "e105f9523c7c4e3eab8fae7b01d3fd83",
            "178eea154f394ef992eea375ce053ccb",
            "0a291b8e2e1245119542d93090b0023b",
            "9015fab762b543bd9a28e7435ae6e977",
            "fbe5120d4dbf4b06987dc72e3be30536",
            "3b92e71d7053438fa8025d536dcbe9bc",
            "9c1d8ea4db6746d49ecbb38289c6926c",
            "11c4378530b94cbb9371cc17df5b1249",
            "627baeeed64b42c4addb3601d38fece5",
            "8cc30dcb96004b0eb49a7b0eb7254a14",
            "003f34cc29f34a3cac3c1edceb6ba31a",
            "1a3bc4e601a6411ab2f7c3988372f935",
            "dd8027cd897245818631e094e4ed8c80",
            "08b3aabd306443208f392f34142f5100",
            "86b10c735ee44eb1b74ff39c9f5937ed",
            "45d99908b9cf4297a3b49d3a623fae17",
            "8002ccb179ba4bd7a90da6054343326c",
            "0768bfe28cb542ba98f9c07e845ea348",
            "37ac8ef87bf74917bf3ab47023020c1f",
            "2a5b3c403f344fb1b33609ee093a9963",
            "95387ea88a41433b91f919e37a2beeb8",
            "c4b391e1e04e403ca092d7878eef200d",
            "c9b53c6c32494869bf41178640564d25",
            "18b8f88154a14b8e8e8001fe3861a123",
            "8bb8cb42f69e43d19b7597139e16f945",
            "063dd3c9b7154c2b86095266a52c94ac",
            "7e5943b15ac045599351aef1f1a1a47e",
            "7ae2eae1eb7e441fb55a54522b771a6c",
            "d64463f94bff419a95472d801b816e1f",
            "902f5996ab184423975c6617e939f68c",
            "ae0f5fec869148cdafe90f2c221562c6",
            "b3723a12e6554ec6ae9d3cfea1b79a83",
            "df817a5f7c8f45d2929eebec6bcf26fe",
            "0289266acd9644c5b372443d25685121",
            "ae4cedd5a6e443158289ce796083d3ad",
            "1edfac6eec2d4992b90134163f444dad",
            "a7d4fcb35ab6447685bc73f6ef67b66a",
            "77adb0ec2a9841fe990d20d4e2ad9f69",
            "f6b011f235b1414fae497d027989dde1",
            "f2f0e483c1544876a9f96cf65f6382c2",
            "0e562cea7c6f418f8516de67232492c2",
            "dac9a6d8f43643a9a57ae0408f9a9b24",
            "a1d8ff2b389b4a1f81625b679d4a6b4d",
            "9b4bb652ce13426184eb69a00f4e8787",
            "7cd89697a0234c4cbe1119b78a827517",
            "e1296780d5e1438fbe28afdbfddf7a79",
            "974f2422758f40749fdf082c77ab8a75",
            "7a23e4409da84bf096cf64b7b7f62533",
            "104b02932c134da783c82aff99b9b908",
            "b7eb58fce57f48d1baee600b80b64f3b",
            "7f0e7307cd354628b87d029757125741",
            "7a73287f752549caa8d3c100ae046786",
            "f45c449f83c141d184163236ccb6c426",
            "ffb0a8a71c3749b2abc3fbafeb67ac8d",
            "572f2e53d97f4b5197b9ef44beda9d8a",
            "bcd5db0f0cfc404a87bff2573e37c48d",
            "bfd8ac804a0e4497b288e9f7d8d88b87",
            "ba8a15a0fc11491bbaf03b9db11cfb8f",
            "17db3b8f5db9446684bf2cc5d65f0fbe",
            "e8f7e29cfcea4f558a56facdf7ba6b72",
            "828b34a3b82d4d8794241e76fe75d1fe",
            "4b2300a04b7049308ab1a4ec8e65ee6b",
            "666f64f345924c9faa4aff802f038fd6",
            "98a013ed830a4243b2496cdfc263e016",
            "1a1fd67bad054dbdad82d1a2719dc873",
            "b594224d1eab4284b6ff0c13d6ee3b07",
            "25513fe619af42ecab8f45badf3050c5",
            "7abbed4cfd9047458cef4d4fe556675e",
            "dcc1adfd3f2d4947ac7c16a67fc28048",
            "a687862b7d694b9982b037b377be6a41",
            "a08543921ba6465b96f5bf2e9c5be06f",
            "27fe06d3b83e4652abc4826521150498",
            "fcb5e265ef0f4304aa74be5da0cff5ab"
          ]
        },
        "id": "KwAR4kpXfQeM",
        "outputId": "626efe0e-15d0-427d-9c2a-0167b545db6a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "733083c1342549a19e60ee170c848063",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading .gitattributes: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e03ef2f0c4ee4ea58225df77c9773065",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "041255dc0b4e4ea78f937dbab0f0072c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01d5853bde6343579d878baed31869c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e5e1a83f0164a86895b0bd45f974103",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "783ae4f8af6a4ebc99d91febccf795d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e37484d541a9469baba662016dbebb76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d481955f95a44e608caea9be11110255",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d513ed6fc454ad4954314f1ca43541b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O1.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "327eff2159a3461fbe519c4894b70ba8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O2.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3010c28daea47e9a3e1be7c0db0bc36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O3.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18eb640ba3614cf6b50a64162f984e91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O4.onnx:   0%|          | 0.00/45.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d82f01287ef407d9e5ffad183dd4c50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b24ccff458944c769f3068df383802f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)el_qint8_avx512.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "663bf456c10240ec8f8a620a95a3f653",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nt8_avx512_vnni.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e90d58d8bd694acf840a4bef39d8f409",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_quint8_avx2.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0473f6921b124d278367031b4e6cccc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading openvino_model.bin:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a435c6552424d4cb418dc20ffc6a60d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading openvino_model.xml: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2340343870bb4f0da76a76e29b67fbff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_qint8_quantized.bin:   0%|          | 0.00/22.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "960be35de43b46e7a3dd4b564d404515",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_qint8_quantized.xml: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb12941792314e729e8473a8d1242760",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e461638844c4a6a8fa8d24d8b084afb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9879bb312a8f473db6a2c3d0f7b7d591",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfb38ae65a0b4812941886d70ec0f7fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "224e3ef13e004f20b28e8b8067c97a35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "860ddec7a510474d99552521faa297cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading train_script.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eabbc30930fa453ebdd9ab4cb0b706b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f18372486ac14dd0a479706c27e64a95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44ada1b1e8184ebc8a3c8db91536ff06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f71cb7ff318423c8e502ae4ce300d42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c822ced2a2da47c185e1608029b29837",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83cafcac35354ee7be49f86e9e8fbf48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a495ee526539484ebb2b85633617732a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/646 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11c4378530b94cbb9371cc17df5b1249",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)fetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ac8ef87bf74917bf3ab47023020c1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "902f5996ab184423975c6617e939f68c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e562cea7c6f418f8516de67232492c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a73287f752549caa8d3c100ae046786",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "666f64f345924c9faa4aff802f038fd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json\n",
            "Indexing complete!\n",
            "\n",
            "=== Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what is the worst slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: The worst slack is 0.3252ns for the path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk.\n",
            "\n",
            "Question: what are the top 2 worst paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: The worst slack is 0.3252ns for the path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk.\n",
            "\n",
            "Question: how many paths are there in the json file?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Total number of timing paths: 2\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "\n",
        "class LocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with proper encoding handling\"\"\"\n",
        "        try:\n",
        "            # Try UTF-8 first\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                return json.load(f)\n",
        "        except UnicodeDecodeError:\n",
        "            try:\n",
        "                # Try UTF-16\n",
        "                with open(file_path, 'r', encoding='utf-16') as f:\n",
        "                    return json.load(f)\n",
        "            except UnicodeDecodeError:\n",
        "                try:\n",
        "                    # Try UTF-16 with BOM\n",
        "                    with open(file_path, 'r', encoding='utf-16-sig') as f:\n",
        "                        return json.load(f)\n",
        "                except UnicodeDecodeError:\n",
        "                    try:\n",
        "                        # Try latin-1 as fallback\n",
        "                        with open(file_path, 'r', encoding='latin-1') as f:\n",
        "                            return json.load(f)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error reading {file_path}: {e}\")\n",
        "                        return {}\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('slack') != 'N/A':\n",
        "                try:\n",
        "                    slack_value = float(metadata['slack'])\n",
        "                    all_data.append({\n",
        "                        'slack': slack_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                        'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"general\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Classify this question into one of these categories:\n",
        "\n",
        "- worst_slack: Questions about worst/best slack values\n",
        "- best_slack: Questions about best slack values\n",
        "- total_paths: Questions about number of paths\n",
        "- path_types: Questions about different path types\n",
        "- clock_groups: Questions about clock groups\n",
        "- slack_stats: Questions about slack statistics\n",
        "- endpoint_frequency: Questions about endpoint frequency\n",
        "- worst_hold_time_req: Questions about worst hold time requirements\n",
        "- best_hold_time_req: Questions about best hold time requirements\n",
        "- clock_skew: Questions about clock skew\n",
        "- next_path: Questions about \"next path\" or iterating through paths\n",
        "- hold_time_req: Questions about hold time requirements\n",
        "- general: General questions\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Respond with only the category name: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    max_new_tokens=20,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to our categories\n",
        "            if \"worst\" in category and \"slack\" in category:\n",
        "                return \"worst_slack\"\n",
        "            elif \"best\" in category and \"slack\" in category:\n",
        "                return \"best_slack\"\n",
        "            elif \"next\" in category or \"next_path\" in category:\n",
        "                return \"next_path\"\n",
        "            elif \"total\" in category or \"number\" in category:\n",
        "                return \"total_paths\"\n",
        "            elif \"type\" in category:\n",
        "                return \"path_types\"\n",
        "            elif \"group\" in category:\n",
        "                return \"clock_groups\"\n",
        "            elif \"stat\" in category:\n",
        "                return \"slack_stats\"\n",
        "            elif \"endpoint\" in category:\n",
        "                return \"endpoint_frequency\"\n",
        "            elif \"hold\" in category and \"worst\" in category:\n",
        "                return \"worst_hold_time_req\"\n",
        "            elif \"hold\" in category and \"best\" in category:\n",
        "                return \"best_hold_time_req\"\n",
        "            elif \"hold\" in category and \"requirement\" in category:\n",
        "                return \"hold_time_req\"\n",
        "            elif \"skew\" in category:\n",
        "                return \"clock_skew\"\n",
        "            else:\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\n",
        "        # Try LLM classification first\n",
        "        llm_result = self._classify_question_with_llm(question)\n",
        "        if llm_result != \"general\":\n",
        "            return llm_result\n",
        "\n",
        "        # Fallback to pattern matching\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        if \"next\" in question_lower and \"path\" in question_lower:\n",
        "            return \"next_path\"\n",
        "        elif \"worst\" in question_lower and \"slack\" in question_lower:\n",
        "            return \"worst_slack\"\n",
        "        elif \"best\" in question_lower and \"slack\" in question_lower:\n",
        "            return \"best_slack\"\n",
        "        elif \"total\" in question_lower or \"number\" in question_lower or \"how many\" in question_lower:\n",
        "            return \"total_paths\"\n",
        "        elif \"type\" in question_lower:\n",
        "            return \"path_types\"\n",
        "        elif \"group\" in question_lower:\n",
        "            return \"clock_groups\"\n",
        "        elif \"stat\" in question_lower:\n",
        "            return \"slack_stats\"\n",
        "        elif \"endpoint\" in question_lower:\n",
        "            return \"endpoint_frequency\"\n",
        "        elif \"hold\" in question_lower and \"worst\" in question_lower:\n",
        "            return \"worst_hold_time_req\"\n",
        "        elif \"hold\" in question_lower and \"best\" in question_lower:\n",
        "            return \"best_hold_time_req\"\n",
        "        elif \"hold\" in question_lower and \"requirement\" in question_lower:\n",
        "            return \"hold_time_req\"\n",
        "        elif \"skew\" in question_lower:\n",
        "            return \"clock_skew\"\n",
        "        else:\n",
        "            return \"general\"\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    max_new_tokens=200,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        # Add to history\n",
        "        self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "        # Get all slack data for comprehensive analysis\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Classify the question\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "\n",
        "        # Generate response based on question type\n",
        "        if question_type == \"next_path\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            # Sort paths by slack (worst to best)\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "            # Get the next path after current index\n",
        "            if self.current_path_index < len(sorted_paths):\n",
        "                next_path = sorted_paths[self.current_path_index]\n",
        "                self.current_path_index += 1\n",
        "                return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "            else:\n",
        "                return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "        elif question_type == \"worst_slack\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            worst_slack = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            # Reset current path index to start from worst\n",
        "            self.current_path_index = 0\n",
        "            return f\"The worst slack is {worst_slack['slack']}ns for the path from {worst_slack['startpoint']} to {worst_slack['endpoint']} in group {worst_slack['group']}.\"\n",
        "\n",
        "        elif question_type == \"best_slack\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            best_slack = max(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"The best slack is {best_slack['slack']}ns for the path from {best_slack['startpoint']} to {best_slack['endpoint']} in group {best_slack['group']}.\"\n",
        "\n",
        "        elif question_type == \"total_paths\":\n",
        "            total_paths = len(all_slack_data)\n",
        "            return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "        elif question_type == \"slack_stats\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            slack_values = [x['slack'] for x in all_slack_data]\n",
        "            avg_slack = sum(slack_values) / len(slack_values)\n",
        "            min_slack = min(slack_values)\n",
        "            max_slack = max(slack_values)\n",
        "\n",
        "            return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "        elif question_type == \"clock_skew\":\n",
        "            clock_skew_data = self._get_clock_skew_data()\n",
        "            if not clock_skew_data:\n",
        "                return \"No clock skew data available.\"\n",
        "\n",
        "            # Find the path with worst slack and get its clock skew\n",
        "            worst_slack_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            for path in clock_skew_data:\n",
        "                if (path['startpoint'] == worst_slack_path['startpoint'] and\n",
        "                    path['endpoint'] == worst_slack_path['endpoint']):\n",
        "                    return f\"The clock skew for the path from {path['startpoint']} to {path['endpoint']} is {path['clock_skew']}ns.\"\n",
        "\n",
        "            return f\"Clock skew data available for {len(clock_skew_data)} paths. Clock skew values range from {min([x['clock_skew'] for x in clock_skew_data]):.3f}ns to {max([x['clock_skew'] for x in clock_skew_data]):.3f}ns.\"\n",
        "\n",
        "        elif question_type == \"hold_time_req\":\n",
        "            hold_time_data = self._get_hold_time_data()\n",
        "            if not hold_time_data:\n",
        "                return \"No hold time requirement data available.\"\n",
        "\n",
        "            # Find the path with worst slack and get its hold time requirement\n",
        "            worst_slack_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            for path in hold_time_data:\n",
        "                if (path['startpoint'] == worst_slack_path['startpoint'] and\n",
        "                    path['endpoint'] == worst_slack_path['endpoint']):\n",
        "                    return f\"The hold time requirement for the path from {path['startpoint']} to {path['endpoint']} is {path['hold_time_requirement']}ns.\"\n",
        "\n",
        "            return f\"Hold time requirement data available for {len(hold_time_data)} paths. Hold time requirements range from {min([x['hold_time_requirement'] for x in hold_time_data]):.3f}ns to {max([x['hold_time_requirement'] for x in hold_time_data]):.3f}ns.\"\n",
        "\n",
        "        elif question_type == \"worst_hold_time_req\":\n",
        "            hold_time_data = self._get_hold_time_data()\n",
        "            if not hold_time_data:\n",
        "                return \"No hold time requirement data available.\"\n",
        "\n",
        "            worst_hold_time = min(hold_time_data, key=lambda x: x['hold_time_requirement'])\n",
        "            return f\"The worst hold time requirement is {worst_hold_time['hold_time_requirement']}ns for the path from {worst_hold_time['startpoint']} to {worst_hold_time['endpoint']} in group {worst_hold_time['group']}.\"\n",
        "\n",
        "        elif question_type == \"best_hold_time_req\":\n",
        "            hold_time_data = self._get_hold_time_data()\n",
        "            if not hold_time_data:\n",
        "                return \"No hold time requirement data available.\"\n",
        "\n",
        "            best_hold_time = max(hold_time_data, key=lambda x: x['hold_time_requirement'])\n",
        "            return f\"The best hold time requirement is {best_hold_time['hold_time_requirement']}ns for the path from {best_hold_time['startpoint']} to {best_hold_time['endpoint']} in group {best_hold_time['group']}.\"\n",
        "\n",
        "        else:\n",
        "            # For general questions, use LLM with context\n",
        "            try:\n",
        "                # Generate embedding for the question\n",
        "                question_embedding = self.embedding_model.encode(question).tolist()\n",
        "\n",
        "                # Search for similar documents\n",
        "                results = self.collection.query(\n",
        "                    query_embeddings=[question_embedding],\n",
        "                    n_results=top_k\n",
        "                )\n",
        "\n",
        "                # Format context\n",
        "                context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "                # Use LLM to generate response\n",
        "                answer = self._generate_llm_response(question, context)\n",
        "\n",
        "                # Update history\n",
        "                self.history[-1]['answer'] = answer\n",
        "\n",
        "                return answer\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"Error processing question: {e}\"\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = LocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738,
          "referenced_widgets": [
            "ce0680c2d90f4d16bd652b877a0011f8",
            "e2e3494632fe4516a68c03018765c4d1",
            "497d5ef5243940aab69644d2fbd8b90e",
            "84d8a2accea04fa28b53d94f103cbcca",
            "88051db9debc47c7be8240ad62f9adc1",
            "3200a71728314547a5abebfac664d358",
            "5545aaeb70e5462baf4b5a28363eaf9a",
            "8823ccf5e72a44fab7c915343767ff67",
            "5f09e0153c3e4404a59b19d6163e4c78",
            "c48635a6a24240e3a431653250119583",
            "d79d1c155aca49448eb59ca6f870a7fc"
          ]
        },
        "id": "h-N7afpHibb-",
        "outputId": "17d3a949-d7de-4ae6-9959-bd250e2e63fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce0680c2d90f4d16bd652b877a0011f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n",
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what are the top 2 worst paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3179821962.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3179821962.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {answer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3179821962.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, question, top_k)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;31m# Classify the question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mquestion_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;31m# Generate response based on question type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3179821962.py\u001b[0m in \u001b[0;36m_classify_question\u001b[0;34m(self, question, data)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;34m\"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# Try LLM classification first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mllm_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify_question_with_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mllm_result\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"general\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mllm_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3179821962.py\u001b[0m in \u001b[0;36m_classify_question_with_llm\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 outputs = self.llm_model.generate(\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2802\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_proj_slices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretraining_tp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mfp16_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SCB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                 set_module_tensor_to_device(\n\u001b[0m\u001b[1;32m    287\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16_statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics)\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('slack') != 'N/A':\n",
        "                try:\n",
        "                    slack_value = float(metadata['slack'])\n",
        "                    all_data.append({\n",
        "                        'slack': slack_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                        'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with proper attention mask\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"general\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Classify this question into one of these categories:\n",
        "\n",
        "- worst_slack: Questions about worst/best slack values\n",
        "- best_slack: Questions about best slack values\n",
        "- top_worst_paths: Questions about top N worst paths (e.g., \"top 2 worst\", \"worst 3 paths\")\n",
        "- top_best_paths: Questions about top N best paths (e.g., \"top 2 best\", \"best 3 paths\")\n",
        "- total_paths: Questions about number of paths\n",
        "- path_types: Questions about different path types\n",
        "- clock_groups: Questions about clock groups\n",
        "- slack_stats: Questions about slack statistics\n",
        "- endpoint_frequency: Questions about endpoint frequency\n",
        "- worst_hold_time_req: Questions about worst hold time requirements\n",
        "- best_hold_time_req: Questions about best hold time requirements\n",
        "- clock_skew: Questions about clock skew\n",
        "- next_path: Questions about \"next path\" or iterating through paths\n",
        "- hold_time_req: Questions about hold time requirements\n",
        "- general: General questions\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Respond with only the category name: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=20,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to our categories\n",
        "            if \"top_worst_paths\" in category:\n",
        "                return \"top_worst_paths\"\n",
        "            elif \"top_best_paths\" in category:\n",
        "                return \"top_best_paths\"\n",
        "            elif \"worst\" in category and \"slack\" in category:\n",
        "                return \"worst_slack\"\n",
        "            elif \"best\" in category and \"slack\" in category:\n",
        "                return \"best_slack\"\n",
        "            elif \"next\" in category or \"next_path\" in category:\n",
        "                return \"next_path\"\n",
        "            elif \"total\" in category or \"number\" in category:\n",
        "                return \"total_paths\"\n",
        "            elif \"type\" in category:\n",
        "                return \"path_types\"\n",
        "            elif \"group\" in category:\n",
        "                return \"clock_groups\"\n",
        "            elif \"stat\" in category:\n",
        "                return \"slack_stats\"\n",
        "            elif \"endpoint\" in category:\n",
        "                return \"endpoint_frequency\"\n",
        "            elif \"hold\" in category and \"worst\" in category:\n",
        "                return \"worst_hold_time_req\"\n",
        "            elif \"hold\" in category and \"best\" in category:\n",
        "                return \"best_hold_time_req\"\n",
        "            elif \"hold\" in category and \"requirement\" in category:\n",
        "                return \"hold_time_req\"\n",
        "            elif \"skew\" in category:\n",
        "                return \"clock_skew\"\n",
        "            else:\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\n",
        "        # Try LLM classification first\n",
        "        llm_result = self._classify_question_with_llm(question)\n",
        "        if llm_result != \"general\":\n",
        "            return llm_result\n",
        "\n",
        "        # Fallback to pattern matching\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for top N patterns first\n",
        "        if (\"top\" in question_lower or \"worst\" in question_lower) and (\"2\" in question_lower or \"3\" in question_lower or \"4\" in question_lower or \"5\" in question_lower or \"10\" in question_lower):\n",
        "            if \"worst\" in question_lower:\n",
        "                return \"top_worst_paths\"\n",
        "            elif \"best\" in question_lower:\n",
        "                return \"top_best_paths\"\n",
        "        elif \"next\" in question_lower and \"path\" in question_lower:\n",
        "            return \"next_path\"\n",
        "        elif \"worst\" in question_lower and \"slack\" in question_lower:\n",
        "            return \"worst_slack\"\n",
        "        elif \"best\" in question_lower and \"slack\" in question_lower:\n",
        "            return \"best_slack\"\n",
        "        elif \"total\" in question_lower or \"number\" in question_lower or \"how many\" in question_lower:\n",
        "            return \"total_paths\"\n",
        "        elif \"type\" in question_lower:\n",
        "            return \"path_types\"\n",
        "        elif \"group\" in question_lower:\n",
        "            return \"clock_groups\"\n",
        "        elif \"stat\" in question_lower:\n",
        "            return \"slack_stats\"\n",
        "        elif \"endpoint\" in question_lower:\n",
        "            return \"endpoint_frequency\"\n",
        "        elif \"hold\" in question_lower and \"worst\" in question_lower:\n",
        "            return \"worst_hold_time_req\"\n",
        "        elif \"hold\" in question_lower and \"best\" in question_lower:\n",
        "            return \"best_hold_time_req\"\n",
        "        elif \"hold\" in question_lower and \"requirement\" in question_lower:\n",
        "            return \"hold_time_req\"\n",
        "        elif \"skew\" in question_lower:\n",
        "            return \"clock_skew\"\n",
        "        else:\n",
        "            return \"general\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=200,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        # Add to history\n",
        "        self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "        # Get all slack data for comprehensive analysis\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Classify the question\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "\n",
        "        # Generate response based on question type\n",
        "        if question_type == \"next_path\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            # Sort paths by slack (worst to best)\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "            # Get the next path after current index\n",
        "            if self.current_path_index < len(sorted_paths):\n",
        "                next_path = sorted_paths[self.current_path_index]\n",
        "                self.current_path_index += 1\n",
        "                return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "            else:\n",
        "                return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "        elif question_type == \"worst_slack\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            worst_slack = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            # Reset current path index to start from worst\n",
        "            self.current_path_index = 0\n",
        "            return f\"The worst slack is {worst_slack['slack']}ns for the path from {worst_slack['startpoint']} to {worst_slack['endpoint']} in group {worst_slack['group']}.\"\n",
        "\n",
        "        elif question_type == \"best_slack\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            best_slack = max(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"The best slack is {best_slack['slack']}ns for the path from {best_slack['startpoint']} to {best_slack['endpoint']} in group {best_slack['group']}.\"\n",
        "\n",
        "        elif question_type == \"top_worst_paths\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            # Extract number from question\n",
        "            n = self._extract_number_from_question(question)\n",
        "            n = min(n, len(all_slack_data))  # Don't exceed available paths\n",
        "\n",
        "            # Sort paths by slack (worst to best)\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "            # Get top N worst paths\n",
        "            top_worst = sorted_paths[:n]\n",
        "\n",
        "            result = f\"Top {n} worst slack paths:\\n\"\n",
        "            for i, path in enumerate(top_worst, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "            return result.strip()\n",
        "\n",
        "        elif question_type == \"top_best_paths\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            # Extract number from question\n",
        "            n = self._extract_number_from_question(question)\n",
        "            n = min(n, len(all_slack_data))  # Don't exceed available paths\n",
        "\n",
        "            # Sort paths by slack (best to worst)\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "\n",
        "            # Get top N best paths\n",
        "            top_best = sorted_paths[:n]\n",
        "\n",
        "            result = f\"Top {n} best slack paths:\\n\"\n",
        "            for i, path in enumerate(top_best, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "            return result.strip()\n",
        "\n",
        "        elif question_type == \"total_paths\":\n",
        "            total_paths = len(all_slack_data)\n",
        "            return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "        elif question_type == \"slack_stats\":\n",
        "            if not all_slack_data:\n",
        "                return \"No slack data available.\"\n",
        "\n",
        "            slack_values = [x['slack'] for x in all_slack_data]\n",
        "            avg_slack = sum(slack_values) / len(slack_values)\n",
        "            min_slack = min(slack_values)\n",
        "            max_slack = max(slack_values)\n",
        "\n",
        "            return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "        elif question_type == \"clock_skew\":\n",
        "            clock_skew_data = self._get_clock_skew_data()\n",
        "            if not clock_skew_data:\n",
        "                return \"No clock skew data available.\"\n",
        "\n",
        "            # Find the path with worst slack and get its clock skew\n",
        "            worst_slack_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            for path in clock_skew_data:\n",
        "                if (path['startpoint'] == worst_slack_path['startpoint'] and\n",
        "                    path['endpoint'] == worst_slack_path['endpoint']):\n",
        "                    return f\"The clock skew for the path from {path['startpoint']} to {path['endpoint']} is {path['clock_skew']}ns.\"\n",
        "\n",
        "            return f\"Clock skew data available for {len(clock_skew_data)} paths. Clock skew values range from {min([x['clock_skew'] for x in clock_skew_data]):.3f}ns to {max([x['clock_skew'] for x in clock_skew_data]):.3f}ns.\"\n",
        "\n",
        "        elif question_type == \"hold_time_req\":\n",
        "            hold_time_data = self._get_hold_time_data()\n",
        "            if not hold_time_data:\n",
        "                return \"No hold time requirement data available.\"\n",
        "\n",
        "            # Find the path with worst slack and get its hold time requirement\n",
        "            worst_slack_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            for path in hold_time_data:\n",
        "                if (path['startpoint'] == worst_slack_path['startpoint'] and\n",
        "                    path['endpoint'] == worst_slack_path['endpoint']):\n",
        "                    return f\"The hold time requirement for the path from {path['startpoint']} to {path['endpoint']} is {path['hold_time_requirement']}ns.\"\n",
        "\n",
        "            return f\"Hold time requirement data available for {len(hold_time_data)} paths. Hold time requirements range from {min([x['hold_time_requirement'] for x in hold_time_data]):.3f}ns to {max([x['hold_time_requirement'] for x in hold_time_data]):.3f}ns.\"\n",
        "\n",
        "        elif question_type == \"worst_hold_time_req\":\n",
        "            hold_time_data = self._get_hold_time_data()\n",
        "            if not hold_time_data:\n",
        "                return \"No hold time requirement data available.\"\n",
        "\n",
        "            worst_hold_time = min(hold_time_data, key=lambda x: x['hold_time_requirement'])\n",
        "            return f\"The worst hold time requirement is {worst_hold_time['hold_time_requirement']}ns for the path from {worst_hold_time['startpoint']} to {worst_hold_time['endpoint']} in group {worst_hold_time['group']}.\"\n",
        "\n",
        "        elif question_type == \"best_hold_time_req\":\n",
        "            hold_time_data = self._get_hold_time_data()\n",
        "            if not hold_time_data:\n",
        "                return \"No hold time requirement data available.\"\n",
        "\n",
        "            best_hold_time = max(hold_time_data, key=lambda x: x['hold_time_requirement'])\n",
        "            return f\"The best hold time requirement is {best_hold_time['hold_time_requirement']}ns for the path from {best_hold_time['startpoint']} to {best_hold_time['endpoint']} in group {best_hold_time['group']}.\"\n",
        "\n",
        "        else:\n",
        "            # For general questions, use LLM with context\n",
        "            try:\n",
        "                # Generate embedding for the question\n",
        "                question_embedding = self.embedding_model.encode(question).tolist()\n",
        "\n",
        "                # Search for similar documents\n",
        "                results = self.collection.query(\n",
        "                    query_embeddings=[question_embedding],\n",
        "                    n_results=top_k\n",
        "                )\n",
        "\n",
        "                # Format context\n",
        "                context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "                # Use LLM to generate response\n",
        "                answer = self._generate_llm_response(question, context)\n",
        "\n",
        "                # Update history\n",
        "                self.history[-1]['answer'] = answer\n",
        "\n",
        "                return answer\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"Error processing question: {e}\"\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703,
          "referenced_widgets": [
            "6f449e8a08314ae5a98eca56bbc23e50",
            "edd3b6647ebd4f5f848e2dc037f8c3c6",
            "6eaa4a7fc562446a8e1490c91e71ad96",
            "89e33a2008554bf8acd8c6bdae2145b4",
            "92961d3f66ef461a8e689a615034790a",
            "73b72bae7bcd45d19705a36d3ae0e50a",
            "3a93149b9fc045aead269b10f96b6b57",
            "76e8dcaa61f241f7953c12eb22f4a633",
            "f0c95183354f406a937ec91baf47847c",
            "26e318fd50a9459f8c84136659e991b4",
            "113f01d7ad9a4ff79aeec8bbf68176d2"
          ]
        },
        "id": "b1Q3gDmZjnFY",
        "outputId": "8aed45b5-a21f-468a-81d7-62944d422ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f449e8a08314ae5a98eca56bbc23e50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what are the two top worst paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-288763386.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-288763386.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {answer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-288763386.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, question, top_k)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_navigation_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquestion_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ranking\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_ranking_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquestion_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"counting\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_counting_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-288763386.py\u001b[0m in \u001b[0;36m_handle_ranking_query\u001b[0;34m(self, question, all_slack_data)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mdata_context\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_counting_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-288763386.py\u001b[0m in \u001b[0;36m_generate_llm_response\u001b[0;34m(self, question, context)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 outputs = self.llm_model.generate(\n\u001b[0m\u001b[1;32m    529\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2802\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mfp16_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SCB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 set_module_tensor_to_device(\n\u001b[0;32m--> 287\u001b[0;31m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16_statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{self.prefix}{key}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"safetensors_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('slack') != 'N/A':\n",
        "                try:\n",
        "                    slack_value = float(metadata['slack'])\n",
        "                    all_data.append({\n",
        "                        'slack': slack_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                        'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with proper attention mask\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"general\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Classify this question into one of these HIGH-LEVEL categories:\n",
        "\n",
        "- ranking: Questions about ranking, ordering, or finding top/best/worst items\n",
        "- counting: Questions about counting, totals, or quantities\n",
        "- statistics: Questions about statistical analysis, distributions, or summaries\n",
        "- filtering: Questions about filtering, searching, or finding specific items\n",
        "- navigation: Questions about iterating, browsing, or moving through data\n",
        "- general: General questions that don't fit other categories\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Respond with only the category name: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=20,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                return category\n",
        "            else:\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\n",
        "        # Try LLM classification first\n",
        "        llm_result = self._classify_question_with_llm(question)\n",
        "        if llm_result != \"general\":\n",
        "            return llm_result\n",
        "\n",
        "        # Fallback to pattern matching with high-level categories\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Ranking patterns\n",
        "        if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "            return \"ranking\"\n",
        "        # Counting patterns\n",
        "        elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "            return \"counting\"\n",
        "        # Statistics patterns\n",
        "        elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "            return \"statistics\"\n",
        "        # Filtering patterns\n",
        "        elif any(word in question_lower for word in [\"find\", \"search\", \"filter\", \"where\", \"which\", \"show me\"]):\n",
        "            return \"filtering\"\n",
        "        # Navigation patterns\n",
        "        elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "            return \"navigation\"\n",
        "        else:\n",
        "            return \"general\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare structured data for LLM\n",
        "        data_context = \"Available timing paths:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare summary data for LLM\n",
        "        data_context = f\"Total paths: {len(all_slack_data)}\\n\"\n",
        "        data_context += f\"Groups: {set(path['group'] for path in all_slack_data)}\\n\"\n",
        "        data_context += f\"Slack range: {min(path['slack'] for path in all_slack_data):.3f}ns to {max(path['slack'] for path in all_slack_data):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        data_context = f\"Slack statistics:\\n\"\n",
        "        data_context += f\"- Count: {len(slack_values)}\\n\"\n",
        "        data_context += f\"- Min: {min(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Max: {max(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Average: {sum(slack_values)/len(slack_values):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare detailed data for LLM\n",
        "        data_context = \"All timing paths:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=200,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        # Add to history\n",
        "        self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "        # Get all slack data for comprehensive analysis\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Classify the question\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        if question_type == \"navigation\":\n",
        "            return self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            return self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            return self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            return self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            return self._handle_filtering_query(question, all_slack_data)\n",
        "        else:\n",
        "            # For general questions, use LLM with context\n",
        "            try:\n",
        "                # Generate embedding for the question\n",
        "                question_embedding = self.embedding_model.encode(question).tolist()\n",
        "\n",
        "                # Search for similar documents\n",
        "                results = self.collection.query(\n",
        "                    query_embeddings=[question_embedding],\n",
        "                    n_results=top_k\n",
        "                )\n",
        "\n",
        "                # Format context\n",
        "                context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "                # Use LLM to generate response\n",
        "                answer = self._generate_llm_response(question, context)\n",
        "\n",
        "                # Update history\n",
        "                self.history[-1]['answer'] = answer\n",
        "\n",
        "                return answer\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"Error processing question: {e}\"\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686,
          "referenced_widgets": [
            "dc853598552445ca8e4c19ad8ea1c3f0",
            "7c9992ed09774ed3a923d53447247c91",
            "af99b92440a444b98319f553c0e3664c",
            "e01a8f30104b4de391e3afe833ca812a",
            "d740506359ce402cabb61eb8a715bfac",
            "9e018aa9759c4a61a783480bfbfd553f",
            "8e32b322c8f84a71857d71c62f745984",
            "dc30b224e3744378b975796174a98c98",
            "bc74fda7740d4c56a305da69b0814f72",
            "cfb9264dfd054211974c0b5990f59c62",
            "99c3f6923d9343fca47e09071a81ba20"
          ]
        },
        "id": "CVpzuw1-kxkM",
        "outputId": "c9a6aad6-cbc3-47a2-ef0c-8bd7bc3eeebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc853598552445ca8e4c19ad8ea1c3f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what are the two top worst paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1886626768.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1886626768.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {answer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1886626768.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, question, top_k)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;31m# Classify the question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mquestion_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;31m# Generate response based on high-level question type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1886626768.py\u001b[0m in \u001b[0;36m_classify_question\u001b[0;34m(self, question, data)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;34m\"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# Try LLM classification first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mllm_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify_question_with_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mllm_result\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"general\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mllm_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1886626768.py\u001b[0m in \u001b[0;36m_classify_question_with_llm\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 outputs = self.llm_model.generate(\n\u001b[0m\u001b[1;32m    366\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2802\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mfp16_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SCB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 set_module_tensor_to_device(\n\u001b[0;32m--> 287\u001b[0;31m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16_statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{self.prefix}{key}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"safetensors_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('slack') != 'N/A':\n",
        "                try:\n",
        "                    slack_value = float(metadata['slack'])\n",
        "                    all_data.append({\n",
        "                        'slack': slack_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                        'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with proper attention mask\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"general\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Classify this question into one of these HIGH-LEVEL categories:\n",
        "\n",
        "- ranking: Questions about ranking, ordering, or finding top/best/worst items\n",
        "- counting: Questions about counting, totals, or quantities\n",
        "- statistics: Questions about statistical analysis, distributions, or summaries\n",
        "- filtering: Questions about filtering, searching, or finding specific items\n",
        "- navigation: Questions about iterating, browsing, or moving through data\n",
        "- general: General questions that don't fit other categories\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Respond with only the category name: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=20,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                return category\n",
        "            else:\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\n",
        "        # Try LLM classification first\n",
        "        llm_result = self._classify_question_with_llm(question)\n",
        "        if llm_result != \"general\":\n",
        "            return llm_result\n",
        "\n",
        "        # Fallback to pattern matching with high-level categories\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Ranking patterns\n",
        "        if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "            return \"ranking\"\n",
        "        # Counting patterns\n",
        "        elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "            return \"counting\"\n",
        "        # Statistics patterns\n",
        "        elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "            return \"statistics\"\n",
        "        # Filtering patterns\n",
        "        elif any(word in question_lower for word in [\"find\", \"search\", \"filter\", \"where\", \"which\", \"show me\"]):\n",
        "            return \"filtering\"\n",
        "        # Navigation patterns\n",
        "        elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "            return \"navigation\"\n",
        "        else:\n",
        "            return \"general\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare structured data for LLM\n",
        "        data_context = \"Available timing paths:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare summary data for LLM\n",
        "        data_context = f\"Total paths: {len(all_slack_data)}\\n\"\n",
        "        data_context += f\"Groups: {set(path['group'] for path in all_slack_data)}\\n\"\n",
        "        data_context += f\"Slack range: {min(path['slack'] for path in all_slack_data):.3f}ns to {max(path['slack'] for path in all_slack_data):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        data_context = f\"Slack statistics:\\n\"\n",
        "        data_context += f\"- Count: {len(slack_values)}\\n\"\n",
        "        data_context += f\"- Min: {min(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Max: {max(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Average: {sum(slack_values)/len(slack_values):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare detailed data for LLM\n",
        "        data_context = \"All timing paths:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=200,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        # Add to history\n",
        "        self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "        # Get all slack data for comprehensive analysis\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Classify the question\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        if question_type == \"navigation\":\n",
        "            return self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            return self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            return self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            return self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            return self._handle_filtering_query(question, all_slack_data)\n",
        "        else:\n",
        "            # For general questions, use LLM with context\n",
        "            try:\n",
        "                # Generate embedding for the question\n",
        "                question_embedding = self.embedding_model.encode(question).tolist()\n",
        "\n",
        "                # Search for similar documents\n",
        "                results = self.collection.query(\n",
        "                    query_embeddings=[question_embedding],\n",
        "                    n_results=top_k\n",
        "                )\n",
        "\n",
        "                # Format context\n",
        "                context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "                # Use LLM to generate response\n",
        "                answer = self._generate_llm_response(question, context)\n",
        "\n",
        "                # Update history\n",
        "                self.history[-1]['answer'] = answer\n",
        "\n",
        "                return answer\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"Error processing question: {e}\"\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842,
          "referenced_widgets": [
            "bab05e9155c044e89de49aaf110dafd3",
            "475b6d0583f541348b390af739467fc6",
            "bd13367d418e4309b0e780557805de99",
            "60f4cdaefc2d4f2eb469fa342953be7d",
            "e8f7501307f846c58cfa9d81e9160319",
            "4372a4e66f73433b9907b21becbedcd8",
            "b74166f3dd3c44b3bc8be1961d97956a",
            "392a7daa6776422aac143550f01422f6",
            "cfd20d3d06474742aa0bad6a2a5f22cd",
            "559288102d844e14bb5c5edace7955a2",
            "02fa33e476d84680acdbd932b4332aeb"
          ]
        },
        "id": "k8z7OSXjlD5U",
        "outputId": "a4ee9cac-6851-4780-ddfd-69c0972b7f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bab05e9155c044e89de49aaf110dafd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n",
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what are the two top worst paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Handling ranking query: what are the two top worst paths?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Calling LLM for ranking query...\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 186])\n",
            "DEBUG: Starting LLM generation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1660983055.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1660983055.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {answer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1660983055.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, question, top_k)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_navigation_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquestion_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ranking\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_ranking_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquestion_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"counting\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_counting_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1660983055.py\u001b[0m in \u001b[0;36m_handle_ranking_query\u001b[0;34m(self, question, all_slack_data)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Calling LLM for ranking query...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DEBUG: LLM response received: {len(response)} chars\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1660983055.py\u001b[0m in \u001b[0;36m_generate_llm_response\u001b[0;34m(self, question, context)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Starting LLM generation...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 outputs = self.llm_model.generate(\n\u001b[0m\u001b[1;32m    576\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2802\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mfp16_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SCB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 set_module_tensor_to_device(\n\u001b[0;32m--> 287\u001b[0;31m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16_statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{self.prefix}{key}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"safetensors_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('slack') != 'N/A':\n",
        "                try:\n",
        "                    slack_value = float(metadata['slack'])\n",
        "                    all_data.append({\n",
        "                        'slack': slack_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                        'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with proper attention mask\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"general\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Classify this question into one of these HIGH-LEVEL categories:\n",
        "\n",
        "- ranking: Questions about ranking, ordering, or finding top/best/worst items\n",
        "- counting: Questions about counting, totals, or quantities\n",
        "- statistics: Questions about statistical analysis, distributions, or summaries\n",
        "- filtering: Questions about filtering, searching, or finding specific items\n",
        "- navigation: Questions about iterating, browsing, or moving through data\n",
        "- general: General questions that don't fit other categories\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Respond with only the category name: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=20,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                return category\n",
        "            else:\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\n",
        "        # Try LLM classification first\n",
        "        llm_result = self._classify_question_with_llm(question)\n",
        "        if llm_result != \"general\":\n",
        "            return llm_result\n",
        "\n",
        "        # Fallback to pattern matching with high-level categories\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Ranking patterns\n",
        "        if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "            return \"ranking\"\n",
        "        # Counting patterns\n",
        "        elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "            return \"counting\"\n",
        "        # Statistics patterns\n",
        "        elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "            return \"statistics\"\n",
        "        # Filtering patterns\n",
        "        elif any(word in question_lower for word in [\"find\", \"search\", \"filter\", \"where\", \"which\", \"show me\"]):\n",
        "            return \"filtering\"\n",
        "        # Navigation patterns\n",
        "        elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "            return \"navigation\"\n",
        "        else:\n",
        "            return \"general\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Try LLM first, but with timeout\n",
        "        try:\n",
        "            # Prepare structured data for LLM\n",
        "            data_context = \"Available timing paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "            print(\"DEBUG: Calling LLM for ranking query...\")\n",
        "            response = self._generate_llm_response(question, data_context)\n",
        "            print(f\"DEBUG: LLM response received: {len(response)} chars\")\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: LLM failed, using fallback: {e}\")\n",
        "            # Fallback to direct processing\n",
        "            return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare summary data for LLM\n",
        "        data_context = f\"Total paths: {len(all_slack_data)}\\n\"\n",
        "        data_context += f\"Groups: {set(path['group'] for path in all_slack_data)}\\n\"\n",
        "        data_context += f\"Slack range: {min(path['slack'] for path in all_slack_data):.3f}ns to {max(path['slack'] for path in all_slack_data):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        data_context = f\"Slack statistics:\\n\"\n",
        "        data_context += f\"- Count: {len(slack_values)}\\n\"\n",
        "        data_context += f\"- Min: {min(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Max: {max(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Average: {sum(slack_values)/len(slack_values):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare detailed data for LLM\n",
        "        data_context = \"All timing paths:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        # Add to history\n",
        "        self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "        # Get all slack data for comprehensive analysis\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Classify the question\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        if question_type == \"navigation\":\n",
        "            return self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            return self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            return self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            return self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            return self._handle_filtering_query(question, all_slack_data)\n",
        "        else:\n",
        "            # For general questions, use LLM with context\n",
        "            try:\n",
        "                # Generate embedding for the question\n",
        "                question_embedding = self.embedding_model.encode(question).tolist()\n",
        "\n",
        "                # Search for similar documents\n",
        "                results = self.collection.query(\n",
        "                    query_embeddings=[question_embedding],\n",
        "                    n_results=top_k\n",
        "                )\n",
        "\n",
        "                # Format context\n",
        "                context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "                # Use LLM to generate response\n",
        "                answer = self._generate_llm_response(question, context)\n",
        "\n",
        "                # Update history\n",
        "                self.history[-1]['answer'] = answer\n",
        "\n",
        "                return answer\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"Error processing question: {e}\"\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4e5024d0809c40b2a6069413911db6e6",
            "1490d6000483413f9660a88a3bb7d6e5",
            "ec6e53843fa3422f9174982083d53783",
            "2997826ac37b4f77b80f20c40f2c7fa4",
            "b8f0cfa283ff41ee97677a8f803247aa",
            "42868fad64824cd595cc5ee1383e38fd",
            "d92bedbe2e4c48f489d4f1e021bd719a",
            "c1d7d150fde1478b9ad79256fed54874",
            "c46c7aee4e22458795a875cc4f55da3a",
            "e7ea7dfd8bbd4b4299d0d806c9e1059e",
            "95f4b9e67e3c4f7cb65b4497fd328e5e"
          ]
        },
        "id": "egQRvy0imlBO",
        "outputId": "be0fcc4b-a89c-4547-f669-8321f686bc20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e5024d0809c40b2a6069413911db6e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what are the two top worst paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what are the two top worst paths?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what are the two top worst paths?'\n",
            "DEBUG: Trying LLM classification...\n",
            "DEBUG: LLM classification for: 'what are the two top worst paths?'\n",
            "DEBUG: Tokenizing classification prompt...\n",
            "DEBUG: Creating attention mask...\n",
            "DEBUG: Starting LLM classification generation...\n",
            "DEBUG: Decoding classification response...\n",
            "DEBUG: Raw LLM response: '[INST] You are a timing analysis assistant. Classify this question into one of these HIGH-LEVEL categories:\n",
            "\n",
            "- ranking: Questions about ranking, ordering, or finding top/best/worst items\n",
            "- counting: Questions about counting, totals, or quantities\n",
            "- statistics: Questions about statistical analysis, distributions, or summaries\n",
            "- filtering: Questions about filtering, searching, or finding specific items\n",
            "- navigation: Questions about iterating, browsing, or moving through data\n",
            "- general: General questions that don't fit other categories\n",
            "\n",
            "Question: what are the two top worst paths?\n",
            "\n",
            "Respond with only the category name: [/INST]  ranking'\n",
            "DEBUG: Extracted category: 'ranking'\n",
            "DEBUG: Valid category found: 'ranking'\n",
            "DEBUG: LLM classification result: 'ranking'\n",
            "DEBUG: Using LLM result: ranking\n",
            "DEBUG: Question classified as: 'ranking'\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what are the two top worst paths?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Calling LLM for ranking query...\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 186])\n",
            "DEBUG: Starting LLM generation...\n",
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 235\n",
            "DEBUG: LLM response received: 235 chars\n",
            "Answer: Based on the timing data provided, the two top worst paths are:\n",
            "\n",
            "1. Slack: 0.3252ns - Start: chip_core/housekeeping/_6778_ - End: chip_core/housekeeping/_6778_ - Group: hkspi_clk\n",
            "2. Slack: 0.6112ns - Start: chip_core/housekeeping/_6656\n",
            "\n",
            "Question: how many paths are there?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how many paths are there?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how many paths are there?'\n",
            "DEBUG: Trying LLM classification...\n",
            "DEBUG: LLM classification for: 'how many paths are there?'\n",
            "DEBUG: Tokenizing classification prompt...\n",
            "DEBUG: Creating attention mask...\n",
            "DEBUG: Starting LLM classification generation...\n",
            "DEBUG: Decoding classification response...\n",
            "DEBUG: Raw LLM response: '[INST] You are a timing analysis assistant. Classify this question into one of these HIGH-LEVEL categories:\n",
            "\n",
            "- ranking: Questions about ranking, ordering, or finding top/best/worst items\n",
            "- counting: Questions about counting, totals, or quantities\n",
            "- statistics: Questions about statistical analysis, distributions, or summaries\n",
            "- filtering: Questions about filtering, searching, or finding specific items\n",
            "- navigation: Questions about iterating, browsing, or moving through data\n",
            "- general: General questions that don't fit other categories\n",
            "\n",
            "Question: how many paths are there?\n",
            "\n",
            "Respond with only the category name: [/INST]  counting'\n",
            "DEBUG: Extracted category: 'counting'\n",
            "DEBUG: Valid category found: 'counting'\n",
            "DEBUG: LLM classification result: 'counting'\n",
            "DEBUG: Using LLM result: counting\n",
            "DEBUG: Question classified as: 'counting'\n",
            "DEBUG: Routing to handler for type: counting\n",
            "DEBUG: Calling counting handler\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 106])\n",
            "DEBUG: Starting LLM generation...\n",
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 65\n",
            "Answer: The timing analysis reveals that there are 2 paths in the design.\n",
            "\n",
            "Question: show the startpoint and endpoints for each path\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'show the startpoint and endpoints for each path'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'show the startpoint and endpoints for each path'\n",
            "DEBUG: Trying LLM classification...\n",
            "DEBUG: LLM classification for: 'show the startpoint and endpoints for each path'\n",
            "DEBUG: Tokenizing classification prompt...\n",
            "DEBUG: Creating attention mask...\n",
            "DEBUG: Starting LLM classification generation...\n",
            "DEBUG: Decoding classification response...\n",
            "DEBUG: Raw LLM response: '[INST] You are a timing analysis assistant. Classify this question into one of these HIGH-LEVEL categories:\n",
            "\n",
            "- ranking: Questions about ranking, ordering, or finding top/best/worst items\n",
            "- counting: Questions about counting, totals, or quantities\n",
            "- statistics: Questions about statistical analysis, distributions, or summaries\n",
            "- filtering: Questions about filtering, searching, or finding specific items\n",
            "- navigation: Questions about iterating, browsing, or moving through data\n",
            "- general: General questions that don't fit other categories\n",
            "\n",
            "Question: show the startpoint and endpoints for each path\n",
            "\n",
            "Respond with only the category name: [/INST]  navigation'\n",
            "DEBUG: Extracted category: 'navigation'\n",
            "DEBUG: Valid category found: 'navigation'\n",
            "DEBUG: LLM classification result: 'navigation'\n",
            "DEBUG: Using LLM result: navigation\n",
            "DEBUG: Question classified as: 'navigation'\n",
            "DEBUG: Routing to handler for type: navigation\n",
            "DEBUG: Calling navigation handler\n",
            "Answer: Next path slack: 0.3252ns for the path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk.\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with proper attention mask\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Classify this question into one of these HIGH-LEVEL categories:\n",
        "\n",
        "- ranking: Questions about ranking, ordering, or finding top/best/worst items\n",
        "- counting: Questions about counting, totals, or quantities\n",
        "- statistics: Questions about statistical analysis, distributions, or summaries\n",
        "- filtering: Questions about filtering, searching, or finding specific items\n",
        "- navigation: Questions about iterating, browsing, or moving through data\n",
        "- general: General questions that don't fit other categories\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Respond with only the category name: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=10,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Try LLM classification first\n",
        "        print(\"DEBUG: Trying LLM classification...\")\n",
        "        llm_result = self._classify_question_with_llm(question)\n",
        "        print(f\"DEBUG: LLM classification result: '{llm_result}'\")\n",
        "\n",
        "        if llm_result != \"general\":\n",
        "            print(f\"DEBUG: Using LLM result: {llm_result}\")\n",
        "            return llm_result\n",
        "\n",
        "        # Fallback to pattern matching with high-level categories\n",
        "        print(\"DEBUG: Using pattern matching fallback...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Ranking patterns\n",
        "        if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "            return \"ranking\"\n",
        "        # Counting patterns\n",
        "        elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "            return \"counting\"\n",
        "        # Statistics patterns\n",
        "        elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "            return \"statistics\"\n",
        "        # Filtering patterns\n",
        "        elif any(word in question_lower for word in [\"find\", \"search\", \"filter\", \"where\", \"which\", \"show me\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "            return \"filtering\"\n",
        "        # Navigation patterns\n",
        "        elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "            return \"navigation\"\n",
        "        else:\n",
        "            print(\"DEBUG: Pattern matched as 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Try LLM first, but with timeout\n",
        "        try:\n",
        "            # Prepare structured data for LLM\n",
        "            data_context = \"Available timing paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "            print(\"DEBUG: Calling LLM for ranking query...\")\n",
        "            response = self._generate_llm_response(question, data_context)\n",
        "            print(f\"DEBUG: LLM response received: {len(response)} chars\")\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: LLM failed, using fallback: {e}\")\n",
        "            # Fallback to direct processing\n",
        "            return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare summary data for LLM\n",
        "        data_context = f\"Total paths: {len(all_slack_data)}\\n\"\n",
        "        data_context += f\"Groups: {set(path['group'] for path in all_slack_data)}\\n\"\n",
        "        data_context += f\"Slack range: {min(path['slack'] for path in all_slack_data):.3f}ns to {max(path['slack'] for path in all_slack_data):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        data_context = f\"Slack statistics:\\n\"\n",
        "        data_context += f\"- Count: {len(slack_values)}\\n\"\n",
        "        data_context += f\"- Min: {min(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Max: {max(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Average: {sum(slack_values)/len(slack_values):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare detailed data for LLM\n",
        "        data_context = \"All timing paths:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}'\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "        if question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            return self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            return self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            return self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            return self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            return self._handle_filtering_query(question, all_slack_data)\n",
        "        else:\n",
        "            # For general questions, use LLM with context\n",
        "            try:\n",
        "                # Generate embedding for the question\n",
        "                question_embedding = self.embedding_model.encode(question).tolist()\n",
        "\n",
        "                # Search for similar documents\n",
        "                results = self.collection.query(\n",
        "                    query_embeddings=[question_embedding],\n",
        "                    n_results=top_k\n",
        "                )\n",
        "\n",
        "                # Format context\n",
        "                context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "                # Use LLM to generate response\n",
        "                answer = self._generate_llm_response(question, context)\n",
        "\n",
        "                # Update history\n",
        "                self.history[-1]['answer'] = answer\n",
        "\n",
        "                return answer\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"Error processing question: {e}\"\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3b1234e1dc9e43068d9a2225c678f233",
            "c7c122c227e74d14b5df8905181a49a9",
            "de7514463b55423ca43a02f372efbf53",
            "8503c829903b4fb49939a62f1882f997",
            "3e42b7b2b71d4531aa256ebb5b448ba4",
            "cf58af6ecd1f4b9fb2e1c16ef02f98dd",
            "2a502de44af741df966ae3c4cc7a976d",
            "85704f23d84b4d658a7979c87c7f168f",
            "faf5a994a28048468fca714783669e22",
            "8b6f08c755fc4d8aaeed30107abf1a74",
            "1e15f984cdd443d8bd7f64e23b7de14f"
          ]
        },
        "id": "V4-lTPXCwlfl",
        "outputId": "72ad5e2a-4c4a-4d37-f5dc-db6f70f48dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b1234e1dc9e43068d9a2225c678f233",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what are the two top worst paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what are the two top worst paths?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what are the two top worst paths?'\n",
            "DEBUG: Trying LLM classification...\n",
            "DEBUG: LLM classification for: 'what are the two top worst paths?'\n",
            "DEBUG: Tokenizing classification prompt...\n",
            "DEBUG: Creating attention mask...\n",
            "DEBUG: Starting LLM classification generation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: LLM generation took 167.60 seconds\n",
            "DEBUG: Decoding classification response...\n",
            "DEBUG: Raw LLM response: '[INST] Classify this timing question:\n",
            "\n",
            "- ranking: worst/best/top questions\n",
            "- counting: how many/total questions  \n",
            "- filtering: show/find questions\n",
            "- general: other questions\n",
            "\n",
            "Question: \"what are the two top worst paths?\"\n",
            "\n",
            "Category: [/INST]  This question'\n",
            "DEBUG: Extracted category: 'this question'\n",
            "DEBUG: Invalid category 'this question', returning 'general'\n",
            "DEBUG: LLM classification result: 'general'\n",
            "DEBUG: Using pattern matching fallback...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 167.63s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what are the two top worst paths?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Calling LLM for ranking query...\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 186])\n",
            "DEBUG: Starting LLM generation...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2418035222.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2418035222.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {answer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2418035222.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, question, top_k)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquestion_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ranking\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Calling ranking handler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_ranking_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquestion_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"counting\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Calling counting handler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2418035222.py\u001b[0m in \u001b[0;36m_handle_ranking_query\u001b[0;34m(self, question, all_slack_data)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Calling LLM for ranking query...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DEBUG: LLM response received: {len(response)} chars\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2418035222.py\u001b[0m in \u001b[0;36m_generate_llm_response\u001b[0;34m(self, question, context)\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Starting LLM generation...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                 outputs = self.llm_model.generate(\n\u001b[0m\u001b[1;32m    617\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2802\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mfp16_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SCB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 set_module_tensor_to_device(\n\u001b[0;32m--> 287\u001b[0;31m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16_statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{self.prefix}{key}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"safetensors_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using LLM first, then fallback to pattern matching\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Try LLM classification first\n",
        "        print(\"DEBUG: Trying LLM classification...\")\n",
        "        llm_result = self._classify_question_with_llm(question)\n",
        "        print(f\"DEBUG: LLM classification result: '{llm_result}'\")\n",
        "\n",
        "        if llm_result != \"general\":\n",
        "            print(f\"DEBUG: Using LLM result: {llm_result}\")\n",
        "            return llm_result\n",
        "\n",
        "        # Fallback to pattern matching with high-level categories\n",
        "        print(\"DEBUG: Using pattern matching fallback...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Ranking patterns\n",
        "        if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "            return \"ranking\"\n",
        "        # Counting patterns\n",
        "        elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "            return \"counting\"\n",
        "        # Statistics patterns\n",
        "        elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "            return \"statistics\"\n",
        "        # Filtering patterns\n",
        "        elif any(word in question_lower for word in [\"find\", \"search\", \"filter\", \"where\", \"which\", \"show me\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "            return \"filtering\"\n",
        "        # Navigation patterns\n",
        "        elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "            return \"navigation\"\n",
        "        else:\n",
        "            print(\"DEBUG: Pattern matched as 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Try LLM first, but with timeout\n",
        "        try:\n",
        "            # Prepare structured data for LLM\n",
        "            data_context = \"Available timing paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "            print(\"DEBUG: Calling LLM for ranking query...\")\n",
        "            response = self._generate_llm_response(question, data_context)\n",
        "            print(f\"DEBUG: LLM response received: {len(response)} chars\")\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: LLM failed, using fallback: {e}\")\n",
        "            # Fallback to direct processing\n",
        "            return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare summary data for LLM\n",
        "        data_context = f\"Total paths: {len(all_slack_data)}\\n\"\n",
        "        data_context += f\"Groups: {set(path['group'] for path in all_slack_data)}\\n\"\n",
        "        data_context += f\"Slack range: {min(path['slack'] for path in all_slack_data):.3f}ns to {max(path['slack'] for path in all_slack_data):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        data_context = f\"Slack statistics:\\n\"\n",
        "        data_context += f\"- Count: {len(slack_values)}\\n\"\n",
        "        data_context += f\"- Min: {min(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Max: {max(slack_values):.3f}ns\\n\"\n",
        "        data_context += f\"- Average: {sum(slack_values)/len(slack_values):.3f}ns\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Prepare detailed data for LLM\n",
        "        data_context = \"All timing paths:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            data_context += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "        if question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            return self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            return self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            return self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            return self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            return self._handle_filtering_query(question, all_slack_data)\n",
        "        else:\n",
        "            # For general questions, use LLM with context\n",
        "            try:\n",
        "                # Generate embedding for the question\n",
        "                question_embedding = self.embedding_model.encode(question).tolist()\n",
        "\n",
        "                # Search for similar documents\n",
        "                results = self.collection.query(\n",
        "                    query_embeddings=[question_embedding],\n",
        "                    n_results=top_k\n",
        "                )\n",
        "\n",
        "                # Format context\n",
        "                context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "                # Use LLM to generate response\n",
        "                answer = self._generate_llm_response(question, context)\n",
        "\n",
        "                # Update history\n",
        "                self.history[-1]['answer'] = answer\n",
        "\n",
        "                return answer\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"Error processing question: {e}\"\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4ad162fbbc4e4c1295aebe0b93eb75cd",
            "8bdd167f55b54badad2c66a09aec83fd",
            "601e2c5c5518412a87421cce4f7aba1d",
            "2791beeace374a439ab95451b76a5c8c",
            "b64530a7667148adb8c21f6c1b57135d",
            "e589f888e00d4b08b19ae0af71da25c4",
            "69041b87e25143e59711779525aca6d0",
            "1df031ca9457426c947dcd28c64a4632",
            "e8a88bdbbacf4095b91491ab4514af91",
            "98826e88b1a5420e87db574ee849fa68",
            "2b617db277f54bca86220c2e642d12f0"
          ]
        },
        "id": "ZABEQnXeytD_",
        "outputId": "ecd7e1b0-bd62-4ddd-83ae-0a1ed564812a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ad162fbbc4e4c1295aebe0b93eb75cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what are the two top worst paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what are the two top worst paths?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what are the two top worst paths?'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what are the two top worst paths?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Top 2 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "\n",
            "Question: how many paths are there in total?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how many paths are there in total?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how many paths are there in total?'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'counting'\n",
            "DEBUG: Question classified as: 'counting' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: counting\n",
            "DEBUG: Calling counting handler\n",
            "DEBUG: Using direct counting (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Total number of timing paths: 2\n",
            "\n",
            "Question: what are the clock skew for those two paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what are the clock skew for those two paths?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what are the clock skew for those two paths?'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'general'\n",
            "DEBUG: Question classified as: 'general' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: general\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using FAST pattern matching only\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Skip LLM classification entirely - it's too slow!\n",
        "        print(\"DEBUG: Using fast pattern matching only...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Ranking patterns\n",
        "        if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "            return \"ranking\"\n",
        "        # Counting patterns\n",
        "        elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "            return \"counting\"\n",
        "        # Statistics patterns\n",
        "        elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "            return \"statistics\"\n",
        "        # Filtering patterns\n",
        "        elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "            return \"filtering\"\n",
        "        # Navigation patterns\n",
        "        elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "            return \"navigation\"\n",
        "        else:\n",
        "            print(\"DEBUG: Pattern matched as 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        question_lower = question.lower()\n",
        "        if \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "        else:\n",
        "            # Generic filtering - show all paths\n",
        "            result = \"All timing paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "14109c03ea904a83abd66208234faecf",
            "c20bf4c0d22d4efdb52db1effe57f19f",
            "850d9511decb4716a414782063937d77",
            "f6491464b46f4f9f97b3dd5288854ae6",
            "5b736b5404714877bcca15e17a5edeec",
            "7739707832fe445490158d5f77578b61",
            "fda702e3812240b59ccf56099fb4a91a",
            "ac7cd1df41174ad799eeccef1429d6cb",
            "a725cae7f2e44f5f90d525ddc791d39f",
            "4502ca6ea067426ea288506ee093532e",
            "7247ffd7d7d740eaabca5d82df0eb122"
          ]
        },
        "id": "4yqErd09z6Bz",
        "outputId": "eff39595-54c2-41b2-c071-464c00d02a23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14109c03ea904a83abd66208234faecf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n",
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what are the clock skews for all paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what are the clock skews for all paths?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what are the clock skews for all paths?'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'filtering' (clock skew)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Clock skew information for all paths:\n",
            "1. Path chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ - Clock skew: 0.4998999999999967ns - Slack: 0.3252ns\n",
            "2. Path chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ - Clock skew: 0.4468000000000001ns - Slack: 0.6112ns\n",
            "\n",
            "Question: what are the hold time requirements for all paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what are the hold time requirements for all paths?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what are the hold time requirements for all paths?'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'filtering' (hold time)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Hold time requirements for all paths:\n",
            "1. Path chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ - Hold time requirement: 0.1002ns - Slack: 0.3252ns\n",
            "2. Path chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ - Hold time requirement: -0.0246ns - Slack: 0.6112ns\n",
            "\n",
            "Question: paths that need attention\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'paths that need attention'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'paths that need attention'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'general'\n",
            "DEBUG: Question classified as: 'general' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: general\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\n",
            "\n",
            "Question: Compare the clock skew between the worst and best slack paths\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'Compare the clock skew between the worst and best slack paths'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'Compare the clock skew between the worst and best slack paths'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: Compare the clock skew between the worst and best slack paths\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Top 2 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "\n",
            "Question: Show me the paths with really bad slack values\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'Show me the paths with really bad slack values'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'Show me the paths with really bad slack values'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'filtering'\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: All timing paths with details:\n",
            "1. Slack: 0.3252ns - Start: chip_core/housekeeping/_6778_ - End: chip_core/housekeeping/_6778_ - Group: hkspi_clk\n",
            "   Clock skew: 0.4998999999999967ns\n",
            "   Hold time requirement: 0.1002ns\n",
            "2. Slack: 0.6112ns - Start: chip_core/housekeeping/_6656_ - End: chip_core/housekeeping/_6654_ - Group: hkspi_clk\n",
            "   Clock skew: 0.4468000000000001ns\n",
            "   Hold time requirement: -0.0246ns\n",
            "\n",
            "Question: What's the correlation between clock skew and slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'What's the correlation between clock skew and slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'What's the correlation between clock skew and slack?'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'filtering' (clock skew)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Clock skew information for all paths:\n",
            "1. Path chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ - Clock skew: 0.4998999999999967ns - Slack: 0.3252ns\n",
            "2. Path chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ - Clock skew: 0.4468000000000001ns - Slack: 0.6112ns\n",
            "\n",
            "Question: Which paths are borderline failing?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'Which paths are borderline failing?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'Which paths are borderline failing?'\n",
            "DEBUG: Using fast pattern matching only...\n",
            "DEBUG: Pattern matched as 'filtering'\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: All timing paths with details:\n",
            "1. Slack: 0.3252ns - Start: chip_core/housekeeping/_6778_ - End: chip_core/housekeeping/_6778_ - Group: hkspi_clk\n",
            "   Clock skew: 0.4998999999999967ns\n",
            "   Hold time requirement: 0.1002ns\n",
            "2. Slack: 0.6112ns - Start: chip_core/housekeeping/_6656_ - End: chip_core/housekeeping/_6654_ - Group: hkspi_clk\n",
            "   Clock skew: 0.4468000000000001ns\n",
            "   Hold time requirement: -0.0246ns\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Classify the question type using FAST pattern matching only\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Skip LLM classification entirely - it's too slow!\n",
        "        print(\"DEBUG: Using fast pattern matching only...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Ranking patterns\n",
        "        if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "            return \"ranking\"\n",
        "        # Counting patterns\n",
        "        elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "            return \"counting\"\n",
        "        # Statistics patterns\n",
        "        elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "            return \"statistics\"\n",
        "        # Clock skew patterns\n",
        "        elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "            return \"filtering\"\n",
        "        # Hold time patterns\n",
        "        elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "            return \"filtering\"\n",
        "        # Filtering patterns\n",
        "        elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "            return \"filtering\"\n",
        "        # Navigation patterns\n",
        "        elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "            return \"navigation\"\n",
        "        else:\n",
        "            print(\"DEBUG: Pattern matched as 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "19d6845ed2e143c3b66c0706b52d3cb2",
            "5076ca236d164978a3da150637eba20d",
            "7ab465a6dc3b453c8fe2a6c7a37e16f8",
            "57cc26dc0b884f16af085d88df442984",
            "0425a8a6bcb547529502608c95c27060",
            "75baf60ac515444f8a491b51c46ef3ad",
            "0072536ff3fd4ecda7de0ff71349b8e1",
            "baa44427116e4f789ef61f0aaeec76a7",
            "db8fc5d08637491eb0a1862edc8cbc41",
            "0ec4879f78ad4030ad355052698133db",
            "9bf149682077465182b85fd87f23922d"
          ]
        },
        "id": "V0krqVG83kFt",
        "outputId": "069de7d5-3734-4438-9516-cdf51f8fe2c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19d6845ed2e143c3b66c0706b52d3cb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n",
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what is the worst path?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the worst path?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the worst path?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the worst path?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Top 2 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "\n",
            "Question: how many paths are there?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how many paths are there?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how many paths are there?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'counting'\n",
            "DEBUG: Question classified as: 'counting' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: counting\n",
            "DEBUG: Calling counting handler\n",
            "DEBUG: Using direct counting (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Total number of timing paths: 2\n",
            "\n",
            "Question: which paths are borderline failing?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'which paths are borderline failing?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'which paths are borderline failing?'\n",
            "DEBUG: Query complexity: complex\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "cannot access free variable 'question_lower' where it is not associated with a value in enclosing scope",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4061180763.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4061180763.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {answer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4061180763.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, question, top_k)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mclassify_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Classifying question...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mquestion_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0mclassify_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mclassify_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4061180763.py\u001b[0m in \u001b[0;36m_classify_question\u001b[0;34m(self, question, data)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# Ranking patterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion_lower\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"worst\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bottom\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"highest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lowest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Pattern matched as 'ranking'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"ranking\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4061180763.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# Ranking patterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion_lower\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"worst\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bottom\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"highest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lowest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Pattern matched as 'ranking'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"ranking\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: cannot access free variable 'question_lower' where it is not associated with a value in enclosing scope"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Ranking\n",
        "            \"how many\", \"total\", \"count\", \"number of\",             # Counting\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"borderline\", \"failing\", \"violation\", \"critical\",       # Interpretive\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",          # Recommendations\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "        ]\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "        # Ranking patterns\n",
        "        if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "            return \"ranking\"\n",
        "        # Counting patterns\n",
        "        elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "            return \"counting\"\n",
        "        # Statistics patterns\n",
        "        elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "            return \"statistics\"\n",
        "        # Clock skew patterns\n",
        "        elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "            return \"filtering\"\n",
        "        # Hold time patterns\n",
        "        elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "            return \"filtering\"\n",
        "        # Filtering patterns\n",
        "        elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "            return \"filtering\"\n",
        "        # Navigation patterns\n",
        "        elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "            print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "            return \"navigation\"\n",
        "        else:\n",
        "            print(\"DEBUG: Pattern matched as 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may contribute to timing issues)\\n\"\n",
        "                elif slack_values[i-1] < 0.5:\n",
        "                    context += f\"  Slack analysis: CRITICAL (timing violation)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: Adequate timing margin\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- Negative slack values indicate timing violations\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Hold time requirements help identify critical paths\\n\"\n",
        "        context += \"- Paths between housekeeping modules often show degradation\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364,
          "referenced_widgets": [
            "7e12a0bb9b8d494597b5edfe8a197524",
            "7e4eae7672864ffa8752daa1d8bb2b03",
            "94a3a90a469048f7a2519f6dc5a03339",
            "d9af2c59e2cd4132be70c579cb4eb87c",
            "2ff191213a1b490aaaf013ade48a38a1",
            "3046ddbe60724c8384c7da1d54134ce7",
            "329ac193ee214fcca82fa936f0693b80",
            "d6fbf61661f44b9087a15a8f7db47135",
            "e42864f0fe9f418e86c1b1e4ab804912",
            "9aae2bc1cd4540a69460ce54bb2fa63c",
            "52b55f718b6d49a4b59b7ec10f31aa3e"
          ]
        },
        "id": "51VW7B6e59xk",
        "outputId": "1a782587-c52b-4e40-b91f-2e63fd45332e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e12a0bb9b8d494597b5edfe8a197524",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n",
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Ranking\n",
        "            \"how many\", \"total\", \"count\", \"number of\",             # Counting\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"borderline\", \"failing\", \"violation\", \"critical\",       # Interpretive\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",          # Recommendations\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "        ]\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may contribute to timing issues)\\n\"\n",
        "                elif slack_values[i-1] < 0.5:\n",
        "                    context += f\"  Slack analysis: CRITICAL (timing violation)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: Adequate timing margin\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- Negative slack values indicate timing violations\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Hold time requirements help identify critical paths\\n\"\n",
        "        context += \"- Paths between housekeeping modules often show degradation\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9488384bf67948c2a9670ec586787b9a",
            "399513d2399143958f03a1f9628c0e0f",
            "688c9f0efae94ee29e57dd29e86cc1d6",
            "c4fc6d88e77c4a35b58e1f75629aee30",
            "7f8447f023fd4da1afdcca72f590bc0a",
            "1e732b94e8354f94b7b9ed5b0e3f5ba0",
            "c677ac8c37cc4b16840063accfb8a1bc",
            "83c95f06cd834517b51e463735e70481",
            "9d8539bacda0431a88034e1e321b6ecf",
            "a846c2e7b4894fc28513117fc9fb5fe2",
            "7ef8e967a56d41b0bed16f6be231d62e",
            "87d943c837c2412cbdef9d39625411e6",
            "58a290facd204df3b8cbb6d2d3fd6457",
            "af82c5fc79ad40e6972d33aa75f4d54a",
            "e902067b2be445ebab16abbad4732a92",
            "59be65899ba347dc9142115b4b67eb77",
            "6b062987e1e340e8af1c3e7805bc68fc",
            "7f35caf43b1f48f0a2c02ff7af6cbeba",
            "283a54a4e1634b5ead12e07d527bf858",
            "dca7b3b217d04a33901475132fdd62c8",
            "cbd68b865b9c45b0be066ec544d4609b",
            "a20276f34e05456fb077e47900d9e327",
            "595ab24928984f4f874c55e9b382a7a1",
            "907998058c394d3a968da216b1b2cb5c",
            "a82f857182724e48a22a7f5ac84ce5e0",
            "1f14d3de34c94d16876a493a7fd4954f",
            "e2ce4a6220ad49c1811d39cc281c6ef2",
            "e6a4d0c7c2c54b74be80002d81590e48",
            "dec0127e01e54096b2c0b8395e990c02",
            "f0dce412e798474c9ea469ee08020ec5",
            "06d930e8a1a54df4b826ce1826dfde28",
            "9f7e8db5838d4ae3acbdecf6b11b73dc",
            "c22c4f099ac74ac69bf008afd04a79fc",
            "20978600309b476ea6b765a4e33799c4",
            "523c8942435f4fd18956b71bf7740a0f",
            "b9801b6340234966a72feb10c92c870d",
            "0a30e530d8d04ff592d4d6aa63d69ab9",
            "c514798d2df14f35bb06fe4666152883",
            "fd88aa6c3b124896a02624637ab35161",
            "b66de9ddfb5442048432e976a8aba8d9",
            "d5b7bafe241b4cf281c2c503745462de",
            "89d745d00ff84f3fa59a24a2f0a424d1",
            "07dfea43f10145e0b44cc0dd9c8cb422",
            "d5888a15e0a549c39235a4a271ecfaf9",
            "218c14ff046b4f158d95bc74db198b8a",
            "2e1197b4df64475a8d0d40c0943f5430",
            "54ac3a0b746c4e7ca030569ae4e876a9",
            "9e226eeb21d44f6783df0bf237fe2ad0",
            "2c00abccd45d448582cf54e121d18468",
            "fb4b3045806446cd94141b5336d62bda",
            "225e96f289754ff4bc6e40b794401060",
            "a27f830e5e754451956fd907b2356114",
            "3c6c26093b0749d3b70f67680871fe91",
            "8aa68c701e2e497e8f4ddc005bbc02dc",
            "cd36f89ac1964d2faacacbcb4c46a1cf",
            "1175e59d19cc42ab84f1f649d5b407e0",
            "00e57cda7d954cba9013ecb19821f991",
            "29e5c4cc583a49fe926a5351431c56d0",
            "6d180428907442e095a1654b7d27b4b0",
            "2e8a802dc1ff4440aade769460aed8ca",
            "f6e869838c304085a4623f3f741b0f09",
            "76472b9a721140368a530273bf6c0dc9",
            "6beea24e3ec9466b9c4a7a6f3f672900",
            "a611633fb50d4a5cbc3bed1e2277cbd4",
            "0f78ca3482264d97a075e7273f908242",
            "762969cd2c4646b89b7b05eae1e30cf6",
            "74542d3c007648008320bd55e9dece00",
            "a54ceeac73b2405683e2b141dd5d36ba",
            "c9a08804863742ef897e7f995e22feed",
            "7ce9a9f267ee4ee3a76f8f45b0201ab2",
            "a4cc2a9d3f1c47d8bb9ac961ea25aaa4",
            "9eda247c525341e09534c201b76480a9",
            "b3c4f06774f94b038da571d3305e923c",
            "cdaf4f84ad1a410eb9810e6fd2ec0c2d",
            "f7d59dd85f764e6aa69efb449e840448",
            "6f46030f8e2b4783abeca5f6be6cc69e",
            "3a91b1b5b45e412eb57439eddce5b6dc",
            "470bdb34970940d89bc06aba6e8b5f8b",
            "ef0ced69039b4a22b6c7293b40f4abe0",
            "8f356c5f092e4882b67fa217ed8c7e0b",
            "c6a2e62e55464d109ab15b59739945f4",
            "b2c66b1721a44b82ac642d0484cb5b1d",
            "2953e4dbffcf4c359a301f0c20b7c9bd",
            "66fae20cb5fe443bb3fc67f501b3a833",
            "22729dea76084b1a8e4081a53f72df91",
            "49539475661e421cb73c7cf4e8e79c6a",
            "fc01ba8433b94bc7ae9253c53976061d",
            "3dad8eb5f7784207a9c371b7252cc820",
            "650a6da4aa814adda0d20d64da66e7d7",
            "c38d850a979b4697967517f24b2c117c",
            "b1eb6b4938c84498814d5989141de7c3",
            "67396f894c5541d89e938f640a24cc02",
            "3544eb4f2e244bb2976adb26694d9544",
            "f9e7765331864ab1bfca3052b49ce653",
            "e8c249f3c1e547ac97cc070dc8ba7090",
            "f5282d896f8247bdaeadc39b049387bb",
            "adab5bd60804478789c48e6354155064",
            "a5c96d0ecee24e9dbd5ee8214130496d",
            "14005756676843ac8405d38e078b169f",
            "cc59958e762340638ed6dd165abacbfa",
            "f622bbb32d324712b55f5ff913edc68e",
            "9614fb1eb86644269802498db026a191",
            "a0f261d9d7dc4696a3797b8f64450019",
            "f909ddad8f204206ad830ebcb1b4cf3f",
            "dafb046befc2424a9c6b3d18b002099c",
            "9ea11c066c454c3f9e3dc145cd1db969",
            "4e8a17077f464ae890236a0985b17d0a",
            "28ea88de83bc4973ba23fb0c1c3c3ded",
            "8211fd05644d4b16af73b5a175570f64",
            "c35647a002cf45609356d7114f20034f",
            "c316d87f5d3745489b4b52887f695a6c",
            "89a1446c35ae422b8fcb095307d1145d",
            "50efa3a93c474ce2b6d077f899b1bf2b",
            "8d8b709b6cb847f7817ecdd3db63cae1",
            "a4d48093f53244898b12f1790a268041",
            "18b792e3313744389effe6f0abfb8a1f",
            "8916cab077c940cab463ce2584d2af2d",
            "960ed08742294f0c86b7cb4bdc84cac3",
            "ddb00c765dc2458bb8441f0076c2b6b9",
            "663a136650014618999dd0850ebce86f",
            "07da8bb58adf4b45bb8272fa49ac5fa1",
            "7e7b7fba04384ba491431b73fe4ad578",
            "95536468b3f0493bb41add69fbfce20c",
            "2218a1ab3d4746f1aee860dc28736e40",
            "1a6e96b498a9469fbfff24aff4be7210",
            "bbef7a3eba2f4b9da001ba9ed20d3fd2",
            "7fef97d46d614d868575b068f4419191",
            "7e45b7d0619b4d72ae23d4fa875c59f5",
            "c7297a2a112c4669a4e6c0b4c09eadd5",
            "0b69456c949446008576495a6e5a50ab",
            "30e781ba326a4cc2ac7ab90a760b5781",
            "7ff4a524f9394f799877985188686c0d",
            "574c3a381e564e96bbe31bc802db9fef",
            "62c32a7f46dc4127a89884287f990973",
            "9f01be8c1c754841a7ac8413ec33ca4d",
            "908394de664a40fcb75ef67518af901e",
            "9f02c626e14341bfae840dec5f606c7f",
            "195f14728bfe4bde98df406ebd58c2a8",
            "312faa5d21274016b6661c8eec9e3ebc",
            "ef02eccba38b44d291b6aaddb154c31c",
            "9a66f1e36cb44883918363d338c73a38",
            "6eb210f2c3dc43c89c89c959fd90038d",
            "0e79192245444dcbafa8eef76329613d",
            "3f6aaacb9961458ba6e3a12cd35c659c",
            "21d2d52c79ab47deb0feb79c7bbf212b",
            "4869195465f2442699d4919afb741487",
            "347a6e13bdf34635ab382a60a2f6b576",
            "b2c92180be0f439bb602f279b27f9fe2",
            "67556a4e4c6d4d879a826fd7a7ea3776",
            "65fc61c20c5649d6ae94f9d0b50fb2fa",
            "933c26c05bec46d79833d49d2df75bcf",
            "3773be4816d6405f804bc35449a7fb51",
            "63bc2f90b24f4e519c46a6af86ae3337",
            "f2c83afc96c040b5a06e32172fa5c619",
            "ce2db56f31914f2ca3665deef27691a9",
            "d7c0867cbe774034b864ca03ea36db43",
            "df588496885341f99b8c6ef5d34d3615",
            "b0fc237cf73d41649aaad595caa77afc",
            "dfe165554d37431fb905c422795b0e7b",
            "dc11e6e2d7ca45e89acf110a5e8b2b51",
            "ea5dc8d06be042d99123fe29135cc458",
            "cadff53568fd416a8192f5fec395a154",
            "066e6598660645378c3939d3d2841f18",
            "f606184b714e4637bdb7c2be84a99540",
            "64853c976d0345a5a66ec8a615ff7cb6",
            "45e9950e3ac4418795a2b748a957c517",
            "5287de44b8b54af8a56fecc63687ec63",
            "a218a6064fc84c7e85fd72a4ec1d0f9b",
            "66b11835308947b8a5f80e44fb4c62ad",
            "ea029b5137e84350ba46446599c515f2",
            "944c18536cc9460e992a663ca5a7fe0c",
            "1f67677176da4de49517f82137f2ca09",
            "b0715facc91d46d4bd8425cb5e85f180",
            "73c3a185b51041898b14dad342b396ca",
            "a82e3ac5189b450380ca453d179ae249",
            "e5ce2131a15640ebbbebb59af50be5f7",
            "bf26e383bfce47cb83724b91c1e4d515",
            "a3a52d5fe3324b24b41984a39eda9981",
            "0116f19ff33f43a28b1a52556fcc0574",
            "836e9cadc9134dcb984085cf6f2aad89",
            "69dc4490371d4b07bc46418a6df42559",
            "ca11caa2866c4498a183378a6d0e0b27",
            "b427eb8ab5d04b46878ced6f9177f3c7",
            "6a300e51e94b4190a944854cc3fe0dde",
            "3df110d821d245a4b8674cf7fbebb310",
            "65b17955bc594e73911afe8f4a50d62c",
            "6d1190e3ab6e478985839d47a0f211a7",
            "29a527cf27ef483ea81ddf7aee7092a8",
            "97eb4648fae04213ab41d97a5fd97d1f",
            "d5f2ac09302a4cf4b9f8c1b8a27ff553",
            "ab00268816b040d5b17b2f7727317f33",
            "111448fcca994e6c965e79de5c86f191",
            "56c444637c4e4adc9ce25f14ab356b97",
            "6f2a93f8310b42a0953deac752327f76",
            "7e390a4a7e9f444e80ce7f7bd8bfa7c5",
            "0a6f1cbcb4ff41908ee1b9558e5fabe8",
            "80336a35e8b34d5ca43005314b7f8f0a",
            "f0a93c75544841df8a44bbbb65308f09",
            "61608a496a07479abeb5e4d0cbb37b8c",
            "1cd10969f46b47309a70809d20b9aeed",
            "7c95503eaacb4822831de884d58e5d4f",
            "3f3b71aa26574b0389b972013f2d9bff",
            "ac757f21d8dd44bd9cdd3104ae5516ae",
            "fdadd988c345471b9328e946052c7050",
            "5078f8e91520424dbc088c9a21281dd3",
            "6cb4c935e02a45a886061e86524e19f6",
            "55850c6dfd554b9b89cf7bd65663212d",
            "05b1d21677de42548ad430d2e5e956ca",
            "b36dcdd6783f465baeff85801392e250",
            "a2dafb59428e4e83868b98e8a5f2889a",
            "f0996c9bfc8c4ff8aee1731e4d8df14c",
            "9cb139db06744566ab0117c203410779",
            "a269825541dc4c198a420cdef61f30f7",
            "ee6126e14e474bd0811f46fd7ba20ac8",
            "66dbc1edfc2048d399462886420de59f",
            "4329b9c9355143de9aefda5ff3442339",
            "8da366a6e93d492985fd79ccf56a4bec",
            "fe41ec0ba2c744cda207131bff468694",
            "9562d2e0fa054e75ab9bdc654e5a98fa",
            "8f65f914e8334809b66008d8bf28724a",
            "acb8d65a4e17487392e300d160ac2f3e",
            "ac1efbae7d4d49799e363b49cf72828c",
            "79dd93f3e6824121a2996368413ce540",
            "f9046efb742444a994c5085da40e9e82",
            "fb0d14ec849441c6adef6bd20a9a0116",
            "8b96ad475f15422989be6b1af92974ef",
            "9ec23ac822dd40bbbc87aba60d0765db",
            "7e9fb025e113438884f0edc4a8fac845",
            "390db3d08ceb49fdb0ae2084f6ca8ec9",
            "4bc5b70a7bf8441fbcab42d464ce5113",
            "196429f9ea73463cb22321b827fef7dc",
            "7cb451f16a3243a2a6d4f57c0c7908df",
            "7d13f6764bf343bea7d6ff1d2e1b4dcf",
            "5e2d4634930147939df1e200189823df",
            "2d504c24293f4db3a239cf6fa4b06d52",
            "3b7c506254cf4055871f9c05e64a049e",
            "fffd1b1b97564479a3600e524ed97e90",
            "5c2938c29bd94735a6a8c88afcdd9f6c",
            "05edf76d9a424e0f9d6abcc368dae91f",
            "731cf3819ec742a59d7eebb40e641429",
            "365c751ecfb94b67847d1dcc4a3ad582",
            "0604455104ba4e97a816f0c2f0324229",
            "a24ca1cd569c4c11a98e138ce756ebb8",
            "b7e88840efb94b38a51ebbfe9a8c9df8",
            "f51d94fe01ba47a08b9df8b64c3f0639",
            "08ec5ea1fa0d414ab4ac46ac5d5a5de4",
            "91577fcae4184dfe9ac578ebfe164316",
            "615a33c7c711486e804b177b217a34aa",
            "e024a851ebf24c3e9d148e61172db385",
            "9721d6dfab9d42b8bff850e36961f22b",
            "e747b944c0714a3ca8395e15dc9aacbc",
            "89bb26f685044d6ba6ab09369c2d915a",
            "c8a97cf4fd0949f0bdc8c5f99bc1a814",
            "3a3087d770354696985569b8c6fcb3db",
            "a8d77cc90ae14019a41746fa75dd4d17",
            "60bb4daed0ee4e90b741c43619429087",
            "9d40cb1b2664451d8a6d00035918381e",
            "9a1b17557b5d49bb9f029fd598a404ce",
            "8aade0326d344d029813b5fe6f4fca3b",
            "fbe093f574044ca5a9bb0d8bd9ac0351",
            "1577df45e53e4f9fb55ad515fef3ddd1",
            "d69bba33938b4cd8b124f0cea77541b1",
            "e2cde23aa6134265a0986cebde88c68a",
            "0e94ce04526c4da38051b66bee51634c",
            "bf7d7fe25a2c455d89c4c9e3ac0409c7",
            "c2f2d0b6ce86439294dfef13956577bc",
            "5e4ceba4a07e4dafb7a2dc2acb778111",
            "58c81480ec6649e2aa7bce960ae64c51",
            "db8e8f5ac9cd4a1c81b0f72943ad2961",
            "d71d15a2a16d4db5b933ab2b3c49435b",
            "263331e29a024113bb53ffb9d6237368",
            "c65ea55165de4adea3939adae385acca",
            "032e3682bfe9460d86e7cf6809529176",
            "8c3dfe8015634ee9a65e32fe9a18da12",
            "c8e0ce97446a44eca1b6f7bb7804187a",
            "4f8378019748425fa002d77f1d4fc9ef",
            "e669c01427514e428e99cfcd8791d657",
            "f949115e02674a5b9b2b42ba117bc00e",
            "9a341371b2cc4686883010155592712b",
            "8ec2f7993da54eb4a9e7391c1795f357",
            "0f1caa4f54f44f40b4b3033718629a05",
            "9bf58fb4838148ef841e617234487182",
            "06ef8a823951486fbfab571c64ad8a8c",
            "511d824e50b64f1f947f0c8536487f04",
            "cf35f3e76f7a4e7ebb41836a58839a1e",
            "da39fc9483cd4005b7645a43c1f601f6",
            "527bffe660d94ed988c3641435a6a255",
            "1de6ca23a8e7419e99c8d058e44d6fa4",
            "9bd882b92f1a48988e733ee91d64f8c0",
            "5999613a44e0411aa5d0f8645c4e0a73",
            "656fed84483f4d9a8f2406df250a0a0e",
            "fe0b23b3c21d4950a0e8df9ac6731d4d",
            "41d761ed5d454d7ab913df8be5c3c882",
            "8533caf3523a42f3bdcf434882fb8977",
            "474b6ed46e2b477497257702c1ca3801",
            "23b547017c6342a38c95b2f305521ec7",
            "8fd950ed089f499fa9238b2c8dbe3000",
            "9a60254eca3248b5ac66ef9869c93431",
            "84f61bc3cfb940f78ef7dffbb068f3d4",
            "8fb4f62bffc941af8c2fe4bf44b03379",
            "9f6964a7796f41abbd299e66207faef8",
            "40416307e5004aecae064b6ac9af2a37",
            "761e3c97bcca447496efd906754360e9",
            "b8dd59450c77480b917c0c886182f5dc",
            "d073040d10694ed49276313135ab9d7a",
            "3ee8296a86f74949bd667ab4657d8b72",
            "8f16d510c2544051bdc807ad850d3e85",
            "df1b98b2ce36481a82ee632e05d1ba87",
            "14051861f2964cac90b6e14652858364",
            "b867043fbae34d4da23ab9c35453b559",
            "d9c8dfec2ce448cabcfff69a393e3b92",
            "1a9653731d094d0e8ebc29f389756dd1",
            "b994063c34354e1991314c955c5ea499",
            "ff395e16d9114575ab36ae6302f2b8d2",
            "00e5fdeec82b4b99963329f0899ae511",
            "5e103bd5ce7a4a01a0cae9f49a6a24af",
            "7a3618cd87a74dc6b8b791b9b6f324ba",
            "bd8545261a93447d855d6c8dde545dad",
            "11c1568b03a74bb88779f2f9a783a5bb",
            "97d5efa75ab9412e90387c7fa2e2a03a",
            "2ba57ddb56f04301bfc45b73f70f1335",
            "4ac27f54421d4730ab0c2f139eaacd5c",
            "685b1c66e7904c5aa35237270363ccec",
            "db38d6004098448d94f6a02e3b59a670",
            "5177550e5f944d1a9de83364cba894a0",
            "1cc3383096594b54bfa180a8f499b274",
            "42151894c52c416dae00e8f1f8cecf5a",
            "a4f636e0348e4b4b87f4f454d994a8fd",
            "06b75cd6798543f9b9ae91fa881c6111",
            "d6765c0c71754f139e6ab99bf4f779b3",
            "efb6a0b7346c403ba42a84d92a9d16e3",
            "38d8119e862d4642823b84553fc8ac67",
            "d0247626449946978fba8feb81052ca6",
            "66c475c2b5384bf7b573c65a2b58464f",
            "a6fc099e97af4420abaecea8b7997c2e",
            "6e55d9d9c27d47a7930b996473fc6e2d",
            "7d3c3b666e4d42e0826aeaecbf604197",
            "45875b031b044710a0f7e9532033dc40",
            "6bc37ed1cb53427dac681e7763fb9ffd",
            "002e26124ac54442a5d1f99379cf5fc8",
            "fe10aa0808b74b2297d5c23606bf4676",
            "a83c3f6fa11d460ca3d1352edcca5741",
            "e773cb0be4d7481b99f4bc1d806c2190",
            "569e08a7b6644cf19fb076b504ad56d2",
            "2e306f6e1a4d4564945f276c7a850f55",
            "8d92e6bd9ab04c549b59851fab2d9920",
            "890ef333e80140568fbaf6ddaf30f50d",
            "3f7e107e2b1e474480989bdbde7e431b",
            "3fb431ed4a10403c9300bbce14ed9e7b",
            "7d561285cb8a427988ceca99d932650e",
            "d03ebc36f32540538770715e7edc0828",
            "06a89b3989094cc492caeddbcd8d6bf6",
            "d54fab8a2609469590715024d1fe7b3e",
            "4185b71614e945dc8bf524b160bd10fa",
            "e8bd356bdd604c40b98bbf420ab26264",
            "27f7a761766a45bf88e5a4b5112fa4ae",
            "1774b3b2a43a4e70a1472a6f982df625",
            "20d67a27ae2145b89b311190e25122ef",
            "6cc0cfbf8d4841cea3d39d7c5ab3c93a",
            "b259069439724a43a22052563e503534",
            "8dc7025e871c4c1f85424896e6054015",
            "e677ce983d624825907556fec239aeac",
            "3c1fb029bb8245cea2f95b9acb34bf88",
            "843e055eb2dd497387801623a769eaaf",
            "2888991785d84433950702ad287ee691",
            "db01ae3488b74fbf9e6b4abca0d3d59c",
            "c3a89fdea1374ca689e9edb88026ed48",
            "606337b912264bb7ba7cc2e822af74c3",
            "1722feda370a4afab8a081786b26a889",
            "d307bfcb2e6e4fce8cbaeaa688c84840",
            "c87e04b1fab34a5da4dce96ac8595c1c",
            "291d9eba2f3b459ca7cf583b91092d0d",
            "2dc4498e482f4e8fab1f860df6e89bbc",
            "27ca669e00cd490d96938b1448013b17",
            "a92ef27afbdd4d2c88f8c68f7c1756e1",
            "a73edc477d4b47b7995b3afac43fcd6c",
            "58e94c3caf9f4f14b7d6d5838e033f96",
            "96488210acde43e6a30928e94897e627",
            "9e83d80b293a410f85fc6ce6a6c265c8",
            "6cab9909670e4163a52a63b7b9275be1",
            "d6df8f42799e438a9fb18a29d5862a9a",
            "6ce58e2d9e014944b6a280c9d696ded0",
            "d73589d0a22243debbc3950e59a9867b",
            "3e518e2430e842e98a3c54d5960eefe1",
            "e1b4036b291a4a3b9ad9f110ebf03946",
            "eb4112735c3e4222828e401ace44730d",
            "8c4fe33b3d394774b95cacad4fafc474",
            "7fb59f7d333f4ec88d444021b3534fd1",
            "4ef56ac0025544a4aef80e3aac82aca1",
            "b6fbf4cb4b974065a1b89595e80e2593",
            "2da999512828443b9acd1dcfa4119c84",
            "975b339d5f5b4949bcaf04325baadb8f",
            "464b32269e0c4a40a56ea223c6c18e53",
            "e69ee0ea123143f18a60ab620703ffea",
            "e70f60edda7f43c7adce2e16f9f46521",
            "d4bdb1c3fa43458882821c2cc4b90fcb",
            "49ad2dcf668a409ca6516bec6b5605ff",
            "ec5ec4e6c8904fcbbafcdf9dcc46db77",
            "1cc67fb9698d4082b503b46525650f02",
            "566443bd974d499393f6f0515ec38f22",
            "d3baa763413a4b6eb90b0299af7d2b59",
            "6d84ceee84d9462699aa90d7d1a81eec",
            "e8efa08a51e34f4cb010e5dcc5ce1f3c",
            "421f2f1b64b84aefadbc3c68d072f600",
            "37cc571e9e504f059fe50d5c2396a4b2",
            "83364bc38a694466bc5e03140cfaaf38",
            "10964dce0fc141f1b27b582fdab2c9b6",
            "8a4be78da4e3413bbcd0e4645f9b4213",
            "6caf554a27e344048b1ba4eeb9e554cb",
            "af551d32608b494885650d16479ec4bf",
            "576d552a4dac4aa187c82a848318bfa5",
            "437df8da1c0e4fb692a94fb4451fe8b3",
            "34069299114d471d95ec180b2844fd9a",
            "95c9d707b0374ba593461152e90d1660",
            "c546d23e4e8248d2b7fae7063bb43c38",
            "90eee82806684434ab5afbe3f57388bd",
            "9a6277dd7972411aa5c005a6238d67a3",
            "68d88b90a9cf490c91322fd13173a384",
            "c180f1d76ab44f5489282f878aea8551",
            "335d74b3e67a4fa0839423332d9a3e00",
            "87323ba357e3416aa83b710fc972f236",
            "06471650c03440e7bb8701cde0971a6f",
            "620e046c29d74b9ea554b47072d75307",
            "149e1e8208f1482e9d5acafbe1d37288",
            "8847c23d1bc442e1a06d6dd55de758c9",
            "7844052c70894ab9927923f632829f1e",
            "c3293a821ec94b0f8650455b324aa3cb",
            "c7b10637086547ef8df4a085e227c004",
            "03fd23b543574db59244e3e01d5dfb30"
          ]
        },
        "id": "U0KsbKvq7Hfp",
        "outputId": "92580dd2-3f3b-4f65-84a2-0255c0e3a40c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9488384bf67948c2a9670ec586787b9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading .gitattributes: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87d943c837c2412cbdef9d39625411e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "595ab24928984f4f874c55e9b382a7a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20978600309b476ea6b765a4e33799c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "218c14ff046b4f158d95bc74db198b8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1175e59d19cc42ab84f1f649d5b407e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74542d3c007648008320bd55e9dece00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "470bdb34970940d89bc06aba6e8b5f8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "650a6da4aa814adda0d20d64da66e7d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O1.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc59958e762340638ed6dd165abacbfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O2.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c316d87f5d3745489b4b52887f695a6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O3.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e7b7fba04384ba491431b73fe4ad578",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O4.onnx:   0%|          | 0.00/45.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "574c3a381e564e96bbe31bc802db9fef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f6aaacb9961458ba6e3a12cd35c659c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)el_qint8_avx512.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce2db56f31914f2ca3665deef27691a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nt8_avx512_vnni.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45e9950e3ac4418795a2b748a957c517",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_quint8_avx2.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf26e383bfce47cb83724b91c1e4d515",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading openvino_model.bin:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29a527cf27ef483ea81ddf7aee7092a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading openvino_model.xml: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61608a496a07479abeb5e4d0cbb37b8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_qint8_quantized.bin:   0%|          | 0.00/22.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2dafb59428e4e83868b98e8a5f2889a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_qint8_quantized.xml: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acb8d65a4e17487392e300d160ac2f3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cb451f16a3243a2a6d4f57c0c7908df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a24ca1cd569c4c11a98e138ce756ebb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a3087d770354696985569b8c6fcb3db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf7d7fe25a2c455d89c4c9e3ac0409c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f8378019748425fa002d77f1d4fc9ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading train_script.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "527bffe660d94ed988c3641435a6a255",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a60254eca3248b5ac66ef9869c93431",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14051861f2964cac90b6e14652858364",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97d5efa75ab9412e90387c7fa2e2a03a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efb6a0b7346c403ba42a84d92a9d16e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a83c3f6fa11d460ca3d1352edcca5741",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d54fab8a2609469590715024d1fe7b3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/646 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "843e055eb2dd497387801623a769eaaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)fetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a92ef27afbdd4d2c88f8c68f7c1756e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb4112735c3e4222828e401ace44730d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49ad2dcf668a409ca6516bec6b5605ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a4be78da4e3413bbcd0e4645f9b4213",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c180f1d76ab44f5489282f878aea8551",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'which paths are borderline failing?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'which paths are borderline failing?'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'which paths are borderline failing?', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 459])\n",
            "DEBUG: Starting LLM generation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 380\n",
            "DEBUG: Handler completed in 8.95s, total query time: 8.95s\n",
            "Answer: Based on the timing data provided, the analysis suggests that Path 1 has a negative slack value of 0.325ns, which means that it is borderline failing. This indicates that the path is experiencing a timing violation, and the slack value is close to the minimum slack value of 0.325ns.\n",
            "\n",
            "The analysis also suggests that Clock skew > 0.4ns typically impacts timing margin, and in this\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'show clock skew for all paths'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'show clock skew for all paths'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'filtering' (clock skew)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Clock skew information for all paths:\n",
            "1. Path chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ - Clock skew: 0.4998999999999967ns - Slack: 0.3252ns\n",
            "2. Path chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ - Clock skew: 0.4468000000000001ns - Slack: 0.6112ns\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'why is this path failing?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'why is this path failing?'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'why is this path failing?', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 458])\n",
            "DEBUG: Starting LLM generation...\n",
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 410\n",
            "DEBUG: Handler completed in 6.16s, total query time: 6.16s\n",
            "Answer: The path is failing due to high clock skew, which is a measure of the difference in the time it takes for signals to arrive at different clock edges. In this case, the clock skew between the two housekeeping modules is higher than the maximum allowable value of 0.4ns, which is causing the slack values to be negative. This is a timing violation and is likely impacting the overall timing margin of the design.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'which paths are failing?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'which paths are failing?'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'which paths are failing?', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 457])\n",
            "DEBUG: Starting LLM generation...\n",
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 392\n",
            "DEBUG: Handler completed in 6.80s, total query time: 6.80s\n",
            "Answer: Based on the timing analysis data provided, the following paths are failing:\n",
            "\n",
            "* Path 1: The slack value of -0.3252ns indicates a timing violation, and the clock skew analysis indicates that this path may contribute to timing issues.\n",
            "* Path 2: The slack value of -0.6112ns also indicates a timing violation, and the clock skew analysis indicates that this path may contribute to timing issues.\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Ranking\n",
        "            \"how many\", \"total\", \"count\", \"number of\",             # Counting\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"borderline\", \"failing\", \"violation\", \"critical\",       # Interpretive\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",          # Recommendations\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "        ]\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may contribute to timing issues)\\n\"\n",
        "                elif slack_values[i-1] < 0.5:\n",
        "                    context += f\"  Slack analysis: CRITICAL (timing violation)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: Adequate timing margin\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- Negative slack values indicate timing violations\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Hold time requirements help identify critical paths\\n\"\n",
        "        context += \"- Paths between housekeeping modules often show degradation\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8ac91f09e4754e83848a8e2040b3798d",
            "c4dc0bb1a1d44787813c62a579ef8245",
            "807409b68b3a4350947653b9b5c9ed71",
            "36d464130f7041c4ba782827c5b2824b",
            "1a48c5bc740a4c4bbe795deb33484e37",
            "8b0b6e16f8dc495baf746059b062b936",
            "03a251947a3f4262b8df2d00e4a9bb36",
            "6664aca9bc8443ec8c7425541ba2c72a",
            "c3ced9cf432d4e6cb76863a7b78b645f",
            "b2e2e7f982e94087953e68244df6ca91",
            "407ed72b494348b59d344756ca13c364"
          ]
        },
        "id": "0qLbhxktWnNF",
        "outputId": "283eaedf-ef10-403e-b924-11a3de9cdfc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ac91f09e4754e83848a8e2040b3798d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n",
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what is the reason for worst slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the reason for worst slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the reason for worst slack?'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'what is the reason for worst slack?', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 534])\n",
            "DEBUG: Starting LLM generation...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1877559912.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1877559912.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {answer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1877559912.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, question, top_k)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"complex\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Calling complex query handler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_complex_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquestion_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"navigation\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Calling navigation handler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1877559912.py\u001b[0m in \u001b[0;36m_handle_complex_query\u001b[0;34m(self, question, all_slack_data)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Use the LLM for complex analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_comprehensive_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_slack_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1877559912.py\u001b[0m in \u001b[0;36m_generate_llm_response\u001b[0;34m(self, question, context)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Starting LLM generation...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m                 outputs = self.llm_model.generate(\n\u001b[0m\u001b[1;32m    727\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2802\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mfp16_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SCB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 set_module_tensor_to_device(\n\u001b[0;32m--> 287\u001b[0;31m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16_statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{self.prefix}{key}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"safetensors_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Ranking\n",
        "            \"how many\", \"total\", \"count\", \"number of\",             # Counting\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Simple timing status patterns (can be handled fast)\n",
        "        timing_status_patterns = [\n",
        "            \"failing\", \"violation\", \"fail\", \"failed\",            # Timing status\n",
        "            \"passing\", \"pass\", \"passed\",                          # Timing status\n",
        "            \"critical\", \"borderline\"                             # Timing status\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",          # Recommendations\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "        ]\n",
        "\n",
        "        # Check for simple timing status patterns first\n",
        "        for pattern in timing_status_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Timing status patterns\n",
        "            elif any(word in question_lower for word in [\"failing\", \"violation\", \"crash\", \"crash\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (timing status)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for timing status queries first\n",
        "        if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "            failing_paths = []\n",
        "            passing_paths = []\n",
        "\n",
        "            for path in all_slack_data:\n",
        "                slack = path['slack']\n",
        "                if slack < 0:\n",
        "                    failing_paths.append(path)\n",
        "                else:\n",
        "                    passing_paths.append(path)\n",
        "\n",
        "            results = []\n",
        "            if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\"]):\n",
        "                if failing_paths:\n",
        "                    results.append(\"🔴 FAILING PATHS (Negative Slack = Timing Violation):\")\n",
        "                    for path in failing_paths:\n",
        "                        results.append(f\"  📍 {path['startpoint']} → {path['endpoint']}: Slack={path['slack']:.3f}ns [VIOLATION]\")\n",
        "                else:\n",
        "                    results.append(\"✅ GOOD NEWS: NO FAILING PATHS!\")\n",
        "                    results.append(\"All paths have positive slack values (timing passes)\")\n",
        "                    results.append(f\"📊 Summary: {len(passing_paths)} paths PASS timing\")\n",
        "\n",
        "            elif any(word in question_lower for word in [\"passing\", \"pass\", \"critica\"]):\n",
        "                critical_count = sum(1 for p in passing_paths if 0 <= p['slack'] < 0.1)\n",
        "                results.append(f\"🟢 TIMING STATUS SUMMARY:\")\n",
        "                results.append(f\"  📈 PASSING PATHS: {len(passing_paths)} paths\")\n",
        "                results.append(f\"  📈 FAILING PATHS: {len(failing_paths)} paths\")\n",
        "                results.append(f\"  ⚠️ CRITICAL PATHS: {critical_count} paths with <0.1ns margin\")\n",
        "\n",
        "            return \"\\n\".join(results) if results else \"No timing status data available\"\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] You are a timing analysis assistant. Based on the timing data provided, answer the user's question clearly and concisely.\n",
        "\n",
        "Timing Data Context:\n",
        "{context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Provide a clear, technical answer about the timing analysis: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=100,  # Reduced for faster response\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True  # Stop early if EOS token is generated\n",
        "                )\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return \"Error generating response with LLM.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                current_slack = slack_values[i-1]\n",
        "                if current_slack < 0:\n",
        "                    context += f\"  Slack analysis: TIMING FAILURE (negative slack = violation)\\n\"\n",
        "                elif current_slack < 0.1:\n",
        "                    context += f\"  Slack analysis: CRITICAL (very small positive margin)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: TIMING PASS (adequate positive margin)\\n\"\n",
        "\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may impact timing margin)\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- POSITIVE slack = timing PASS (data arrives before required time)\\n\"\n",
        "        context += \"- NEGATIVE slack = timing FAILURE (violation)\\n\"\n",
        "        context += \"- Slack < 0.1ns = critical margin (close to violation)\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Current data shows ONLY positive slacks (all paths PASS)\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03e347bcf70e45c3adf783ffd241684f",
            "0d0d1ba150d941e39407ec3c40fb8947",
            "723a7558456f44fdb00ea74d265567d3",
            "e528d567434e4b3e91b31419d26bcee7",
            "abd76b7b03584a628469aaa052e93adf",
            "63f64032a2af4837b7f1b1aca98ab3c8",
            "ad7aa71e881b4cd8bc07301ead088a35",
            "1dfd570945fc48b8b85d9ca720d5d20e",
            "4b9b80df084f47dea44be7097d146273",
            "f900545332374c6dbf6ed32d20804b99",
            "168c22fcfcfc4cf984d95263553aa3a6",
            "6c7073bfe32f43678e2d4ea5e638567a",
            "4cc007c436c248debe965da1a2f84cde",
            "543469ef680f406497315759786b2be1",
            "b3d35c8a9dcd4d82a8f7be8913438d6c",
            "e58aa02aba6e4cf593d24b09171a2507",
            "d592f659a3b94b688003f960f4ffe312",
            "ced1d4ae254140b6a72f8daf74552443",
            "59887a48564c465998655dc95ae4768b",
            "e2494586f25e4d8f86258ee8345cd6e6",
            "274860a62ea742999b445a24adf37be4",
            "60d24e1fd47c450f9300e9a276c3b24a",
            "f4ab92d24c5c4b39b43ed6800b053664",
            "fe955c6fbe3942eb92d34df78a0a340d",
            "4ac93a96d1d649aa99c13ad6e2d3e230",
            "e61cb74837d346339a3dac48c6b6ee33",
            "f9fc54b202ff442ba96b1a38999e8f97",
            "d6f45dacc2244384a12751f0e2615949",
            "5cdf714ed91049f58f1ad4ea57608469",
            "9c10a268b45d4312b50b4f6cda7e5e69",
            "961858920d1c4468a92c06fddcd82654",
            "5564c6ebca1f401da44da628e3467f6b",
            "b9187c69f7034061bc034f475751349a",
            "ab11a24aaa8d436eaae776d48ddb54c6",
            "301e9194750b4bd99f25083e87e51da5",
            "8194e30d81ec4cf6bd0de360a72ec9d5",
            "25ef83e4e1674cca8c3ca32753936c25",
            "47abc603bb49443181cbcade412d5e48",
            "68167a4f370646adb0a11ecfaf0a5c6a",
            "2af06338b725458085a6e077b51f5aee",
            "bba243a5e6b54abab0ac3d164cd81ab1",
            "f2158488626d4208ac7ad75aa1e32287",
            "33d9b1a309c94ce19378890710ded038",
            "279bd9d2a5394730b0ebd3a51d7bf5d4",
            "5e33cc6b901b4890bc116cf98d9f12bf",
            "6189e2b3ee664bedb9a66a16ba3fb3db",
            "558dc661cdc842fca527b1b863c20946",
            "c261513358e142fab2aa9f320d1e0f88",
            "e6c71f3337434e0180dd02ed0ffd3f66",
            "5be65bf7257f482ba5c6452e81fbc5d0",
            "f2fde1e327f643b3883769f744f2b80c",
            "d55b4b7d46cf4e46a9d2acb6abf7173c",
            "d578ec8a8ae7489ba440c81ed0b29fe4",
            "afc61d4881ae490ca23e43ad96cc984c",
            "ce65ecb03d2f46319d3701e179f4a8a4",
            "fe2376c54fda4d3d82cf734065a21af0",
            "1d54cd329f85444ea5d07af27e3bdb3b",
            "703c3090a3174febbc3007a0d1ee8139",
            "890af1b470284e3bab45e041978a86e4",
            "dc4d8c42f42a4eeea9c870af30e34f6b",
            "cdc2f962e5ff4cedb2f594221a8a01b3",
            "f6550dd8d904418ab042151090738a6c",
            "25b37c6a428042e7afc440ef347da339",
            "94238c0b77484bffb79c1f7827335cd0",
            "f6cdc9172f80400dab1d7074738caeb5",
            "2fa77fbc9ba9417882562ee5941d87f7",
            "29350e14c64d41a48d978f7ca7029c87",
            "1af21745f03048d69505addc2fe343a7",
            "d355d433873d41c8bf25207f3de2f8fd",
            "501fedf74d1f4f15a028ccdfecb3c195",
            "7af50139dee3421b94826d4d9c2a2a03",
            "fb3d29e8735e477b943de9e85de59843",
            "b72d45f7bf6a4a27a43982156255c912",
            "44d5b962a04148b88f7713caf23155dd",
            "41e5f287e49b48259e281aaf763b87e5",
            "52a376c445e3430ebbd05d7931c9b9ca",
            "18ef89f0f21b454fa59eda04def352fd",
            "9c6156e0af9f4309b116281761e2ea5f",
            "4b79614345144b40a73436f909f1e4ef",
            "fa5c95af95434f689ab197e9948822da",
            "a894fe12b637441cbc5c55a030e820a1",
            "e65787c746d444a3bd83a76161cd4231",
            "57f2adb727d84496a7fbc7e085243a56",
            "9b4bf2eef3cf48d6ad89cb3c2ae44d3e",
            "f0477415f78e4e3c9590deb5dd89e3a3",
            "46e51e03792d4b7cbb6300bbb3ab83f6",
            "4aad7e2f72324820b71e06a431e446bf",
            "6f5eb69733114c948a58a16ac56ebd1d",
            "f872e5c7ad4d445ca465d7543e367d4f",
            "029a42a215fe405796154508c1e59dbb",
            "dfb2f9c743f14d368a67ca5784f53a2e",
            "635da505b3784c0cbbb757b39e230189",
            "ff4d1cdd581c4452a946e4cdaf5c4967",
            "617ec32f75eb48cbbd3abf21bca37364",
            "3340fc0094214e7d873e51746b35eff4",
            "aa6eab96f8834474a25d2ae00f72423e",
            "51db87e88cba4a95a1bfe120d92c456a",
            "8b0bced691b24eee8537bf2ceb00a838",
            "c1b06077292041d38d22b0878a1aa0d5",
            "65b73133de974967a3ca1a9d103a8eb9",
            "99bbd82b8a3e40cfa63a36ba9ea7eed4",
            "ecaae07d704c4ce6a65003c1908dd9b8",
            "48fe890bb8a142ba881ac0cb302b7f17",
            "517f0e8a313a461fbd5a95dbb63ad1d4",
            "e5d0710b08744963b30911b07fede59f",
            "a254cf227f0943c29ac18aa3db8ed644",
            "d49fc935142b4bcaa849fa9836ce74c3",
            "8a62588975df42c9978eb92d9100ac1d",
            "4f507aebbc354dafb0a27465b8c28a25",
            "5dec8406357a4c2296d4ac1ea29f5f1b",
            "d933a7a8163b405d91d1da63072034e6",
            "03efaf509a814ea6b634676272a4fddb",
            "4eb8f3d5fb1b4c40be42dbe2bc676c34",
            "6c95d19381154dc98d15787b1c7c580a",
            "397966192433469181a6d41159a04c99",
            "9549580fc33f4444b07c708ce8821625",
            "224dff89a22745dcbcaecadddd2a4347",
            "cefdd3039c4c4290843f7e00d1fb91b5",
            "cebd3fdac18f4a548a21eff316080b29",
            "fec9edad0dcc4d4d80ed16e51e514bab",
            "d6da2ae12acd4c65b945db378c6f4930",
            "14a75f7756544876b26a226ba5022380",
            "878c42bfaae64315b1f04b10691073d4",
            "61da6987ccec43938a5fbbb94b2a8ef1",
            "23b33c0769274ba19c26b882366d19b2",
            "c6a129e3dfd6454f9cad29dba89ce3e8",
            "6d63143c4c794bb1b3d9c03ffcf23296",
            "cc9e5a059c4f4333b9045117d2aa586a",
            "9a9f8aa5cfd04d09a789493a14508bab",
            "57e28c6d9cda4d62ae6c51bc6f31bb14",
            "b972f97cb962438fad4e19065ec88b62",
            "1d002b747ec2483d996597cae36d1133",
            "9338023e38b54b1f93acfda71b922ca1",
            "a3cb55c1cfde4a06ba1b5bb3c0d8d1c4",
            "1c5cf2f8a2e94fafb8a4e06d12187311",
            "b7f2df11c1414ef0b3584f2d204db68d",
            "380edf7f24fa4de29a2f25d37d809aad",
            "ac476d2812b64cff99e3d76ac5fc6af2",
            "9f79bc6b949340f5b9a3a7d497613640",
            "08d01c0af065491784c56692df28636c",
            "9f6ef1f7df314bc1b7a5c004b6d9d334",
            "408d5f76046846ab8cc8a597000544bd",
            "adfcf69075bd405f8ad95e2d6a3efb93",
            "ac94e748b4104222a5ec37b37c3ae1ca",
            "9c2a4a5f52b54c1ca758090684f27af4",
            "f2c0073c07254195841a5a54817b1711",
            "2bfd8a5a43dc449a892717c256c6a688",
            "e36b6fe3dea64db2bf4d6a1d457fea87",
            "4ef2704b02e24e75bc437e3bd14e42ec",
            "d2b3bf36a32b4d30bf7b077e28c9a974",
            "38412e3383a34014a9c4fdf2862fc58d",
            "538c1a40cf694fec90c8030d41b909c4",
            "97e5d127819d41e8919640569b6e65f9",
            "f9ff5711fcc147e497231ab3fbaaff05",
            "736e6b944baf485cbacc1b5bbfd9bbd6",
            "36777f8923884efb8215d9eb3d985f14",
            "ef0d5656fe2c4d08a228db5502e93af4",
            "4a769323f3284e1c8ed9911a95299dd0",
            "f89c633efea047e78e49031e6c55b694",
            "f842684899af42a887557e16f9fe1869",
            "308dfd6c4af54bc99dbdf7b21b7b2a85",
            "acafcbf3322c4e9089b409168db06f57",
            "ca8a5ab32fd94d6aba83ff7030986432",
            "b0bd7e54d8d246c98d631f5921318056",
            "cafc9336a8eb4f04a714ef3b36bf9939",
            "fbce8382bb5d46f19f883f815a7c69dc",
            "62e6758384644f00bc16a3f273a03caa",
            "00b4cf8b2b15482fbd606df261893e92",
            "4efabe35061a4d31bb5b7bf6aa5acfaf",
            "9075b3075fe8428f9a5c89336c291127",
            "04d0669fc63644029b19f42796773a58",
            "3a980969bc974a688ac906590d2748c0",
            "0852d4d1958d473e8c9548ad973d0be5",
            "58cc52cf551541d1a88614b48432ae8c",
            "d8a1546d0afc4357a8aec090b5a9dd5b",
            "ffc31f20dffd4fe184dff35cc1b93145",
            "1f27d1d078bd45418ddc4b2f2061cf6f",
            "ed4bfa6a255246b295e81d71948603d4",
            "2c21f36468c344bc9ddc091783014c6e",
            "294e2c8f1cdc4c319becefab92110181",
            "f8c11d9d21d44ac19dfe03b1752648c1",
            "8f5949efdf56409c8b0fab5da676ffb2",
            "8bdebcdf79b5416ab353b4c7f66a21e8",
            "44c8838ba4f0403ab9955f616961b23c",
            "808ee969da34465b8d6107547e4ed7ab",
            "97b865cd42284ff2a11a93e9ad2acfb3",
            "70409302db19422faa5656683cf7a800",
            "4258ac6b45c546ee9ef2c6ccc7429f6e",
            "f3afcaeed1874a54be7275b0e7d18806",
            "cd1d41870d304e4c86904bcc27fd736d",
            "ecc1c2eff0164a7fa60afc1825e871f7",
            "89de784100844ec7a74f5c43efad4d4c",
            "a1d082ef4b8446809ad2235500d2bc64",
            "ceb9821d6a3f4311991478dc34a65d69",
            "3e0a786891f949ae9162ae04944ec79e",
            "eb7d40b1f9ca44de9dcab34c916a688e",
            "8a0385004be349ed950da812260f5f4c",
            "e1d02549eb704476b389b010b7dd082d",
            "566213f1d5c544b7ad0413b56d70a5dc",
            "b163ef7384eb4f95be00e7ec1a73b72f",
            "a2893e31fe114666bf9d05489147cc57",
            "ab6c1bb8c15441098750575fb3e9e37d",
            "21e0c252a0cd4918a3a24326b9e58418",
            "6b0891462bab4cb3afbe36451372ea47",
            "69d3c55274a24ada8ccc56b35b5e6c56",
            "adc806811f7f46a3a5e7d5fd63aaad82",
            "aec5135b6af04f1cbd2d3d629967d279",
            "42d9e893c83c436fb645002a2e8f7b03",
            "8c9d86afca934fd298a224b812747f10",
            "b9819afe1b0246169b69dad9079b1323",
            "9898a9ca5e6c4b74a304a5d5a9ee27b0",
            "70d6e987d8f847b794cd082e67c59937",
            "d577fb2eff974dc99b83199f1f6d27dd",
            "af3c4068fb5645199925ff390dd2921a",
            "36c5226338df4ffab441b3272c85cbeb",
            "d398bdcf5b624bceb3aa0c54ad0060f9",
            "53b1c2bf1de14e23b5e15daf2e8474c6",
            "cb157b8f41634e7cb2648b0e127ac1bd",
            "f4ad40b0874149de9170a31171bcfcc3",
            "6a033c92fcfc4ffda669b8d2835dfae9",
            "6273874c5a024d7b9e56cb4963f12234",
            "654746114040476294d4df8ef2f6405f",
            "2ed4500812064ea2b2b15347ce40f8b1",
            "563320bc9c174de48297b02321407d34",
            "06c467a050af439eb75c22dfd050fcd7",
            "f9fb38eb00d8499693cbc0b172855704",
            "f26c772aa920484c9183c7e8f844cdab",
            "c330b41a854c4df6a90787e24a2c65bd",
            "70726e64583e49c9bb03fc2d089cee75",
            "f9af9d703e0a4f40b18ddb32c8cb1e64",
            "1ff0d42557a443498f1f65ecfc31697c",
            "a46d13462af54b2fbbc7b6430e217f33",
            "800abf389bd042c9bd37272f0580b858",
            "bbee8de5f57b47cb82ed24d8ad29b97b",
            "4bdb0bc3434643829cd63ca79b7f4bae",
            "9d0788d7fdba4feaa23a2535ba1ff584",
            "8c61b12340974cd780ec35c9d6376370",
            "2506f7ff62f34694945d0d044033007a",
            "1a992e81e2b54a729b637fb68ea26493",
            "68b20dfc91b249579b6b1a9407cea6d3",
            "93eaf5ec5e384428ad283fa2e5e2a7d3",
            "269a6fb8fefa4520a13d8690d42779e5",
            "cc3e78e5639641ac924f6a914bb06c5d",
            "a21702b8b0f14f6fa8aed65580d4b19e",
            "999c34534fb84a34b038fb3ed5b164fd",
            "d190374c6a334c57b9106b08ccbfbeb9",
            "82243f048b364fd883616c1f5382ba6c",
            "411fc75d76cb43948cd667afc23c2122",
            "aa6d829bb45043ed80c88f1f435caa99",
            "d5efdac5590c4c038ca3c3e124d26244",
            "c010c51d57fa4c51982171c86c0dce6e",
            "c7a2cb6f2a9d4dda8f671720c86fa351",
            "7b2c18055ca449bdbe55ecb6a6406f5b",
            "886b5e318b224e8f900aef060cb2933c",
            "ee4609a9e8f24d37b05613ffecbe81af",
            "e96f864d01cb4157b0ed9839be66df8d",
            "42ae91e5fc8742598ee4e87f31eb78ba",
            "c204dd2a307a4f14b83f78b566db76b4",
            "c233330728fa47fa85dd46c662a85da3",
            "64301bcee191455eb109b4cc9fbe2aeb",
            "a17976ebcf2e492c9d8346549c0d78a1",
            "f148ffeb620e4b0f9386ad07a030a510",
            "18c3385e47624b65a6ac5b84f9b3b38f",
            "d050f8b75269494ab05df3641733eace",
            "09d4b368f26845f28772f0c1407f4f0f",
            "259642531cb94b51872b17364ecba85a",
            "b546d194321743b9b118833a9f2e3f25",
            "f505098deaf5434dba68eaa808166c61",
            "f37d63649186471986697434d2d3472b",
            "e2aaa5cbcd494af3af90bb4b5c87acac",
            "b0b50c76c34b49b48f938fbafe4ae6e2",
            "c0b524a0dda74af4a3d03f93ecf28f55",
            "2965d4e4269944c081e4612aec0f129f",
            "23d8173c7650442890db6e84c810777d",
            "399d5f1435d44853bcc8dcde38aa0da6",
            "137662b6ab434085936faae1eae803bd",
            "d6c6d351dfc547fab33a66ba75a5dfd1",
            "2d486a82021c48a6a252a462a769793a",
            "4643035d28d947eea75c869e1a01a0e4",
            "47a9340723aa4898b45e4caf5a5dfa2a",
            "0d25b83472a848e0904a1797698a0b1a",
            "9daaba1833cf481c87f7f2fac4e96b13",
            "94ff2084abbc4cac8344ecc4a1baac68",
            "65f486ffda8f4f829e2918b125d27f58",
            "17e3167dc0e54b60bf49d8da3a91afbd",
            "9a0a865a646f4acaada044d13e3625a4",
            "7f745822f8364a789f747e2918a9dca5",
            "d93a4635e0054cac8488f9b1dad79add",
            "f44f5689aa6443b7baf7592c7654e3df",
            "73160150383b4165bfce13bc1c273e83",
            "d69185aff09d4f9aa1130547755a891f",
            "8ec98a177e27463f92e013a923ebd4b6",
            "e19efdbd9fcf45dda16591f249650500",
            "05629090422f41d0a5dd075dec2e6215",
            "d7b7a81ce3794c82b71f4a798c0ae94e",
            "8c5fef3fd8554ab99add17472ce7d7b0",
            "b5361ebf7ac249c4b1842c0590550432",
            "6b0afa6e524e499f958b5d34357df6a7",
            "94ff97bd00954662b2a82bf1e989157d",
            "ac01bfa5e00c4cfb9381a221eaa00700",
            "efb76c551bb14347b81f5ec94c9b3ce1",
            "5cbc78aa35724b9aabefc64674e93616",
            "0d452a26332f41a7b66b82d3c85c0821",
            "0912053bf7154e6f96b6e65aca1a1f65",
            "3a6d2c86797b4144aa1d69451b4d1c35",
            "99d0d6d99a1d4a1196ee947a858b98b2",
            "930ae74d94ff4aa99652fed0ece2db5e",
            "71eb8ad9448d438eba902551fd8c69ba",
            "acd91cc98a7c430eb0f700234cb6c6ff",
            "a87f5c4a298b4ae99616906459bcc1dc",
            "be075c3c2ac74e39b0067c1b1e420eaa",
            "fea8133c8e5e4ebf8663b6cb8fd97c1e",
            "e961068556c1445caaf44b31e997b5b8",
            "66f8ed40e3dd4891bda18ecd6c3d70bf",
            "4e0980ff295942b9bbed8a2405f0ac4c",
            "81549c298b9f4ba8944adb13d80eb0b0",
            "c7706284d0064f6e92790faf75024309",
            "79085e7e53984825a78d6ae75ec59672",
            "edfa7f1f22444e2e87af496895974836",
            "f99a3c23e6ac4cae93429d10c5d25eb9",
            "2ed2f0de1e644e97bddd2b7db30b18bd",
            "24daf4fe0ee24a86bcf2bbe0bcd2b11f",
            "9d9c2bc1c0b24981ae21b26a7a27f14f",
            "e3c3fcfa2dd4426f9083a8e4060cd6ca",
            "963744ca2e244e6ba4a6f753e6e35848",
            "3b44909b5ac1411395bc8d8832af5822",
            "fc458d5904fc419eb7e95c8cee17f455",
            "cd5ef7e1149e4276a5c835bb99f55859",
            "61a7ef1dfa53425cabbbacdc40261ae7",
            "314c193307024550b7fed8f34351e2f1",
            "8d383b22fae14e08b5a3dff84ab987ec",
            "683e4d9a973c4c08b5f14f7ebafd5bbb",
            "71fe8408fc814231b82624bba94337ef",
            "e5361e90811b4f94b498ca3ddc4a4614",
            "4e3ecd49555d4440893b44fe5f4eb7ca",
            "b9f09cbda5e64779b7058b09190c3840",
            "605d41776906404ab6aa0c091786eb60",
            "c34aa8a147bd49549ec4cf632d5f8999",
            "0350a9ed8f5944d1bc1a83288d2ecaa9",
            "25593c1670284e09bc8dad7cc33ed3d1",
            "2e2f278bdb2d49cb9cc7f9d45b8f38c9",
            "6dee68e3e5fb4b8cbd5ebf8ee63e6d63",
            "e03a6a9147c143f3877c49a25c5f02a1",
            "4e4eda429d2643fd97d6f403efbc66a0",
            "4cf09d742e854971b283ec6b4cefc122",
            "a1a51adc982042fe8ead05c085b6baee",
            "599eb83f9de840f38691794cf66b19f5",
            "7031ca0c7e0e42678d396db7122f91e8",
            "7bdcc9e737be44a4ac5a5c412f5009bb",
            "4c6800f3a154486a928e40ee362353d2",
            "9a22f76a484f42a594e33489c3417b06",
            "c91fff0b12e941f59d69e7aa036ec410",
            "3740c36c90124fe4a5a6d1e1fffc55ee",
            "f7fea2b9f789438abf0cba04637af9ca",
            "179aeeaa25ab4b07848fa99b5634f20e",
            "e22c18f263a448ef8f281273e350b50c",
            "b42efad6f7384945b9f9d98bfbe9fb94",
            "4fb4f3b1aac94eb187dd0d8986b3205c",
            "4f130b3ab9744cff92875c199639eb65",
            "aa899a4f5fc947ddbdf94ec1d16dcff2",
            "605b0f90d6ca4f56967a2f9f628b1502",
            "c80eb443ffe84fdf956cf7fa5a79f426",
            "26692debeb9c45d3899ab463f3054eff",
            "460c31822a4f4818bc08e263d0cc3a13",
            "b0c3b18d932648488b9c741067de403d",
            "30220cb4d8a1429e8d92976b825e3d83",
            "5f0ad748e4374da1b9f0e13307716a15",
            "c02c6e94284a485db756cd5e8c27b03d",
            "c69a6eebe7664bc6b9ca484430258771",
            "6b9b0f9078df43529c0a21bf0c336f9d",
            "bb69bdf1234648aba639e442b0e97f98",
            "9e2118042c734316877dcc65ab0608cd",
            "0cd01c76aeef4e2b9b9a201eadac2f2f",
            "a3b98694916e49b79496261ff134143f",
            "3f4f42efe424496a904f3206a266e82e",
            "66efae71b5f8457883b4a06d6b6f9b7c",
            "0ca4fbed1bec44b4991401cb94be3ad1",
            "9af6b6d434af4e51a684b9431b085c07",
            "096af96cd077434f989f069152e41f64",
            "d98fb0bb67754e71bd0c82f622cc33b1",
            "dc139872f43647a0aa8cd5e6e38fdf3b",
            "7dd03a7932e84f1eaf45c9e95d77bc51",
            "f2606f97087240dab23f994a553daafc",
            "12fbaae50e1948f2b3f384498cfa7f1d",
            "72b0237db5444040a52b3fe259abe949",
            "889ce5cd1d814240ae2b0ce6c0a52b29",
            "5c2a547748654e08aa0b99d977516986",
            "9623e48730cd4f22b534ec278440ea66",
            "1cc95ce9969b4a5b9d26578410342c7a",
            "71f9dc0a6a9f4e418b81ea3a0826c8b0",
            "66528f506156490790644ddac5b413fe",
            "2ec0479b85164b7faee6cf201593ba6e",
            "0aa66b87e90d44369075f3016ced2301",
            "03c39b0bc0f844f9af35ae8fb9711483",
            "fb756bfcd778451a885d7decd0712c97",
            "c4c0408926174b9ab668e8104dcf2c1b",
            "716ecfc982c14965bda6e8b91e15e668",
            "57a5b104c446439ebd360f643a788c9d",
            "c91c7aace656455887bc8c056f49614d",
            "2e0cacb16f694aa19661d93c3c793c63",
            "1284189b4a724e6792ad0b456d7e4fc7",
            "d00172fa7bd240208a371488265339cb",
            "31521fee37034c8ab79c297d766b154c",
            "dd1a4b33dbab422a9a6cd5a5e4c7e50b",
            "70ffd8b2a7074d8ca285490054600a01",
            "c487976920ca48738e42459703e004b1",
            "c23683c2240940928d5eb7f79cd6331e",
            "e70ee7e52dbd4e08b89a9c940e524906",
            "cb69c9024085477aa05b1235d991033f",
            "ea45b3e9d8ed403a849a23003686202b",
            "1e69309b0bf14057a8674f92f3257500",
            "df1115454fbb4ba3a74a0960623d7e15",
            "425f901db1e643efafc71dbba2b5f4d3",
            "7bba393b34594e45987eb6e909b28cc2",
            "e89117c5968244bb971f4edce7ffbc78",
            "0b9bb890b3d741369b4ca6890c289a1f",
            "57512a7d4ba7491ba869eff58c40fef8",
            "6f6805b4575a4c85b43bc8ee093bb64c",
            "f09e64f62669429cbf632fa07ebd59a7",
            "7ddd082677ce42dd86ba5787af78c0f4",
            "7c27afb10e294551a87faf613482960d",
            "ac3d44713ac14ceeb9e5d85963f167df",
            "797ed7936a92434ab666e9769804c14d",
            "d194a55ba688467da7a0db045be7305f",
            "9a2d0142f19349c9ae215f136cec5277",
            "b8b0066ab33a471d9019dfd2bf481006",
            "566840304c9b40c6a0ae43bbdcc563d7",
            "eabc9dbc04304d3f8bc76ea7772fbfb9",
            "f71064670bbb43d3b5307da8c9fcb556"
          ]
        },
        "id": "87UKTa3Ne4Ff",
        "outputId": "523edcd8-d601-4a15-b510-7c8161f5c2be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03e347bcf70e45c3adf783ffd241684f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading .gitattributes: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c7073bfe32f43678e2d4ea5e638567a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4ab92d24c5c4b39b43ed6800b053664",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab11a24aaa8d436eaae776d48ddb54c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e33cc6b901b4890bc116cf98d9f12bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe2376c54fda4d3d82cf734065a21af0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29350e14c64d41a48d978f7ca7029c87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c6156e0af9f4309b116281761e2ea5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f872e5c7ad4d445ca465d7543e367d4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O1.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65b73133de974967a3ca1a9d103a8eb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O2.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d933a7a8163b405d91d1da63072034e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O3.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14a75f7756544876b26a226ba5022380",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_O4.onnx:   0%|          | 0.00/45.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9338023e38b54b1f93acfda71b922ca1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac94e748b4104222a5ec37b37c3ae1ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)el_qint8_avx512.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "736e6b944baf485cbacc1b5bbfd9bbd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nt8_avx512_vnni.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbce8382bb5d46f19f883f815a7c69dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model_quint8_avx2.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f27d1d078bd45418ddc4b2f2061cf6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading openvino_model.bin:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4258ac6b45c546ee9ef2c6ccc7429f6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading openvino_model.xml: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "566213f1d5c544b7ad0413b56d70a5dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_qint8_quantized.bin:   0%|          | 0.00/22.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9819afe1b0246169b69dad9079b1323",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_qint8_quantized.xml: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6273874c5a024d7b9e56cb4963f12234",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a46d13462af54b2fbbc7b6430e217f33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc3e78e5639641ac924f6a914bb06c5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "886b5e318b224e8f900aef060cb2933c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09d4b368f26845f28772f0c1407f4f0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "137662b6ab434085936faae1eae803bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading train_script.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f745822f8364a789f747e2918a9dca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b0afa6e524e499f958b5d34357df6a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acd91cc98a7c430eb0f700234cb6c6ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f99a3c23e6ac4cae93429d10c5d25eb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d383b22fae14e08b5a3dff84ab987ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dee68e3e5fb4b8cbd5ebf8ee63e6d63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3740c36c90124fe4a5a6d1e1fffc55ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/646 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "460c31822a4f4818bc08e263d0cc3a13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)fetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f4f42efe424496a904f3206a266e82e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "889ce5cd1d814240ae2b0ce6c0a52b29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "716ecfc982c14965bda6e8b91e15e668",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e70ee7e52dbd4e08b89a9c940e524906",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f09e64f62669429cbf632fa07ebd59a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: how many paths are there?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how many paths are there?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how many paths are there?'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'how many paths are there?', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 66])\n",
            "DEBUG: Starting LLM generation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 158\n",
            "DEBUG: Handler completed in 5.44s, total query time: 5.45s\n",
            "Answer: There are 2 paths.\n",
            "\n",
            "The slack range is 0.325 to 0.611ns, which indicates that the two paths have different slack values.\n",
            "\n",
            "The fact that all paths are positive\n",
            "\n",
            "Question: what is the worst slack of all paths?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the worst slack of all paths?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the worst slack of all paths?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the worst slack of all paths?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Top 2 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "\n",
            "Question: what is the reason for worst slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the reason for worst slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the reason for worst slack?'\n",
            "DEBUG: Detected problematic phrase 'reason for worst slack', forcing simple classification\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the reason for worst slack?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Top 2 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "\n",
            "Question: what is the reason for worst slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the reason for worst slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the reason for worst slack?'\n",
            "DEBUG: Detected problematic phrase 'reason for worst slack', forcing simple classification\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the reason for worst slack?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Top 2 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "\n",
            "Question: what are the clock skews? \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what are the clock skews?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what are the clock skews?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'filtering' (clock skew)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Clock skew information for all paths:\n",
            "1. Path chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ - Clock skew: 0.4998999999999967ns - Slack: 0.3252ns\n",
            "2. Path chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ - Clock skew: 0.4468000000000001ns - Slack: 0.6112ns\n",
            "\n",
            "Question: what are the hold time requirements?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what are the hold time requirements?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what are the hold time requirements?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'filtering' (hold time)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Hold time requirements for all paths:\n",
            "1. Path chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ - Hold time requirement: 0.1002ns - Slack: 0.3252ns\n",
            "2. Path chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ - Hold time requirement: -0.0246ns - Slack: 0.6112ns\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Basic ranking\n",
        "            \"total\", \"count\", \"number of\",                           # Simple counts (NO conditions)\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Basic statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Simple timing status patterns (can be handled fast)\n",
        "        timing_status_patterns = [\n",
        "            \"failing\", \"violation\", \"fail\", \"failed\",            # Timing status\n",
        "            \"passing\", \"pass\", \"passed\",                          # Timing status\n",
        "            \"critical\", \"borderline\"                             # Timing status\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",          # Recommendations\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "            \"less than\", \"greater than\", \"more than\", \"between\",   # Conditional queries\n",
        "            \"above\", \"below\", \"equal to\", \"higher than\", \"lower than\"  # Additional conditions\n",
        "        ]\n",
        "\n",
        "        # Check for simple timing status patterns first\n",
        "        for pattern in timing_status_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        # Force simple classification for certain problematic phrases\n",
        "        problematic_phrases = [\n",
        "            \"reason for worst slack\",\n",
        "            \"why worst slack\",\n",
        "            \"worst slack reason\"\n",
        "        ]\n",
        "        for phrase in problematic_phrases:\n",
        "            if phrase in question_lower:\n",
        "                print(f\"DEBUG: Detected problematic phrase '{phrase}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Timing status patterns\n",
        "            elif any(word in question_lower for word in [\"failing\", \"violation\", \"crash\", \"crash\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (timing status)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries with condition parsing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for conditional counts\n",
        "        if \"slack\" in question_lower:\n",
        "            # Parse conditions like \"slack less than 1ns\", \"slack greater than 1ns\"\n",
        "            if \"less than\" in question_lower or \"below\" in question_lower or \"<\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"less\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] < threshold)\n",
        "                    return f\"Paths with slack less than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"greater than\" in question_lower or \"above\" in question_lower or \"more than\" in question_lower or \">\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"greater\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] > threshold)\n",
        "                    return f\"Paths with slack greater than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"equal to\" in question_lower or \"==\" in question_lower or \"=\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"equal\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] == threshold)\n",
        "                    return f\"Paths with slack equal to {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"between\" in question_lower:\n",
        "                # Extract range values\n",
        "                min_val, max_val = self._extract_range_from_question(question)\n",
        "                if min_val is not None and max_val is not None:\n",
        "                    count = sum(1 for path in all_slack_data if min_val <= path['slack'] <= max_val)\n",
        "                    return f\"Paths with slack between {min_val}ns and {max_val}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "        # Default to total count\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for timing status queries first\n",
        "        if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "            failing_paths = []\n",
        "            passing_paths = []\n",
        "\n",
        "            for path in all_slack_data:\n",
        "                slack = path['slack']\n",
        "                if slack < 0:\n",
        "                    failing_paths.append(path)\n",
        "                else:\n",
        "                    passing_paths.append(path)\n",
        "\n",
        "            results = []\n",
        "            if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\"]):\n",
        "                if failing_paths:\n",
        "                    results.append(\"🔴 FAILING PATHS (Negative Slack = Timing Violation):\")\n",
        "                    for path in failing_paths:\n",
        "                        results.append(f\"  📍 {path['startpoint']} → {path['endpoint']}: Slack={path['slack']:.3f}ns [VIOLATION]\")\n",
        "                else:\n",
        "                    results.append(\"✅ GOOD NEWS: NO FAILING PATHS!\")\n",
        "                    results.append(\"All paths have positive slack values (timing passes)\")\n",
        "                    results.append(f\"📊 Summary: {len(passing_paths)} paths PASS timing\")\n",
        "\n",
        "            elif any(word in question_lower for word in [\"passing\", \"pass\", \"critica\"]):\n",
        "                critical_count = sum(1 for p in passing_paths if 0 <= p['slack'] < 0.1)\n",
        "                results.append(f\"🟢 TIMING STATUS SUMMARY:\")\n",
        "                results.append(f\"  📈 PASSING PATHS: {len(passing_paths)} paths\")\n",
        "                results.append(f\"  📈 FAILING PATHS: {len(failing_paths)} paths\")\n",
        "                results.append(f\"  ⚠️ CRITICAL PATHS: {critical_count} paths with <0.1ns margin\")\n",
        "\n",
        "            return \"\\n\".join(results) if results else \"No timing status data available\"\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _extract_threshold_from_question(self, question: str, condition_type: str) -> float:\n",
        "        \"\"\"Extract numerical threshold from questions like 'slack less than 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns with numbers followed by 'ns'\n",
        "        patterns = [\n",
        "            r'(\\d+\\.?\\d*)\\s*ns',  # \"1ns\", \"1.5ns\", etc.\n",
        "            r'(\\d+\\.?\\d*)',       # Just numbers\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, question_lower)\n",
        "            if matches:\n",
        "                try:\n",
        "                    value = float(matches[-1])  # Take the last number found\n",
        "                    return value\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_range_from_question(self, question: str) -> tuple:\n",
        "        \"\"\"Extract range values from questions like 'slack between 0.5ns and 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for \"between X and Y\" patterns\n",
        "        pattern = r'between\\s+(\\d+\\.?\\d*)\\s+ns?\\s+and\\s+(\\d+\\.?\\d*)\\s+ns?'\n",
        "        match = re.search(pattern, question_lower)\n",
        "        if match:\n",
        "            try:\n",
        "                min_val = float(match.group(1))\n",
        "                max_val = float(match.group(2))\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        # Fallback: extract all numbers\n",
        "        numbers = re.findall(r'(\\d+\\.?\\d*)', question_lower)\n",
        "        if len(numbers) >= 2:\n",
        "            try:\n",
        "                min_val = float(numbers[0])\n",
        "                max_val = float(numbers[1])\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def _create_focused_context(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Create focused context to avoid overwhelming LLM\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Focus on relevant data based on question\n",
        "        if \"worst\" in question_lower or \"bad\" in question_lower:\n",
        "            worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Worst path: {worst_path['slack']}ns slack, {worst_path['startpoint']}→{worst_path['endpoint']}, clock_skew:{worst_path.get('clock_skew', 'N/A')}, hold_time:{worst_path.get('hold_time_requirement', 'N/A')}\"\n",
        "\n",
        "        elif \"best\" in question_lower or \"good\" in question_lower:\n",
        "            best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Best path: {best_path['slack']}ns slack, {best_path['startpoint']}→{best_path['endpoint']}\"\n",
        "\n",
        "        else:\n",
        "            # General summary\n",
        "            slack_values = [p['slack'] for p in all_slack_data]\n",
        "            return f\"{len(all_slack_data)} paths: slack range {min(slack_values):.3f} to {max(slack_values):.3f}ns, all positive (pass timing)\"\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        # Create focused context to avoid overwhelming the model\n",
        "        summary_context = self._create_focused_context(self._get_all_slack_data(), question)\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] Timing Analysis Question:\n",
        "\n",
        "Data: {summary_context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer briefly (2-4 lines): [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            import threading\n",
        "            import time\n",
        "\n",
        "            result = [None]\n",
        "            exception = [None]\n",
        "\n",
        "            def generate_worker():\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = self.llm_model.generate(\n",
        "                            inputs,\n",
        "                            attention_mask=attention_mask,\n",
        "                            max_new_tokens=50,  # Reduced for faster generation\n",
        "                            num_return_sequences=1,\n",
        "                            temperature=0.3,  # Lower temp for consistency\n",
        "                            do_sample=False,   # Deterministic\n",
        "                            pad_token_id=self.tokenizer.eos_token_id,\n",
        "                            eos_token_id=self.tokenizer.eos_token_id,\n",
        "                            early_stopping=True\n",
        "                        )\n",
        "                        result[0] = outputs\n",
        "                except Exception as e:\n",
        "                    exception[0] = e\n",
        "\n",
        "            # Start generation in a thread\n",
        "            thread = threading.Thread(target=generate_worker)\n",
        "            thread.start()\n",
        "            thread.join(timeout=15)  # 15 second timeout\n",
        "\n",
        "            if thread.is_alive():\n",
        "                print(\"DEBUG: LLM generation timed out after 15s, killing thread and using fallback...\")\n",
        "                # Thread is still alive, can't kill it cleanly, but let it continue in background\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if exception[0]:\n",
        "                print(f\"DEBUG: LLM generation failed: {exception[0]}, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if result[0] is None:\n",
        "                print(\"DEBUG: No result from LLM, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            outputs = result[0]\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "\n",
        "            # If answer is too short or seems incomplete, use fallback\n",
        "            if len(answer.strip()) < 10:\n",
        "                print(\"DEBUG: LLM response too short, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return self._generate_fallback_answer(question, None)\n",
        "\n",
        "    def _generate_fallback_answer(self, question: str, context_or_data) -> str:\n",
        "        \"\"\"Generate fallback answer when LLM fails\"\"\"\n",
        "        print(\"DEBUG: Generating fallback answer...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Always get fresh data for fallback\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Handle specific question types with direct logic\n",
        "        if \"worst slack\" in question_lower or \"reason\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "                clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "                hold_req = worst_path.get('hold_time_requirement', 'N/A')\n",
        "\n",
        "                reason_parts = []\n",
        "                if clock_skew != 'N/A':\n",
        "                    try:\n",
        "                        if float(clock_skew) > 0.4:\n",
        "                            reason_parts.append(f\"High clock skew ({clock_skew}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "                if hold_req != 'N/A':\n",
        "                    try:\n",
        "                        if float(hold_req) > 0.1:\n",
        "                            reason_parts.append(f\"High hold time requirement ({hold_req}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                if not reason_parts:\n",
        "                    reason_parts.append(\"Slack is positive but small margin\")\n",
        "\n",
        "                return f\"\"\"Worst slack: {worst_path['slack']:.3f}ns for {worst_path['startpoint']} → {worst_path['endpoint']}\n",
        "\n",
        "Potential reasons:\n",
        "{chr(10).join('- ' + reason for reason in reason_parts)}\n",
        "\n",
        "Note: This path still passes timing (positive slack) but has the smallest margin.\"\"\"\n",
        "\n",
        "        elif \"reason\" in question_lower or \"why\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                return f\"\"\"Timing Analysis Summary:\n",
        "- Total paths: {len(all_slack_data)}\n",
        "- All paths PASS timing (positive slack)\n",
        "- Slack range: {min(p['slack'] for p in all_slack_data):.3f}ns to {max(p['slack'] for p in all_slack_data):.3f}ns\n",
        "\n",
        "Potential timing concerns:\n",
        "- Small slack margins (both < 1ns)\n",
        "- Clock skew and hold time requirements may impact design margin\"\"\"\n",
        "\n",
        "        else:\n",
        "            return f\"Analysis unavailable due to LLM timeout. Raw data: {len(all_slack_data)} paths processed.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                current_slack = slack_values[i-1]\n",
        "                if current_slack < 0:\n",
        "                    context += f\"  Slack analysis: TIMING FAILURE (negative slack = violation)\\n\"\n",
        "                elif current_slack < 0.1:\n",
        "                    context += f\"  Slack analysis: CRITICAL (very small positive margin)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: TIMING PASS (adequate positive margin)\\n\"\n",
        "\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may impact timing margin)\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- POSITIVE slack = timing PASS (data arrives before required time)\\n\"\n",
        "        context += \"- NEGATIVE slack = timing FAILURE (violation)\\n\"\n",
        "        context += \"- Slack < 0.1ns = critical margin (close to violation)\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Current data shows ONLY positive slacks (all paths PASS)\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6ba9d6135a03467abe551fc7dcdffb46",
            "17b8e034b05c4d7c8fbb6ab935bbb990",
            "2e22f01099944fa69c1c304051b7d74e",
            "cb9a4ebd8c9c4348b8ce6085e314441d",
            "9cc6cba5aeec44f299173aac2954190f",
            "e66a9ffb7faf4c1a8d8e51b2e73a8b26",
            "5e1aa87179a045f39644877ee0d5b8e2",
            "c64928ad5908466db07d26da10b1eb0b",
            "4440074eaece43c68755c34646df860d",
            "0e6d461c66a54869915bd23e6910ab4f",
            "1e52ac27563c40dcb43700d28b14210d"
          ]
        },
        "id": "qwFH8rMPaQYH",
        "outputId": "a592dc4c-6548-45c1-9efc-82d5f89d4fba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ba9d6135a03467abe551fc7dcdffb46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: what is the reason for worst slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the reason for worst slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the reason for worst slack?'\n",
            "DEBUG: Detected problematic phrase 'reason for worst slack', forcing simple classification\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the reason for worst slack?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.02s\n",
            "Answer: 📊 WORST SLACK ANALYSIS:\n",
            "📍 Worst path: 0.325ns\n",
            "🔄 From: chip_core/housekeeping/_6778_ → chip_core/housekeeping/_6778_\n",
            "⏰ Clock skew: 0.500ns\n",
            "   ⚠️ HIGH clock skew - impacts timing margin\n",
            "🔒 Hold time requirement: 0.1002ns\n",
            "   ⚠️ HIGH hold time requirement\n",
            "\n",
            "📈 COMPARATIVE ANALYSIS:\n",
            "🎯 Slack range: 0.325ns to 0.611ns\n",
            "💰 Margin difference: 0.286ns\n",
            "\n",
            "✅ TIMING STATUS:\n",
            "🎯 Both paths PASS timing (positive slack)\n",
            "⚠️ Small margins indicate timing sensitivity\n",
            "💡 Consider design optimizations for robustness\n",
            "\n",
            "Question: how many paths are there?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how many paths are there?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how many paths are there?'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'how many paths are there?', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 66])\n",
            "DEBUG: Starting LLM generation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: LLM generation timed out after 15s, killing thread and using fallback...\n",
            "DEBUG: Generating fallback answer...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Handler completed in 15.44s, total query time: 15.44s\n",
            "Answer: Analysis unavailable due to LLM timeout. Raw data: 2 paths processed.\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Basic ranking\n",
        "            \"total\", \"count\", \"number of\",                           # Simple counts (NO conditions)\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Basic statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Simple timing status patterns (can be handled fast)\n",
        "        timing_status_patterns = [\n",
        "            \"failing\", \"violation\", \"fail\", \"failed\",            # Timing status\n",
        "            \"passing\", \"pass\", \"passed\",                          # Timing status\n",
        "            \"critical\", \"borderline\"                             # Timing status\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",          # Recommendations\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "            \"less than\", \"greater than\", \"more than\", \"between\",   # Conditional queries\n",
        "            \"above\", \"below\", \"equal to\", \"higher than\", \"lower than\"  # Additional conditions\n",
        "        ]\n",
        "\n",
        "        # Check for simple timing status patterns first\n",
        "        for pattern in timing_status_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        # Force simple classification for certain problematic phrases\n",
        "        problematic_phrases = [\n",
        "            \"reason for worst slack\",\n",
        "            \"why worst slack\",\n",
        "            \"worst slack reason\"\n",
        "        ]\n",
        "        for phrase in problematic_phrases:\n",
        "            if phrase in question_lower:\n",
        "                print(f\"DEBUG: Detected problematic phrase '{phrase}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Timing status patterns\n",
        "            elif any(word in question_lower for word in [\"failing\", \"violation\", \"crash\", \"crash\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (timing status)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for reasons/analysis specifically\n",
        "        if \"reason\" in question_lower or (\"why\" in question_lower and \"worst\" in question_lower):\n",
        "            return self._analyze_worst_slack_reasons(all_slack_data)\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _analyze_worst_slack_reasons(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Analyze reasons for worst slack\"\"\"\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        second_worst = sorted(all_slack_data, key=lambda x: x['slack'])[1] if len(all_slack_data) > 1 else worst_path\n",
        "\n",
        "        analysis_parts = []\n",
        "\n",
        "        # Analyze the worst path\n",
        "        analysis_parts.append(f\"📊 WORST SLACK ANALYSIS:\")\n",
        "        analysis_parts.append(f\"📍 Worst path: {worst_path['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"🔄 From: {worst_path['startpoint']} → {worst_path['endpoint']}\")\n",
        "\n",
        "        # Clock skew analysis\n",
        "        clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "        if clock_skew != 'N/A':\n",
        "            analysis_parts.append(f\"⏰ Clock skew: {clock_skew:.3f}ns\")\n",
        "            try:\n",
        "                if float(clock_skew) > 0.4:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH clock skew - impacts timing margin\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Moderate clock skew\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Hold time analysis\n",
        "        hold_time = worst_path.get('hold_time_requirement', 'N/A')\n",
        "        if hold_time != 'N/A':\n",
        "            analysis_parts.append(f\"🔒 Hold time requirement: {hold_time}ns\")\n",
        "            try:\n",
        "                if float(hold_time) > 0.1:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH hold time requirement\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Normal hold time requirement\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Comparative analysis\n",
        "        analysis_parts.append(f\"\\n📈 COMPARATIVE ANALYSIS:\")\n",
        "        analysis_parts.append(f\"🎯 Slack range: {worst_path['slack']:.3f}ns to {second_worst['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"💰 Margin difference: {second_worst['slack'] - worst_path['slack']:.3f}ns\")\n",
        "\n",
        "        # Summary assessment\n",
        "        analysis_parts.append(f\"\\n✅ TIMING STATUS:\")\n",
        "        analysis_parts.append(f\"🎯 Both paths PASS timing (positive slack)\")\n",
        "        analysis_parts.append(f\"⚠️ Small margins indicate timing sensitivity\")\n",
        "        analysis_parts.append(f\"💡 Consider design optimizations for robustness\")\n",
        "\n",
        "        return \"\\n\".join(analysis_parts)\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries with condition parsing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for conditional counts\n",
        "        if \"slack\" in question_lower:\n",
        "            # Parse conditions like \"slack less than 1ns\", \"slack greater than 1ns\"\n",
        "            if \"less than\" in question_lower or \"below\" in question_lower or \"<\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"less\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] < threshold)\n",
        "                    return f\"Paths with slack less than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"greater than\" in question_lower or \"above\" in question_lower or \"more than\" in question_lower or \">\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"greater\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] > threshold)\n",
        "                    return f\"Paths with slack greater than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"equal to\" in question_lower or \"==\" in question_lower or \"=\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"equal\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] == threshold)\n",
        "                    return f\"Paths with slack equal to {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"between\" in question_lower:\n",
        "                # Extract range values\n",
        "                min_val, max_val = self._extract_range_from_question(question)\n",
        "                if min_val is not None and max_val is not None:\n",
        "                    count = sum(1 for path in all_slack_data if min_val <= path['slack'] <= max_val)\n",
        "                    return f\"Paths with slack between {min_val}ns and {max_val}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "        # Default to total count\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for timing status queries first\n",
        "        if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "            failing_paths = []\n",
        "            passing_paths = []\n",
        "\n",
        "            for path in all_slack_data:\n",
        "                slack = path['slack']\n",
        "                if slack < 0:\n",
        "                    failing_paths.append(path)\n",
        "                else:\n",
        "                    passing_paths.append(path)\n",
        "\n",
        "            results = []\n",
        "            if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\"]):\n",
        "                if failing_paths:\n",
        "                    results.append(\"🔴 FAILING PATHS (Negative Slack = Timing Violation):\")\n",
        "                    for path in failing_paths:\n",
        "                        results.append(f\"  📍 {path['startpoint']} → {path['endpoint']}: Slack={path['slack']:.3f}ns [VIOLATION]\")\n",
        "                else:\n",
        "                    results.append(\"✅ GOOD NEWS: NO FAILING PATHS!\")\n",
        "                    results.append(\"All paths have positive slack values (timing passes)\")\n",
        "                    results.append(f\"📊 Summary: {len(passing_paths)} paths PASS timing\")\n",
        "\n",
        "            elif any(word in question_lower for word in [\"passing\", \"pass\", \"critica\"]):\n",
        "                critical_count = sum(1 for p in passing_paths if 0 <= p['slack'] < 0.1)\n",
        "                results.append(f\"🟢 TIMING STATUS SUMMARY:\")\n",
        "                results.append(f\"  📈 PASSING PATHS: {len(passing_paths)} paths\")\n",
        "                results.append(f\"  📈 FAILING PATHS: {len(failing_paths)} paths\")\n",
        "                results.append(f\"  ⚠️ CRITICAL PATHS: {critical_count} paths with <0.1ns margin\")\n",
        "\n",
        "            return \"\\n\".join(results) if results else \"No timing status data available\"\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _extract_threshold_from_question(self, question: str, condition_type: str) -> float:\n",
        "        \"\"\"Extract numerical threshold from questions like 'slack less than 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns with numbers followed by 'ns'\n",
        "        patterns = [\n",
        "            r'(\\d+\\.?\\d*)\\s*ns',  # \"1ns\", \"1.5ns\", etc.\n",
        "            r'(\\d+\\.?\\d*)',       # Just numbers\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, question_lower)\n",
        "            if matches:\n",
        "                try:\n",
        "                    value = float(matches[-1])  # Take the last number found\n",
        "                    return value\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_range_from_question(self, question: str) -> tuple:\n",
        "        \"\"\"Extract range values from questions like 'slack between 0.5ns and 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for \"between X and Y\" patterns\n",
        "        pattern = r'between\\s+(\\d+\\.?\\d*)\\s+ns?\\s+and\\s+(\\d+\\.?\\d*)\\s+ns?'\n",
        "        match = re.search(pattern, question_lower)\n",
        "        if match:\n",
        "            try:\n",
        "                min_val = float(match.group(1))\n",
        "                max_val = float(match.group(2))\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        # Fallback: extract all numbers\n",
        "        numbers = re.findall(r'(\\d+\\.?\\d*)', question_lower)\n",
        "        if len(numbers) >= 2:\n",
        "            try:\n",
        "                min_val = float(numbers[0])\n",
        "                max_val = float(numbers[1])\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def _create_focused_context(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Create focused context to avoid overwhelming LLM\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Focus on relevant data based on question\n",
        "        if \"worst\" in question_lower or \"bad\" in question_lower:\n",
        "            worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Worst path: {worst_path['slack']}ns slack, {worst_path['startpoint']}→{worst_path['endpoint']}, clock_skew:{worst_path.get('clock_skew', 'N/A')}, hold_time:{worst_path.get('hold_time_requirement', 'N/A')}\"\n",
        "\n",
        "        elif \"best\" in question_lower or \"good\" in question_lower:\n",
        "            best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Best path: {best_path['slack']}ns slack, {best_path['startpoint']}→{best_path['endpoint']}\"\n",
        "\n",
        "        else:\n",
        "            # General summary\n",
        "            slack_values = [p['slack'] for p in all_slack_data]\n",
        "            return f\"{len(all_slack_data)} paths: slack range {min(slack_values):.3f} to {max(slack_values):.3f}ns, all positive (pass timing)\"\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        # Create focused context to avoid overwhelming the model\n",
        "        summary_context = self._create_focused_context(self._get_all_slack_data(), question)\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] Timing Analysis Question:\n",
        "\n",
        "Data: {summary_context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer briefly (2-4 lines): [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            import threading\n",
        "            import time\n",
        "\n",
        "            result = [None]\n",
        "            exception = [None]\n",
        "\n",
        "            def generate_worker():\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = self.llm_model.generate(\n",
        "                            inputs,\n",
        "                            attention_mask=attention_mask,\n",
        "                            max_new_tokens=50,  # Reduced for faster generation\n",
        "                            num_return_sequences=1,\n",
        "                            temperature=0.3,  # Lower temp for consistency\n",
        "                            do_sample=False,   # Deterministic\n",
        "                            pad_token_id=self.tokenizer.eos_token_id,\n",
        "                            eos_token_id=self.tokenizer.eos_token_id,\n",
        "                            early_stopping=True\n",
        "                        )\n",
        "                        result[0] = outputs\n",
        "                except Exception as e:\n",
        "                    exception[0] = e\n",
        "\n",
        "            # Start generation in a thread\n",
        "            thread = threading.Thread(target=generate_worker)\n",
        "            thread.start()\n",
        "            thread.join(timeout=15)  # 15 second timeout\n",
        "\n",
        "            if thread.is_alive():\n",
        "                print(\"DEBUG: LLM generation timed out after 15s, killing thread and using fallback...\")\n",
        "                # Thread is still alive, can't kill it cleanly, but let it continue in background\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if exception[0]:\n",
        "                print(f\"DEBUG: LLM generation failed: {exception[0]}, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if result[0] is None:\n",
        "                print(\"DEBUG: No result from LLM, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            outputs = result[0]\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "\n",
        "            # If answer is too short or seems incomplete, use fallback\n",
        "            if len(answer.strip()) < 10:\n",
        "                print(\"DEBUG: LLM response too short, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return self._generate_fallback_answer(question, None)\n",
        "\n",
        "    def _generate_fallback_answer(self, question: str, context_or_data) -> str:\n",
        "        \"\"\"Generate fallback answer when LLM fails\"\"\"\n",
        "        print(\"DEBUG: Generating fallback answer...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Always get fresh data for fallback\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Handle specific question types with direct logic\n",
        "        if \"worst slack\" in question_lower or \"reason\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "                clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "                hold_req = worst_path.get('hold_time_requirement', 'N/A')\n",
        "\n",
        "                reason_parts = []\n",
        "                if clock_skew != 'N/A':\n",
        "                    try:\n",
        "                        if float(clock_skew) > 0.4:\n",
        "                            reason_parts.append(f\"High clock skew ({clock_skew}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "                if hold_req != 'N/A':\n",
        "                    try:\n",
        "                        if float(hold_req) > 0.1:\n",
        "                            reason_parts.append(f\"High hold time requirement ({hold_req}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                if not reason_parts:\n",
        "                    reason_parts.append(\"Slack is positive but small margin\")\n",
        "\n",
        "                return f\"\"\"Worst slack: {worst_path['slack']:.3f}ns for {worst_path['startpoint']} → {worst_path['endpoint']}\n",
        "\n",
        "Potential reasons:\n",
        "{chr(10).join('- ' + reason for reason in reason_parts)}\n",
        "\n",
        "Note: This path still passes timing (positive slack) but has the smallest margin.\"\"\"\n",
        "\n",
        "        elif \"reason\" in question_lower or \"why\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                return f\"\"\"Timing Analysis Summary:\n",
        "- Total paths: {len(all_slack_data)}\n",
        "- All paths PASS timing (positive slack)\n",
        "- Slack range: {min(p['slack'] for p in all_slack_data):.3f}ns to {max(p['slack'] for p in all_slack_data):.3f}ns\n",
        "\n",
        "Potential timing concerns:\n",
        "- Small slack margins (both < 1ns)\n",
        "- Clock skew and hold time requirements may impact design margin\"\"\"\n",
        "\n",
        "        else:\n",
        "            return f\"Analysis unavailable due to LLM timeout. Raw data: {len(all_slack_data)} paths processed.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                current_slack = slack_values[i-1]\n",
        "                if current_slack < 0:\n",
        "                    context += f\"  Slack analysis: TIMING FAILURE (negative slack = violation)\\n\"\n",
        "                elif current_slack < 0.1:\n",
        "                    context += f\"  Slack analysis: CRITICAL (very small positive margin)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: TIMING PASS (adequate positive margin)\\n\"\n",
        "\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may impact timing margin)\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- POSITIVE slack = timing PASS (data arrives before required time)\\n\"\n",
        "        context += \"- NEGATIVE slack = timing FAILURE (violation)\\n\"\n",
        "        context += \"- Slack < 0.1ns = critical margin (close to violation)\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Current data shows ONLY positive slacks (all paths PASS)\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "030d91d7bfbb471e9247d3c4d63516c7",
            "4a3f4e3c75674e8c844ad84638752cd9",
            "ee2936eb2c494bc1843aaeca475d4fef",
            "6a68408321e04315a3693f3849563fad",
            "5f8ef43fc4484ec1b7e76e3ad838344f",
            "9ff4fa88d21544a0959b52eea3cdb1ca",
            "99f915f64314496ca86ea825016c6fd9",
            "4f8085040cf84857af29218cabc52eea",
            "71d48b1031c340bb84e5aa14f183c4fe",
            "0fa3a7b26bc342a78dc1c6a211a98f25",
            "bec2bd773e4044cab9bd91186674a61d"
          ]
        },
        "id": "h4ChlKYakdGq",
        "outputId": "365b612a-a732-496f-e02d-0ed07f7a6d6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "030d91d7bfbb471e9247d3c4d63516c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 2 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: how many timing paths are there?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how many timing paths are there?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how many timing paths are there?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'counting'\n",
            "DEBUG: Question classified as: 'counting' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: counting\n",
            "DEBUG: Calling counting handler\n",
            "DEBUG: Using direct counting (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Total number of timing paths: 2\n",
            "\n",
            "Question: what is the worst slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the worst slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the worst slack?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the worst slack?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: Top 2 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "\n",
            "Question: what is the reason for worst slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the reason for worst slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the reason for worst slack?'\n",
            "DEBUG: Detected problematic phrase 'reason for worst slack', forcing simple classification\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the reason for worst slack?\n",
            "DEBUG: Found 2 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.00s\n",
            "Answer: 📊 WORST SLACK ANALYSIS:\n",
            "📍 Worst path: 0.325ns\n",
            "🔄 From: chip_core/housekeeping/_6778_ → chip_core/housekeeping/_6778_\n",
            "⏰ Clock skew: 0.500ns\n",
            "   ⚠️ HIGH clock skew - impacts timing margin\n",
            "🔒 Hold time requirement: 0.1002ns\n",
            "   ⚠️ HIGH hold time requirement\n",
            "\n",
            "📈 COMPARATIVE ANALYSIS:\n",
            "🎯 Slack range: 0.325ns to 0.611ns\n",
            "💰 Margin difference: 0.286ns\n",
            "\n",
            "✅ TIMING STATUS:\n",
            "🎯 Both paths PASS timing (positive slack)\n",
            "⚠️ Small margins indicate timing sensitivity\n",
            "💡 Consider design optimizations for robustness\n",
            "\n",
            "Question: how can we improve the slack?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how can we improve the slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how can we improve the slack?'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'how can we improve the slack?', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 68])\n",
            "DEBUG: Starting LLM generation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 179\n",
            "DEBUG: Handler completed in 3.87s, total query time: 3.87s\n",
            "Answer: To improve the slack, we can try the following:\n",
            "\n",
            "1. Reduce the number of logic gates in the design to reduce the required slack.\n",
            "2. Use a faster clock speed to reduce the slack.\n",
            "3\n",
            "\n",
            "Question: what can we do to make the slack better? List 5 points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what can we do to make the slack better? List 5 points'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what can we do to make the slack better? List 5 points'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'what can we do to make the slack better? List 5 points', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 75])\n",
            "DEBUG: Starting LLM generation...\n",
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 175\n",
            "DEBUG: Handler completed in 3.07s, total query time: 3.07s\n",
            "Answer: To improve the slack, we can try the following:\n",
            "\n",
            "1. Increase the clock frequency to reduce the slack.\n",
            "2. Optimize the design for better resource utilization.\n",
            "3. Use timing-dri\n",
            "\n",
            "Question: what can we do to make the slack better? List 10 points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what can we do to make the slack better? List 10 points'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Retrieved 2 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what can we do to make the slack better? List 10 points'\n",
            "DEBUG: Query complexity: complex\n",
            "DEBUG: Complex query detected: 'what can we do to make the slack better? List 10 points', returning 'complex'\n",
            "DEBUG: Question classified as: 'complex' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: complex\n",
            "DEBUG: Calling complex query handler\n",
            "DEBUG: Using LLM for complex query analysis...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 2 entries\n",
            "DEBUG: Processed 2 slack data entries\n",
            "DEBUG: Tokenizing prompt...\n",
            "DEBUG: Input shape: torch.Size([1, 76])\n",
            "DEBUG: Starting LLM generation...\n",
            "DEBUG: LLM generation completed, decoding...\n",
            "DEBUG: Response decoded, length: 178\n",
            "DEBUG: Handler completed in 3.08s, total query time: 3.08s\n",
            "Answer: To improve the slack, consider the following 10 points:\n",
            "\n",
            "1. Increase the clock frequency to reduce the slack.\n",
            "2. Optimize the design for better resource utilization.\n",
            "3. Use clock\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Basic ranking\n",
        "            \"total\", \"count\", \"number of\",                           # Simple counts (NO conditions)\n",
        "            \"how many\",                                              # counting questions\n",
        "            \"paths are\", \"are there\", \"paths total\",                # Simple counting variations\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Basic statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Simple timing status patterns (can be handled fast)\n",
        "        timing_status_patterns = [\n",
        "            \"failing\", \"violation\", \"fail\", \"failed\",            # Timing status\n",
        "            \"passing\", \"pass\", \"passed\",                          # Timing status\n",
        "            \"critical\", \"borderline\"                             # Timing status\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",          # Recommendations\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "            \"less than\", \"greater than\", \"more than\", \"between\",   # Conditional queries\n",
        "            \"above\", \"below\", \"equal to\", \"higher than\", \"lower than\"  # Additional conditions\n",
        "        ]\n",
        "\n",
        "        # Check for simple timing status patterns first\n",
        "        for pattern in timing_status_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        # Force simple classification for certain problematic phrases\n",
        "        problematic_phrases = [\n",
        "            \"reason for worst slack\",\n",
        "            \"why worst slack\",\n",
        "            \"worst slack reason\"\n",
        "        ]\n",
        "        for phrase in problematic_phrases:\n",
        "            if phrase in question_lower:\n",
        "                print(f\"DEBUG: Detected problematic phrase '{phrase}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\", \"are there\", \"paths are\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Timing status patterns\n",
        "            elif any(word in question_lower for word in [\"failing\", \"violation\", \"crash\", \"crash\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (timing status)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for reasons/analysis specifically\n",
        "        if \"reason\" in question_lower or (\"why\" in question_lower and \"worst\" in question_lower):\n",
        "            return self._analyze_worst_slack_reasons(all_slack_data)\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _analyze_worst_slack_reasons(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Analyze reasons for worst slack\"\"\"\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        second_worst = sorted(all_slack_data, key=lambda x: x['slack'])[1] if len(all_slack_data) > 1 else worst_path\n",
        "\n",
        "        analysis_parts = []\n",
        "\n",
        "        # Analyze the worst path\n",
        "        analysis_parts.append(f\"📊 WORST SLACK ANALYSIS:\")\n",
        "        analysis_parts.append(f\"📍 Worst path: {worst_path['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"🔄 From: {worst_path['startpoint']} → {worst_path['endpoint']}\")\n",
        "\n",
        "        # Clock skew analysis\n",
        "        clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "        if clock_skew != 'N/A':\n",
        "            analysis_parts.append(f\"⏰ Clock skew: {clock_skew:.3f}ns\")\n",
        "            try:\n",
        "                if float(clock_skew) > 0.4:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH clock skew - impacts timing margin\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Moderate clock skew\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Hold time analysis\n",
        "        hold_time = worst_path.get('hold_time_requirement', 'N/A')\n",
        "        if hold_time != 'N/A':\n",
        "            analysis_parts.append(f\"🔒 Hold time requirement: {hold_time}ns\")\n",
        "            try:\n",
        "                if float(hold_time) > 0.1:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH hold time requirement\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Normal hold time requirement\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Comparative analysis\n",
        "        analysis_parts.append(f\"\\n📈 COMPARATIVE ANALYSIS:\")\n",
        "        analysis_parts.append(f\"🎯 Slack range: {worst_path['slack']:.3f}ns to {second_worst['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"💰 Margin difference: {second_worst['slack'] - worst_path['slack']:.3f}ns\")\n",
        "\n",
        "        # Summary assessment\n",
        "        analysis_parts.append(f\"\\n✅ TIMING STATUS:\")\n",
        "        analysis_parts.append(f\"🎯 Both paths PASS timing (positive slack)\")\n",
        "        analysis_parts.append(f\"⚠️ Small margins indicate timing sensitivity\")\n",
        "        analysis_parts.append(f\"💡 Consider design optimizations for robustness\")\n",
        "\n",
        "        return \"\\n\".join(analysis_parts)\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries with condition parsing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Handle simple total counts first\n",
        "        if any(phrase in question_lower for phrase in [\"are there\", \"paths are\", \"how many\", \"total paths\", \"paths total\"]):\n",
        "            # Simple counting - just return total\n",
        "            return f\"Total number of timing paths: {len(all_slack_data)}\"\n",
        "\n",
        "        # Check for conditional counts\n",
        "        if \"slack\" in question_lower:\n",
        "            # Parse conditions like \"slack less than 1ns\", \"slack greater than 1ns\"\n",
        "            if \"less than\" in question_lower or \"below\" in question_lower or \"<\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"less\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] < threshold)\n",
        "                    return f\"Paths with slack less than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"greater than\" in question_lower or \"above\" in question_lower or \"more than\" in question_lower or \">\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"greater\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] > threshold)\n",
        "                    return f\"Paths with slack greater than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"equal to\" in question_lower or \"==\" in question_lower or \"=\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"equal\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] == threshold)\n",
        "                    return f\"Paths with slack equal to {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"between\" in question_lower:\n",
        "                # Extract range values\n",
        "                min_val, max_val = self._extract_range_from_question(question)\n",
        "                if min_val is not None and max_val is not None:\n",
        "                    count = sum(1 for path in all_slack_data if min_val <= path['slack'] <= max_val)\n",
        "                    return f\"Paths with slack between {min_val}ns and {max_val}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "        # Default to total count\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for timing status queries first\n",
        "        if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "            failing_paths = []\n",
        "            passing_paths = []\n",
        "\n",
        "            for path in all_slack_data:\n",
        "                slack = path['slack']\n",
        "                if slack < 0:\n",
        "                    failing_paths.append(path)\n",
        "                else:\n",
        "                    passing_paths.append(path)\n",
        "\n",
        "            results = []\n",
        "            if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\"]):\n",
        "                if failing_paths:\n",
        "                    results.append(\"🔴 FAILING PATHS (Negative Slack = Timing Violation):\")\n",
        "                    for path in failing_paths:\n",
        "                        results.append(f\"  📍 {path['startpoint']} → {path['endpoint']}: Slack={path['slack']:.3f}ns [VIOLATION]\")\n",
        "                else:\n",
        "                    results.append(\"✅ GOOD NEWS: NO FAILING PATHS!\")\n",
        "                    results.append(\"All paths have positive slack values (timing passes)\")\n",
        "                    results.append(f\"📊 Summary: {len(passing_paths)} paths PASS timing\")\n",
        "\n",
        "            elif any(word in question_lower for word in [\"passing\", \"pass\", \"critica\"]):\n",
        "                critical_count = sum(1 for p in passing_paths if 0 <= p['slack'] < 0.1)\n",
        "                results.append(f\"🟢 TIMING STATUS SUMMARY:\")\n",
        "                results.append(f\"  📈 PASSING PATHS: {len(passing_paths)} paths\")\n",
        "                results.append(f\"  📈 FAILING PATHS: {len(failing_paths)} paths\")\n",
        "                results.append(f\"  ⚠️ CRITICAL PATHS: {critical_count} paths with <0.1ns margin\")\n",
        "\n",
        "            return \"\\n\".join(results) if results else \"No timing status data available\"\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _extract_threshold_from_question(self, question: str, condition_type: str) -> float:\n",
        "        \"\"\"Extract numerical threshold from questions like 'slack less than 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns with numbers followed by 'ns'\n",
        "        patterns = [\n",
        "            r'(\\d+\\.?\\d*)\\s*ns',  # \"1ns\", \"1.5ns\", etc.\n",
        "            r'(\\d+\\.?\\d*)',       # Just numbers\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, question_lower)\n",
        "            if matches:\n",
        "                try:\n",
        "                    value = float(matches[-1])  # Take the last number found\n",
        "                    return value\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_range_from_question(self, question: str) -> tuple:\n",
        "        \"\"\"Extract range values from questions like 'slack between 0.5ns and 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for \"between X and Y\" patterns\n",
        "        pattern = r'between\\s+(\\d+\\.?\\d*)\\s+ns?\\s+and\\s+(\\d+\\.?\\d*)\\s+ns?'\n",
        "        match = re.search(pattern, question_lower)\n",
        "        if match:\n",
        "            try:\n",
        "                min_val = float(match.group(1))\n",
        "                max_val = float(match.group(2))\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        # Fallback: extract all numbers\n",
        "        numbers = re.findall(r'(\\d+\\.?\\d*)', question_lower)\n",
        "        if len(numbers) >= 2:\n",
        "            try:\n",
        "                min_val = float(numbers[0])\n",
        "                max_val = float(numbers[1])\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def _create_focused_context(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Create focused context to avoid overwhelming LLM\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Focus on relevant data based on question\n",
        "        if \"worst\" in question_lower or \"bad\" in question_lower:\n",
        "            worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Worst path: {worst_path['slack']}ns slack, {worst_path['startpoint']}→{worst_path['endpoint']}, clock_skew:{worst_path.get('clock_skew', 'N/A')}, hold_time:{worst_path.get('hold_time_requirement', 'N/A')}\"\n",
        "\n",
        "        elif \"best\" in question_lower or \"good\" in question_lower:\n",
        "            best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Best path: {best_path['slack']}ns slack, {best_path['startpoint']}→{best_path['endpoint']}\"\n",
        "\n",
        "        else:\n",
        "            # General summary\n",
        "            slack_values = [p['slack'] for p in all_slack_data]\n",
        "            return f\"{len(all_slack_data)} paths: slack range {min(slack_values):.3f} to {max(slack_values):.3f}ns, all positive (pass timing)\"\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        # Create focused context to avoid overwhelming the model\n",
        "        summary_context = self._create_focused_context(self._get_all_slack_data(), question)\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] Timing Analysis Question:\n",
        "\n",
        "Data: {summary_context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer briefly (2-4 lines): [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            import threading\n",
        "            import time\n",
        "\n",
        "            result = [None]\n",
        "            exception = [None]\n",
        "\n",
        "            def generate_worker():\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = self.llm_model.generate(\n",
        "                            inputs,\n",
        "                            attention_mask=attention_mask,\n",
        "                            max_new_tokens=50,  # Reduced for faster generation\n",
        "                            num_return_sequences=1,\n",
        "                            temperature=0.3,  # Lower temp for consistency\n",
        "                            do_sample=False,   # Deterministic\n",
        "                            pad_token_id=self.tokenizer.eos_token_id,\n",
        "                            eos_token_id=self.tokenizer.eos_token_id,\n",
        "                            early_stopping=True\n",
        "                        )\n",
        "                        result[0] = outputs\n",
        "                except Exception as e:\n",
        "                    exception[0] = e\n",
        "\n",
        "            # Start generation in a thread\n",
        "            thread = threading.Thread(target=generate_worker)\n",
        "            thread.start()\n",
        "            thread.join(timeout=15)  # 15 second timeout\n",
        "\n",
        "            if thread.is_alive():\n",
        "                print(\"DEBUG: LLM generation timed out after 15s, killing thread and using fallback...\")\n",
        "                # Thread is still alive, can't kill it cleanly, but let it continue in background\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if exception[0]:\n",
        "                print(f\"DEBUG: LLM generation failed: {exception[0]}, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if result[0] is None:\n",
        "                print(\"DEBUG: No result from LLM, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            outputs = result[0]\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "\n",
        "            # If answer is too short or seems incomplete, use fallback\n",
        "            if len(answer.strip()) < 10:\n",
        "                print(\"DEBUG: LLM response too short, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return self._generate_fallback_answer(question, None)\n",
        "\n",
        "    def _generate_fallback_answer(self, question: str, context_or_data) -> str:\n",
        "        \"\"\"Generate fallback answer when LLM fails\"\"\"\n",
        "        print(\"DEBUG: Generating fallback answer...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Always get fresh data for fallback\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Handle specific question types with direct logic\n",
        "        if \"worst slack\" in question_lower or \"reason\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "                clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "                hold_req = worst_path.get('hold_time_requirement', 'N/A')\n",
        "\n",
        "                reason_parts = []\n",
        "                if clock_skew != 'N/A':\n",
        "                    try:\n",
        "                        if float(clock_skew) > 0.4:\n",
        "                            reason_parts.append(f\"High clock skew ({clock_skew}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "                if hold_req != 'N/A':\n",
        "                    try:\n",
        "                        if float(hold_req) > 0.1:\n",
        "                            reason_parts.append(f\"High hold time requirement ({hold_req}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                if not reason_parts:\n",
        "                    reason_parts.append(\"Slack is positive but small margin\")\n",
        "\n",
        "                return f\"\"\"Worst slack: {worst_path['slack']:.3f}ns for {worst_path['startpoint']} → {worst_path['endpoint']}\n",
        "\n",
        "Potential reasons:\n",
        "{chr(10).join('- ' + reason for reason in reason_parts)}\n",
        "\n",
        "Note: This path still passes timing (positive slack) but has the smallest margin.\"\"\"\n",
        "\n",
        "        elif \"reason\" in question_lower or \"why\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                return f\"\"\"Timing Analysis Summary:\n",
        "- Total paths: {len(all_slack_data)}\n",
        "- All paths PASS timing (positive slack)\n",
        "- Slack range: {min(p['slack'] for p in all_slack_data):.3f}ns to {max(p['slack'] for p in all_slack_data):.3f}ns\n",
        "\n",
        "Potential timing concerns:\n",
        "- Small slack margins (both < 1ns)\n",
        "- Clock skew and hold time requirements may impact design margin\"\"\"\n",
        "\n",
        "        else:\n",
        "            return f\"Analysis unavailable due to LLM timeout. Raw data: {len(all_slack_data)} paths processed.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                current_slack = slack_values[i-1]\n",
        "                if current_slack < 0:\n",
        "                    context += f\"  Slack analysis: TIMING FAILURE (negative slack = violation)\\n\"\n",
        "                elif current_slack < 0.1:\n",
        "                    context += f\"  Slack analysis: CRITICAL (very small positive margin)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: TIMING PASS (adequate positive margin)\\n\"\n",
        "\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may impact timing margin)\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- POSITIVE slack = timing PASS (data arrives before required time)\\n\"\n",
        "        context += \"- NEGATIVE slack = timing FAILURE (violation)\\n\"\n",
        "        context += \"- Slack < 0.1ns = critical margin (close to violation)\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Current data shows ONLY positive slacks (all paths PASS)\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4a229a76bf2d490582ff9baee316b499",
            "f0bdfb4308e9473aa258d5f07b73be87",
            "0164bb488a2f4159a858e8836d6dbc9f",
            "21171de6dc1c499e940e2eef93ca9ef4",
            "d76f124f54a949508f0d32c68ca58946",
            "1181f9e2492d4d30888bb6371cbe9d18",
            "099ccb8649e343859886ef3f1ba6cfdf",
            "dd6dc7187dee424d817ef2fde4d155db",
            "cb1bf262d0fb4954bf3c3b055989e026",
            "aaf4f9b016604bd88da609cd40708b94",
            "f74bdfb6030449649988316dd8fcfa80"
          ]
        },
        "id": "63zwYrGmroUO",
        "outputId": "d5160069-e39b-4f0b-8ede-19fe4ca6b875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a229a76bf2d490582ff9baee316b499"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 659 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: how many paths are there?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how many paths are there?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how many paths are there?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'counting'\n",
            "DEBUG: Question classified as: 'counting' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: counting\n",
            "DEBUG: Calling counting handler\n",
            "DEBUG: Using direct counting (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.05s\n",
            "Answer: Total number of timing paths: 659\n",
            "\n",
            "Question: what is the worst slack?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the worst slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the worst slack?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the worst slack?\n",
            "DEBUG: Found 659 paths\n",
            "DEBUG: Extracted number: 2\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.03s\n",
            "Answer: Top 2 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "\n",
            "Question: show top 3 worst slacks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'show top 3 worst slacks'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'show top 3 worst slacks'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: show top 3 worst slacks\n",
            "DEBUG: Found 659 paths\n",
            "DEBUG: Extracted number: 3\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.03s\n",
            "Answer: Top 3 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "3. Slack: 0.6174ns - Path from chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6469_ in group hkspi_clk\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Basic ranking\n",
        "            \"total\", \"count\", \"number of\",                           # Simple counts (NO conditions)\n",
        "            \"how many\",                                              # counting questions\n",
        "            \"paths are\", \"are there\", \"paths total\",                # Simple counting variations\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Basic statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Simple timing status patterns (can be handled fast)\n",
        "        timing_status_patterns = [\n",
        "            \"failing\", \"violation\", \"fail\", \"failed\",            # Timing status\n",
        "            \"passing\", \"pass\", \"passed\",                          # Timing status\n",
        "            \"critical\", \"borderline\"                             # Timing status\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "            \"less than\", \"greater than\", \"more than\", \"between\",   # Conditional queries\n",
        "            \"above\", \"below\", \"equal to\", \"higher than\", \"lower than\"  # Additional conditions\n",
        "        ]\n",
        "\n",
        "        # Recommendation patterns (should handle with direct logic, not LLM)\n",
        "        recommendation_patterns = [\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",\n",
        "            \"how can we\", \"what can we do\", \"how to improve\",\n",
        "            \"make better\", \"improve slack\", \"better slack\"\n",
        "        ]\n",
        "\n",
        "        # Check for simple timing status patterns first\n",
        "        for pattern in timing_status_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for recommendation patterns (handle with direct logic)\n",
        "        for pattern in recommendation_patterns:\n",
        "            if pattern in question_lower:\n",
        "                print(f\"DEBUG: Detected recommendation pattern '{pattern}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Force simple classification for certain problematic phrases\n",
        "        problematic_phrases = [\n",
        "            \"reason for worst slack\",\n",
        "            \"why worst slack\",\n",
        "            \"worst slack reason\"\n",
        "        ]\n",
        "        for phrase in problematic_phrases:\n",
        "            if phrase in question_lower:\n",
        "                print(f\"DEBUG: Detected problematic phrase '{phrase}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\", \"are there\", \"paths are\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Timing status patterns\n",
        "            elif any(word in question_lower for word in [\"failing\", \"violation\", \"crash\", \"crash\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (timing status)\")\n",
        "                return \"filtering\"\n",
        "            # Recommendation patterns\n",
        "            elif any(word in question_lower for word in [\"recommend\", \"suggest\", \"optimize\", \"improve\", \"how can we\", \"what can we do\", \"make better\", \"better slack\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (recommendations)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for reasons/analysis specifically\n",
        "        if \"reason\" in question_lower or (\"why\" in question_lower and \"worst\" in question_lower):\n",
        "            return self._analyze_worst_slack_reasons(all_slack_data)\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _analyze_worst_slack_reasons(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Analyze reasons for worst slack\"\"\"\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        second_worst = sorted(all_slack_data, key=lambda x: x['slack'])[1] if len(all_slack_data) > 1 else worst_path\n",
        "\n",
        "        analysis_parts = []\n",
        "\n",
        "        # Analyze the worst path\n",
        "        analysis_parts.append(f\"📊 WORST SLACK ANALYSIS:\")\n",
        "        analysis_parts.append(f\"📍 Worst path: {worst_path['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"🔄 From: {worst_path['startpoint']} → {worst_path['endpoint']}\")\n",
        "\n",
        "        # Clock skew analysis\n",
        "        clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "        if clock_skew != 'N/A':\n",
        "            analysis_parts.append(f\"⏰ Clock skew: {clock_skew:.3f}ns\")\n",
        "            try:\n",
        "                if float(clock_skew) > 0.4:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH clock skew - impacts timing margin\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Moderate clock skew\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Hold time analysis\n",
        "        hold_time = worst_path.get('hold_time_requirement', 'N/A')\n",
        "        if hold_time != 'N/A':\n",
        "            analysis_parts.append(f\"🔒 Hold time requirement: {hold_time}ns\")\n",
        "            try:\n",
        "                if float(hold_time) > 0.1:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH hold time requirement\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Normal hold time requirement\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Comparative analysis\n",
        "        analysis_parts.append(f\"\\n📈 COMPARATIVE ANALYSIS:\")\n",
        "        analysis_parts.append(f\"🎯 Slack range: {worst_path['slack']:.3f}ns to {second_worst['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"💰 Margin difference: {second_worst['slack'] - worst_path['slack']:.3f}ns\")\n",
        "\n",
        "        # Summary assessment\n",
        "        analysis_parts.append(f\"\\n✅ TIMING STATUS:\")\n",
        "        analysis_parts.append(f\"🎯 Both paths PASS timing (positive slack)\")\n",
        "        analysis_parts.append(f\"⚠️ Small margins indicate timing sensitivity\")\n",
        "        analysis_parts.append(f\"💡 Consider design optimizations for robustness\")\n",
        "\n",
        "        return \"\\n\".join(analysis_parts)\n",
        "\n",
        "    def _generate_slack_improvement_recommendations(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Generate comprehensive slack improvement recommendations based on actual data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Determine number of recommendations requested\n",
        "        num_points = 10  # Default\n",
        "        if \"5 points\" in question_lower or \"5 point\" in question_lower:\n",
        "                num_points = 5\n",
        "        elif \"3 points\" in question_lower or \"3 point\" in question_lower:\n",
        "            num_points = 3\n",
        "\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        recommendations = []\n",
        "\n",
        "        # Analyze current timing situation\n",
        "        slack_values = [p['slack'] for p in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "\n",
        "        recommendations.append(f\"📊 CURRENT TIMING STATUS:\")\n",
        "        recommendations.append(f\"• Worst slack: {worst_path['slack']:.3f}ns\")\n",
        "        recommendations.append(f\"• Best slack: {best_path['slack']:.3f}ns\")\n",
        "        recommendations.append(f\"• Average slack: {avg_slack:.3f}ns\")\n",
        "        recommendations.append(f\"• All paths PASS timing ✅\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        recommendations.append(f\"🎯 TOP {num_points} SLACK IMPROVEMENT RECOMMENDATIONS:\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Clock skew optimization\n",
        "        clock_skews = [p.get('clock_skew', 0) for p in all_slack_data if p.get('clock_skew') != 'N/A']\n",
        "        if clock_skews and max(clock_skews) > 0.4:\n",
        "            recommendations.append(f\"1. 🔧 BALANCE CLOCK SKEW\")\n",
        "            recommendations.append(f\"   Current worst skew: {max(clock_skews):.3f}ns\")\n",
        "            recommendations.append(f\"   → Implement balanced clock distribution\")\n",
        "            recommendations.append(f\"   → Add buffer cells in high-skew regions\")\n",
        "            recommendations.append(f\"   → Optimize clock tree synthesis\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        # Hold time optimization\n",
        "        hold_times = [p.get('hold_time_requirement', 0) for p in all_slack_data if p.get('hold_time_requirement') != 'N/A']\n",
        "        if hold_times and max(hold_times) > 0.1:\n",
        "            recommendations.append(f\"2. ⏰ OPTIMIZE HOLD TIME REQUIREMENTS\")\n",
        "            recommendations.append(f\"   Current worst hold time: {max(hold_times):.3f}ns\")\n",
        "            recommendations.append(f\"   → Add hold buffers in critical paths\")\n",
        "            recommendations.append(f\"   → Optimize flip-flop timing\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        # Design optimization based on path analysis\n",
        "        recommendations.append(f\"{2 if clock_skews and max(clock_skews) > 0.4 else 3 if hold_times and max(hold_times) > 0.1 else 1}. 📐 OPTIMIZE DESIGN TOPOLOGY\")\n",
        "        recommendations.append(f\"   Worst path: {worst_path['startpoint']} → {worst_path['endpoint']}\")\n",
        "        if \"housekeeping\" in worst_path.get('startpoint', ''):\n",
        "            recommendations.append(f\"   → Housekeeping modules often have timing sensitivity\")\n",
        "            recommendations.append(f\"   → Consider register pipelining\")\n",
        "        recommendations.append(f\"   → Review logic synthesis constraints\")\n",
        "        recommendations.append(f\"   → Optimize wire routing and placement\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Slack margin improvement\n",
        "        recommendations.append(f\"{3 if clock_skews and max(clock_skews) > 0.4 else 4 if hold_times and max(hold_times) > 0.1 else 2}. 📈 IMPROVE TIMING MARGINS\")\n",
        "        recommendations.append(f\"   Current margins: {min_slack:.3f}ns to {max(slack_values):.3f}ns\")\n",
        "        recommendations.append(f\"   → Target minimum slack > 0.5ns for robustness\")\n",
        "        recommendations.append(f\"   → Consider operating condition guardbands\")\n",
        "        recommendations.append(f\"   → Add timing margin in synthesis\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Speed grade optimization\n",
        "        recommendations.append(f\"{4 if clock_skews and max(clock_skews) > 0.4 else 5 if hold_times and max(hold_times) > 0.1 else 3}. 🚀 SPEED GRADE OPTIMIZATION\")\n",
        "        recommendations.append(f\"   → Evaluate slower speed grades for better timing\")\n",
        "        recommendations.append(f\"   → Trade-off performance vs reliability\")\n",
        "        recommendations.append(f\"   → Consider multi-clock domain partitioning\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Temperature and voltage optimization\n",
        "        recommendations.append(f\"{5 if clock_skews and max(clock_skews) > 0.4 else 6 if hold_times and max(hold_times) > 0.1 else 4}. 🌡️ TEMPERATURE/VOLTAGE ANALYSIS\")\n",
        "        recommendations.append(f\"   → Analyze timing across temperature corners\")\n",
        "        recommendations.append(f\"   → Consider voltage scaling optimization\")\n",
        "        recommendations.append(f\"   → Review process corner sensitivity\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Add remaining recommendations to reach requested count\n",
        "        remaining_count = num_points - (5 if clock_skews and max(clock_skews) > 0.4 else 5 if hold_times and max(hold_times) > 0.1 else 5)\n",
        "\n",
        "        additional_recommendations = [\n",
        "            (\"6. 📋 DESIGN RULE OPTIMIZATION\", \"→ Minimize long wires\\n→ Add repeaters in nets > threshold\\n→ Optimize fanout distribution\"),\n",
        "            (\"7. 🔄 LOGIC OPTIMIZATION\", \"→ Use carry chains efficiently\\n→ Balance combinational logic\\n→ Pipeline critical sections\"),\n",
        "            (\"8. ⚡ POWER OPTIMIZATION\", \"→ Clock gating for unused blocks\\n→ Dynamic voltage scaling\\n→ Reduce switching activity\"),\n",
        "            (\"9. 🎯 CONSTRAINT REFINEMENT\", \"→ Review timing constraints\\n→ Add false/multicycle paths\\n→ Optimize I/O timing\"),\n",
        "            (\"10. 🧪 ANALYSIS IMPROVEMENT\", \"#  → Run Monte Carlo analysis\\n→ Add statistical timing\\n→ Review design coverage\")\n",
        "        ]\n",
        "\n",
        "        for i in range(min(remaining_count, len(additional_recommendations))):\n",
        "            # Calculate proper numbering based on previously added recommendations\n",
        "            base_num = 5\n",
        "            if clock_skews and max(clock_skews) > 0.4:\n",
        "                base_num = 6\n",
        "            elif hold_times and max(hold_times) > 0.1:\n",
        "                base_num = 6\n",
        "            else:\n",
        "                base_num = 4\n",
        "\n",
        "            idx = base_num + i\n",
        "            rec = additional_recommendations[i]\n",
        "            recommendations.append(f\"{idx}. {rec[0]}\")\n",
        "            recommendations.append(f\"   {rec[1]}\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        recommendations.append(\"⚠️  IMPORTANT: Current design PASSES timing. These recommendations optimize margins for robustness.\")\n",
        "\n",
        "        return \"\\n\".join(recommendations)\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries with condition parsing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Handle simple total counts first\n",
        "        if any(phrase in question_lower for phrase in [\"are there\", \"paths are\", \"how many\", \"total paths\", \"paths total\"]):\n",
        "            # Simple counting - just return total\n",
        "            return f\"Total number of timing paths: {len(all_slack_data)}\"\n",
        "\n",
        "        # Check for conditional counts\n",
        "        if \"slack\" in question_lower:\n",
        "            # Parse conditions like \"slack less than 1ns\", \"slack greater than 1ns\"\n",
        "            if \"less than\" in question_lower or \"below\" in question_lower or \"<\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"less\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] < threshold)\n",
        "                    return f\"Paths with slack less than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"greater than\" in question_lower or \"above\" in question_lower or \"more than\" in question_lower or \">\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"greater\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] > threshold)\n",
        "                    return f\"Paths with slack greater than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"equal to\" in question_lower or \"==\" in question_lower or \"=\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"equal\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] == threshold)\n",
        "                    return f\"Paths with slack equal to {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"between\" in question_lower:\n",
        "                # Extract range values\n",
        "                min_val, max_val = self._extract_range_from_question(question)\n",
        "                if min_val is not None and max_val is not None:\n",
        "                    count = sum(1 for path in all_slack_data if min_val <= path['slack'] <= max_val)\n",
        "                    return f\"Paths with slack between {min_val}ns and {max_val}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "        # Default to total count\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Handle recommendation queries with comprehensive advice\n",
        "        if any(word in question_lower for word in [\"recommend\", \"suggest\", \"optimize\", \"improve\", \"how can we\", \"what can we do\", \"make better\", \"better slack\"]):\n",
        "            return self._generate_slack_improvement_recommendations(all_slack_data, question)\n",
        "\n",
        "        # Check for timing status queries first\n",
        "        if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "            failing_paths = []\n",
        "            passing_paths = []\n",
        "\n",
        "            for path in all_slack_data:\n",
        "                slack = path['slack']\n",
        "                if slack < 0:\n",
        "                    failing_paths.append(path)\n",
        "                else:\n",
        "                    passing_paths.append(path)\n",
        "\n",
        "            results = []\n",
        "            if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\"]):\n",
        "                if failing_paths:\n",
        "                    results.append(\"🔴 FAILING PATHS (Negative Slack = Timing Violation):\")\n",
        "                    for path in failing_paths:\n",
        "                        results.append(f\"  📍 {path['startpoint']} → {path['endpoint']}: Slack={path['slack']:.3f}ns [VIOLATION]\")\n",
        "                else:\n",
        "                    results.append(\"✅ GOOD NEWS: NO FAILING PATHS!\")\n",
        "                    results.append(\"All paths have positive slack values (timing passes)\")\n",
        "                    results.append(f\"📊 Summary: {len(passing_paths)} paths PASS timing\")\n",
        "\n",
        "            elif any(word in question_lower for word in [\"passing\", \"pass\", \"critica\"]):\n",
        "                critical_count = sum(1 for p in passing_paths if 0 <= p['slack'] < 0.1)\n",
        "                results.append(f\"🟢 TIMING STATUS SUMMARY:\")\n",
        "                results.append(f\"  📈 PASSING PATHS: {len(passing_paths)} paths\")\n",
        "                results.append(f\"  📈 FAILING PATHS: {len(failing_paths)} paths\")\n",
        "                results.append(f\"  ⚠️ CRITICAL PATHS: {critical_count} paths with <0.1ns margin\")\n",
        "\n",
        "            return \"\\n\".join(results) if results else \"No timing status data available\"\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _extract_threshold_from_question(self, question: str, condition_type: str) -> float:\n",
        "        \"\"\"Extract numerical threshold from questions like 'slack less than 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns with numbers followed by 'ns'\n",
        "        patterns = [\n",
        "            r'(\\d+\\.?\\d*)\\s*ns',  # \"1ns\", \"1.5ns\", etc.\n",
        "            r'(\\d+\\.?\\d*)',       # Just numbers\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, question_lower)\n",
        "            if matches:\n",
        "                try:\n",
        "                    value = float(matches[-1])  # Take the last number found\n",
        "                    return value\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_range_from_question(self, question: str) -> tuple:\n",
        "        \"\"\"Extract range values from questions like 'slack between 0.5ns and 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for \"between X and Y\" patterns\n",
        "        pattern = r'between\\s+(\\d+\\.?\\d*)\\s+ns?\\s+and\\s+(\\d+\\.?\\d*)\\s+ns?'\n",
        "        match = re.search(pattern, question_lower)\n",
        "        if match:\n",
        "            try:\n",
        "                min_val = float(match.group(1))\n",
        "                max_val = float(match.group(2))\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        # Fallback: extract all numbers\n",
        "        numbers = re.findall(r'(\\d+\\.?\\d*)', question_lower)\n",
        "        if len(numbers) >= 2:\n",
        "            try:\n",
        "                min_val = float(numbers[0])\n",
        "                max_val = float(numbers[1])\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def _create_focused_context(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Create focused context to avoid overwhelming LLM\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Focus on relevant data based on question\n",
        "        if \"worst\" in question_lower or \"bad\" in question_lower:\n",
        "            worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Worst path: {worst_path['slack']}ns slack, {worst_path['startpoint']}→{worst_path['endpoint']}, clock_skew:{worst_path.get('clock_skew', 'N/A')}, hold_time:{worst_path.get('hold_time_requirement', 'N/A')}\"\n",
        "\n",
        "        elif \"best\" in question_lower or \"good\" in question_lower:\n",
        "            best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Best path: {best_path['slack']}ns slack, {best_path['startpoint']}→{best_path['endpoint']}\"\n",
        "\n",
        "        else:\n",
        "            # General summary\n",
        "            slack_values = [p['slack'] for p in all_slack_data]\n",
        "            return f\"{len(all_slack_data)} paths: slack range {min(slack_values):.3f} to {max(slack_values):.3f}ns, all positive (pass timing)\"\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        # Create focused context to avoid overwhelming the model\n",
        "        summary_context = self._create_focused_context(self._get_all_slack_data(), question)\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] Timing Analysis Question:\n",
        "\n",
        "Data: {summary_context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer briefly (2-4 lines): [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            import threading\n",
        "            import time\n",
        "\n",
        "            result = [None]\n",
        "            exception = [None]\n",
        "\n",
        "            def generate_worker():\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = self.llm_model.generate(\n",
        "                            inputs,\n",
        "                            attention_mask=attention_mask,\n",
        "                            max_new_tokens=50,  # Reduced for faster generation\n",
        "                            num_return_sequences=1,\n",
        "                            temperature=0.3,  # Lower temp for consistency\n",
        "                            do_sample=False,   # Deterministic\n",
        "                            pad_token_id=self.tokenizer.eos_token_id,\n",
        "                            eos_token_id=self.tokenizer.eos_token_id,\n",
        "                            early_stopping=True\n",
        "                        )\n",
        "                        result[0] = outputs\n",
        "                except Exception as e:\n",
        "                    exception[0] = e\n",
        "\n",
        "            # Start generation in a thread\n",
        "            thread = threading.Thread(target=generate_worker)\n",
        "            thread.start()\n",
        "            thread.join(timeout=15)  # 15 second timeout\n",
        "\n",
        "            if thread.is_alive():\n",
        "                print(\"DEBUG: LLM generation timed out after 15s, killing thread and using fallback...\")\n",
        "                # Thread is still alive, can't kill it cleanly, but let it continue in background\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if exception[0]:\n",
        "                print(f\"DEBUG: LLM generation failed: {exception[0]}, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if result[0] is None:\n",
        "                print(\"DEBUG: No result from LLM, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            outputs = result[0]\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "\n",
        "            # If answer is too short or seems incomplete, use fallback\n",
        "            if len(answer.strip()) < 10:\n",
        "                print(\"DEBUG: LLM response too short, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return self._generate_fallback_answer(question, None)\n",
        "\n",
        "    def _generate_fallback_answer(self, question: str, context_or_data) -> str:\n",
        "        \"\"\"Generate fallback answer when LLM fails\"\"\"\n",
        "        print(\"DEBUG: Generating fallback answer...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Always get fresh data for fallback\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Handle specific question types with direct logic\n",
        "        if \"worst slack\" in question_lower or \"reason\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "                clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "                hold_req = worst_path.get('hold_time_requirement', 'N/A')\n",
        "\n",
        "                reason_parts = []\n",
        "                if clock_skew != 'N/A':\n",
        "                    try:\n",
        "                        if float(clock_skew) > 0.4:\n",
        "                            reason_parts.append(f\"High clock skew ({clock_skew}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "                if hold_req != 'N/A':\n",
        "                    try:\n",
        "                        if float(hold_req) > 0.1:\n",
        "                            reason_parts.append(f\"High hold time requirement ({hold_req}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                if not reason_parts:\n",
        "                    reason_parts.append(\"Slack is positive but small margin\")\n",
        "\n",
        "                return f\"\"\"Worst slack: {worst_path['slack']:.3f}ns for {worst_path['startpoint']} → {worst_path['endpoint']}\n",
        "\n",
        "Potential reasons:\n",
        "{chr(10).join('- ' + reason for reason in reason_parts)}\n",
        "\n",
        "Note: This path still passes timing (positive slack) but has the smallest margin.\"\"\"\n",
        "\n",
        "        elif \"reason\" in question_lower or \"why\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                return f\"\"\"Timing Analysis Summary:\n",
        "- Total paths: {len(all_slack_data)}\n",
        "- All paths PASS timing (positive slack)\n",
        "- Slack range: {min(p['slack'] for p in all_slack_data):.3f}ns to {max(p['slack'] for p in all_slack_data):.3f}ns\n",
        "\n",
        "Potential timing concerns:\n",
        "- Small slack margins (both < 1ns)\n",
        "- Clock skew and hold time requirements may impact design margin\"\"\"\n",
        "\n",
        "        else:\n",
        "            return f\"Analysis unavailable due to LLM timeout. Raw data: {len(all_slack_data)} paths processed.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                current_slack = slack_values[i-1]\n",
        "                if current_slack < 0:\n",
        "                    context += f\"  Slack analysis: TIMING FAILURE (negative slack = violation)\\n\"\n",
        "                elif current_slack < 0.1:\n",
        "                    context += f\"  Slack analysis: CRITICAL (very small positive margin)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: TIMING PASS (adequate positive margin)\\n\"\n",
        "\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may impact timing margin)\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- POSITIVE slack = timing PASS (data arrives before required time)\\n\"\n",
        "        context += \"- NEGATIVE slack = timing FAILURE (violation)\\n\"\n",
        "        context += \"- Slack < 0.1ns = critical margin (close to violation)\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Current data shows ONLY positive slacks (all paths PASS)\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Basic ranking\n",
        "            \"total\", \"count\", \"number of\",                           # Simple counts (NO conditions)\n",
        "            \"how many\",                                              # counting questions\n",
        "            \"paths are\", \"are there\", \"paths total\",                # Simple counting variations\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Basic statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Simple timing status patterns (can be handled fast)\n",
        "        timing_status_patterns = [\n",
        "            \"failing\", \"violation\", \"fail\", \"failed\",            # Timing status\n",
        "            \"passing\", \"pass\", \"passed\",                          # Timing status\n",
        "            \"critical\", \"borderline\"                             # Timing status\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "            \"less than\", \"greater than\", \"more than\", \"between\",   # Conditional queries\n",
        "            \"above\", \"below\", \"equal to\", \"higher than\", \"lower than\",  # Additional conditions\n",
        "            \"can slacks\", \"if clock\", \"relationship\", \"how does\",  # Technical reasoning\n",
        "            \"positive clock\", \"negative clock\", \"skew effect\"      # Clock skew analysis\n",
        "        ]\n",
        "\n",
        "        # Recommendation patterns (should handle with direct logic, not LLM)\n",
        "        recommendation_patterns = [\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",\n",
        "            \"how can we\", \"what can we do\", \"how to improve\",\n",
        "            \"make better\", \"improve slack\", \"better slack\"\n",
        "        ]\n",
        "\n",
        "        # Check for simple timing status patterns first\n",
        "        for pattern in timing_status_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for recommendation patterns (handle with direct logic)\n",
        "        for pattern in recommendation_patterns:\n",
        "            if pattern in question_lower:\n",
        "                print(f\"DEBUG: Detected recommendation pattern '{pattern}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Force simple classification for certain problematic phrases\n",
        "        problematic_phrases = [\n",
        "            \"reason for worst slack\",\n",
        "            \"why worst slack\",\n",
        "            \"worst slack reason\"\n",
        "        ]\n",
        "        for phrase in problematic_phrases:\n",
        "            if phrase in question_lower:\n",
        "                print(f\"DEBUG: Detected problematic phrase '{phrase}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\", \"are there\", \"paths are\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Timing status patterns\n",
        "            elif any(word in question_lower for word in [\"failing\", \"violation\", \"crash\", \"crash\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (timing status)\")\n",
        "                return \"filtering\"\n",
        "            # Recommendation patterns\n",
        "            elif any(word in question_lower for word in [\"recommend\", \"suggest\", \"optimize\", \"improve\", \"how can we\", \"what can we do\", \"make better\", \"better slack\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (recommendations)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries using LLM with structured data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for reasons/analysis specifically\n",
        "        if \"reason\" in question_lower or (\"why\" in question_lower and \"worst\" in question_lower):\n",
        "            return self._analyze_worst_slack_reasons(all_slack_data)\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _analyze_worst_slack_reasons(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Analyze reasons for worst slack\"\"\"\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        second_worst = sorted(all_slack_data, key=lambda x: x['slack'])[1] if len(all_slack_data) > 1 else worst_path\n",
        "\n",
        "        analysis_parts = []\n",
        "\n",
        "        # Analyze the worst path\n",
        "        analysis_parts.append(f\"📊 WORST SLACK ANALYSIS:\")\n",
        "        analysis_parts.append(f\"📍 Worst path: {worst_path['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"🔄 From: {worst_path['startpoint']} → {worst_path['endpoint']}\")\n",
        "\n",
        "        # Clock skew analysis\n",
        "        clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "        if clock_skew != 'N/A':\n",
        "            analysis_parts.append(f\"⏰ Clock skew: {clock_skew:.3f}ns\")\n",
        "            try:\n",
        "                if float(clock_skew) > 0.4:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH clock skew - impacts timing margin\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Moderate clock skew\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Hold time analysis\n",
        "        hold_time = worst_path.get('hold_time_requirement', 'N/A')\n",
        "        if hold_time != 'N/A':\n",
        "            analysis_parts.append(f\"🔒 Hold time requirement: {hold_time}ns\")\n",
        "            try:\n",
        "                if float(hold_time) > 0.1:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH hold time requirement\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Normal hold time requirement\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Comparative analysis\n",
        "        analysis_parts.append(f\"\\n📈 COMPARATIVE ANALYSIS:\")\n",
        "        analysis_parts.append(f\"🎯 Slack range: {worst_path['slack']:.3f}ns to {second_worst['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"💰 Margin difference: {second_worst['slack'] - worst_path['slack']:.3f}ns\")\n",
        "\n",
        "        # Summary assessment\n",
        "        analysis_parts.append(f\"\\n✅ TIMING STATUS:\")\n",
        "        analysis_parts.append(f\"🎯 Both paths PASS timing (positive slack)\")\n",
        "        analysis_parts.append(f\"⚠️ Small margins indicate timing sensitivity\")\n",
        "        analysis_parts.append(f\"💡 Consider design optimizations for robustness\")\n",
        "\n",
        "        return \"\\n\".join(analysis_parts)\n",
        "\n",
        "    def _generate_slack_improvement_recommendations(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Generate comprehensive slack improvement recommendations based on actual data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Determine number of recommendations requested\n",
        "        num_points = 10  # Default\n",
        "        if \"5 points\" in question_lower or \"5 point\" in question_lower:\n",
        "                num_points = 5\n",
        "        elif \"3 points\" in question_lower or \"3 point\" in question_lower:\n",
        "            num_points = 3\n",
        "\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        recommendations = []\n",
        "\n",
        "        # Analyze current timing situation\n",
        "        slack_values = [p['slack'] for p in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "\n",
        "        recommendations.append(f\"📊 CURRENT TIMING STATUS:\")\n",
        "        recommendations.append(f\"• Worst slack: {worst_path['slack']:.3f}ns\")\n",
        "        recommendations.append(f\"• Best slack: {best_path['slack']:.3f}ns\")\n",
        "        recommendations.append(f\"• Average slack: {avg_slack:.3f}ns\")\n",
        "        recommendations.append(f\"• All paths PASS timing ✅\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        recommendations.append(f\"🎯 TOP {num_points} SLACK IMPROVEMENT RECOMMENDATIONS:\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Clock skew optimization\n",
        "        clock_skews = [p.get('clock_skew', 0) for p in all_slack_data if p.get('clock_skew') != 'N/A']\n",
        "        if clock_skews and max(clock_skews) > 0.4:\n",
        "            recommendations.append(f\"1. 🔧 BALANCE CLOCK SKEW\")\n",
        "            recommendations.append(f\"   Current worst skew: {max(clock_skews):.3f}ns\")\n",
        "            recommendations.append(f\"   → Implement balanced clock distribution\")\n",
        "            recommendations.append(f\"   → Add buffer cells in high-skew regions\")\n",
        "            recommendations.append(f\"   → Optimize clock tree synthesis\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        # Hold time optimization\n",
        "        hold_times = [p.get('hold_time_requirement', 0) for p in all_slack_data if p.get('hold_time_requirement') != 'N/A']\n",
        "        if hold_times and max(hold_times) > 0.1:\n",
        "            recommendations.append(f\"2. ⏰ OPTIMIZE HOLD TIME REQUIREMENTS\")\n",
        "            recommendations.append(f\"   Current worst hold time: {max(hold_times):.3f}ns\")\n",
        "            recommendations.append(f\"   → Add hold buffers in critical paths\")\n",
        "            recommendations.append(f\"   → Optimize flip-flop timing\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        # Design optimization based on path analysis\n",
        "        recommendations.append(f\"{2 if clock_skews and max(clock_skews) > 0.4 else 3 if hold_times and max(hold_times) > 0.1 else 1}. 📐 OPTIMIZE DESIGN TOPOLOGY\")\n",
        "        recommendations.append(f\"   Worst path: {worst_path['startpoint']} → {worst_path['endpoint']}\")\n",
        "        if \"housekeeping\" in worst_path.get('startpoint', ''):\n",
        "            recommendations.append(f\"   → Housekeeping modules often have timing sensitivity\")\n",
        "            recommendations.append(f\"   → Consider register pipelining\")\n",
        "        recommendations.append(f\"   → Review logic synthesis constraints\")\n",
        "        recommendations.append(f\"   → Optimize wire routing and placement\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Slack margin improvement\n",
        "        recommendations.append(f\"{3 if clock_skews and max(clock_skews) > 0.4 else 4 if hold_times and max(hold_times) > 0.1 else 2}. 📈 IMPROVE TIMING MARGINS\")\n",
        "        recommendations.append(f\"   Current margins: {min_slack:.3f}ns to {max(slack_values):.3f}ns\")\n",
        "        recommendations.append(f\"   → Target minimum slack > 0.5ns for robustness\")\n",
        "        recommendations.append(f\"   → Consider operating condition guardbands\")\n",
        "        recommendations.append(f\"   → Add timing margin in synthesis\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Speed grade optimization\n",
        "        recommendations.append(f\"{4 if clock_skews and max(clock_skews) > 0.4 else 5 if hold_times and max(hold_times) > 0.1 else 3}. 🚀 SPEED GRADE OPTIMIZATION\")\n",
        "        recommendations.append(f\"   → Evaluate slower speed grades for better timing\")\n",
        "        recommendations.append(f\"   → Trade-off performance vs reliability\")\n",
        "        recommendations.append(f\"   → Consider multi-clock domain partitioning\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Temperature and voltage optimization\n",
        "        recommendations.append(f\"{5 if clock_skews and max(clock_skews) > 0.4 else 6 if hold_times and max(hold_times) > 0.1 else 4}. 🌡️ TEMPERATURE/VOLTAGE ANALYSIS\")\n",
        "        recommendations.append(f\"   → Analyze timing across temperature corners\")\n",
        "        recommendations.append(f\"   → Consider voltage scaling optimization\")\n",
        "        recommendations.append(f\"   → Review process corner sensitivity\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Add remaining recommendations to reach requested count\n",
        "        remaining_count = num_points - (5 if clock_skews and max(clock_skews) > 0.4 else 5 if hold_times and max(hold_times) > 0.1 else 5)\n",
        "\n",
        "        additional_recommendations = [\n",
        "            (\"6. 📋 DESIGN RULE OPTIMIZATION\", \"→ Minimize long wires\\n→ Add repeaters in nets > threshold\\n→ Optimize fanout distribution\"),\n",
        "            (\"7. 🔄 LOGIC OPTIMIZATION\", \"→ Use carry chains efficiently\\n→ Balance combinational logic\\n→ Pipeline critical sections\"),\n",
        "            (\"8. ⚡ POWER OPTIMIZATION\", \"→ Clock gating for unused blocks\\n→ Dynamic voltage scaling\\n→ Reduce switching activity\"),\n",
        "            (\"9. 🎯 CONSTRAINT REFINEMENT\", \"→ Review timing constraints\\n→ Add false/multicycle paths\\n→ Optimize I/O timing\"),\n",
        "            (\"10. 🧪 ANALYSIS IMPROVEMENT\", \"#  → Run Monte Carlo analysis\\n→ Add statistical timing\\n→ Review design coverage\")\n",
        "        ]\n",
        "\n",
        "        for i in range(min(remaining_count, len(additional_recommendations))):\n",
        "            # Calculate proper numbering based on previously added recommendations\n",
        "            base_num = 5\n",
        "            if clock_skews and max(clock_skews) > 0.4:\n",
        "                base_num = 6\n",
        "            elif hold_times and max(hold_times) > 0.1:\n",
        "                base_num = 6\n",
        "            else:\n",
        "                base_num = 4\n",
        "\n",
        "            idx = base_num + i\n",
        "            rec = additional_recommendations[i]\n",
        "            recommendations.append(f\"{idx}. {rec[0]}\")\n",
        "            recommendations.append(f\"   {rec[1]}\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        recommendations.append(\"⚠️  IMPORTANT: Current design PASSES timing. These recommendations optimize margins for robustness.\")\n",
        "\n",
        "        return \"\\n\".join(recommendations)\n",
        "\n",
        "    def _generate_technical_reasoning(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Generate technical reasoning about timing relationships\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Clock skew vs slack analysis\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            return self._explain_clock_skew_relationship(all_slack_data, question)\n",
        "\n",
        "        # General timing relationships\n",
        "        return self._explain_timing_relationships(all_slack_data, question)\n",
        "\n",
        "    def _explain_clock_skew_relationship(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Explain the relationship between clock skew and slack\"\"\"\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get actual clock skew values\n",
        "        clock_skews = [p.get('clock_skew', 0) for p in all_slack_data if p.get('clock_skew') != 'N/A']\n",
        "        current_skew = clock_skews[0] if clock_skews else 0.5  # Use first available skew\n",
        "\n",
        "        explanation = []\n",
        "        explanation.append(\"🔬 CLOCK SKEW vs SLACK RELATIONSHIP:\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"📊 CURRENT DATA:\")\n",
        "        explanation.append(f\"• Current clock skew: {current_skew:.3f}ns\")\n",
        "        explanation.append(f\"• Worst slack: {worst_path['slack']:.3f}ns\")\n",
        "        explanation.append(f\"• Best slack: {best_path['slack']:.3f}ns\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"🧠 TECHNICAL EXPLANATION:\")\n",
        "        explanation.append(\"\")\n",
        "        explanation.append(\"Clock skew affects slack through timing paths:\")\n",
        "        explanation.append(\"\")\n",
        "        explanation.append(\"🔸 POSITIVE CLOCK SKEW (launch clock arrives LATER):\")\n",
        "        explanation.append(\"   • Data has MORE time to propagate\")\n",
        "        explanation.append(\"   • → SLACK IMPROVES (becomes more positive)\")\n",
        "        explanation.append(\"   • → Better timing margin\")\n",
        "        explanation.append(\"\")\n",
        "        explanation.append(\"🔸 NEGATIVE CLOCK SKEW (launch clock arrives EARLIER):\")\n",
        "        explanation.append(\"   • Data has LESS time to propagate\")\n",
        "        explanation.append(\"   • → SLACK DEGRADES (becomes less positive)\")\n",
        "        explanation.append(\"   • → Worse timing margin\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"📐 MATHEMATICAL RELATIONSHIP:\")\n",
        "        explanation.append(\"Slack = Required_Time - Arrival_Time\")\n",
        "        explanation.append(\"If clock_skew increases (more positive):\")\n",
        "        explanation.append(\"→ Required_Time increases\")\n",
        "        explanation.append(\"→ Slack = (Required_Time + skew) - Arrival_Time\")\n",
        "        explanation.append(\"→ Slack IMPROVES ✅\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"🎯 ANSWER TO YOUR QUESTION:\")\n",
        "        explanation.append(\"If clock skews become MORE POSITIVE:\")\n",
        "        explanation.append(\"→ SLACKS WILL IMPROVE (become more positive)\")\n",
        "        explanation.append(\"→ Better timing margins\")\n",
        "        explanation.append(\"→ More robust design\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"⚠️  PRACTICAL CONSIDERATIONS:\")\n",
        "        explanation.append(\"• Positive skew helps setup timing\")\n",
        "        explanation.append(\"• But may hurt hold timing\")\n",
        "        explanation.append(\"• Balance between setup and hold is critical\")\n",
        "        explanation.append(\"• Current design shows moderate skew (0.5ns)\")\n",
        "\n",
        "        return \"\\n\".join(explanation)\n",
        "\n",
        "    def _explain_timing_relationships(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"General timing relationship explanations\"\"\"\n",
        "        explanation = []\n",
        "        explanation.append(\"🔬 TIMING RELATIONSHIPS EXPLANATION:\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        # Basic timing concepts\n",
        "        explanation.append(\"📚 FUNDAMENTAL TIMING CONCEPTS:\")\n",
        "        explanation.append(\"• Setup Time: Data must be stable before clock edge\")\n",
        "        explanation.append(\"• Hold Time: Data must remain stable after clock edge\")\n",
        "        explanation.append(\"• Slack: Margin between arrival and required time\")\n",
        "        explanation.append(\"• Clock Skew: Difference in clock arrival times\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"🎯 KEY RELATIONSHIPS:\")\n",
        "        explanation.append(\"• More positive slack = Better timing margin\")\n",
        "        explanation.append(\"• Clock skew affects both setup and hold timing\")\n",
        "        explanation.append(\"• Temperature/voltage variations impact timing\")\n",
        "        explanation.append(\"• Process corners affect all timing parameters\")\n",
        "\n",
        "        return \"\\n\".join(explanation)\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries with condition parsing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Handle simple total counts first\n",
        "        if any(phrase in question_lower for phrase in [\"are there\", \"paths are\", \"how many\", \"total paths\", \"paths total\"]):\n",
        "            # Simple counting - just return total\n",
        "            return f\"Total number of timing paths: {len(all_slack_data)}\"\n",
        "\n",
        "        # Check for conditional counts\n",
        "        if \"slack\" in question_lower:\n",
        "            # Parse conditions like \"slack less than 1ns\", \"slack greater than 1ns\"\n",
        "            if \"less than\" in question_lower or \"below\" in question_lower or \"<\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"less\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] < threshold)\n",
        "                    return f\"Paths with slack less than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"greater than\" in question_lower or \"above\" in question_lower or \"more than\" in question_lower or \">\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"greater\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] > threshold)\n",
        "                    return f\"Paths with slack greater than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"equal to\" in question_lower or \"==\" in question_lower or \"=\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"equal\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] == threshold)\n",
        "                    return f\"Paths with slack equal to {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"between\" in question_lower:\n",
        "                # Extract range values\n",
        "                min_val, max_val = self._extract_range_from_question(question)\n",
        "                if min_val is not None and max_val is not None:\n",
        "                    count = sum(1 for path in all_slack_data if min_val <= path['slack'] <= max_val)\n",
        "                    return f\"Paths with slack between {min_val}ns and {max_val}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "        # Default to total count\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Handle technical reasoning queries\n",
        "        if any(word in question_lower for word in [\"can slacks\", \"if clock\", \"relationship\", \"how does\", \"positive clock\", \"negative clock\", \"skew effect\"]):\n",
        "            return self._generate_technical_reasoning(all_slack_data, question)\n",
        "\n",
        "        # Handle recommendation queries with comprehensive advice\n",
        "        if any(word in question_lower for word in [\"recommend\", \"suggest\", \"optimize\", \"improve\", \"how can we\", \"what can we do\", \"make better\", \"better slack\"]):\n",
        "            return self._generate_slack_improvement_recommendations(all_slack_data, question)\n",
        "\n",
        "        # Check for timing status queries first\n",
        "        if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "            failing_paths = []\n",
        "            passing_paths = []\n",
        "\n",
        "            for path in all_slack_data:\n",
        "                slack = path['slack']\n",
        "                if slack < 0:\n",
        "                    failing_paths.append(path)\n",
        "                else:\n",
        "                    passing_paths.append(path)\n",
        "\n",
        "            results = []\n",
        "            if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\"]):\n",
        "                if failing_paths:\n",
        "                    results.append(\"🔴 FAILING PATHS (Negative Slack = Timing Violation):\")\n",
        "                    for path in failing_paths:\n",
        "                        results.append(f\"  📍 {path['startpoint']} → {path['endpoint']}: Slack={path['slack']:.3f}ns [VIOLATION]\")\n",
        "                else:\n",
        "                    results.append(\"✅ GOOD NEWS: NO FAILING PATHS!\")\n",
        "                    results.append(\"All paths have positive slack values (timing passes)\")\n",
        "                    results.append(f\"📊 Summary: {len(passing_paths)} paths PASS timing\")\n",
        "\n",
        "            elif any(word in question_lower for word in [\"passing\", \"pass\", \"critica\"]):\n",
        "                critical_count = sum(1 for p in passing_paths if 0 <= p['slack'] < 0.1)\n",
        "                results.append(f\"🟢 TIMING STATUS SUMMARY:\")\n",
        "                results.append(f\"  📈 PASSING PATHS: {len(passing_paths)} paths\")\n",
        "                results.append(f\"  📈 FAILING PATHS: {len(failing_paths)} paths\")\n",
        "                results.append(f\"  ⚠️ CRITICAL PATHS: {critical_count} paths with <0.1ns margin\")\n",
        "\n",
        "            return \"\\n\".join(results) if results else \"No timing status data available\"\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _extract_threshold_from_question(self, question: str, condition_type: str) -> float:\n",
        "        \"\"\"Extract numerical threshold from questions like 'slack less than 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns with numbers followed by 'ns'\n",
        "        patterns = [\n",
        "            r'(\\d+\\.?\\d*)\\s*ns',  # \"1ns\", \"1.5ns\", etc.\n",
        "            r'(\\d+\\.?\\d*)',       # Just numbers\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, question_lower)\n",
        "            if matches:\n",
        "                try:\n",
        "                    value = float(matches[-1])  # Take the last number found\n",
        "                    return value\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_range_from_question(self, question: str) -> tuple:\n",
        "        \"\"\"Extract range values from questions like 'slack between 0.5ns and 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for \"between X and Y\" patterns\n",
        "        pattern = r'between\\s+(\\d+\\.?\\d*)\\s+ns?\\s+and\\s+(\\d+\\.?\\d*)\\s+ns?'\n",
        "        match = re.search(pattern, question_lower)\n",
        "        if match:\n",
        "            try:\n",
        "                min_val = float(match.group(1))\n",
        "                max_val = float(match.group(2))\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        # Fallback: extract all numbers\n",
        "        numbers = re.findall(r'(\\d+\\.?\\d*)', question_lower)\n",
        "        if len(numbers) >= 2:\n",
        "            try:\n",
        "                min_val = float(numbers[0])\n",
        "                max_val = float(numbers[1])\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def _create_focused_context(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Create focused context to avoid overwhelming LLM\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Focus on relevant data based on question\n",
        "        if \"worst\" in question_lower or \"bad\" in question_lower:\n",
        "            worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Worst path: {worst_path['slack']}ns slack, {worst_path['startpoint']}→{worst_path['endpoint']}, clock_skew:{worst_path.get('clock_skew', 'N/A')}, hold_time:{worst_path.get('hold_time_requirement', 'N/A')}\"\n",
        "\n",
        "        elif \"best\" in question_lower or \"good\" in question_lower:\n",
        "            best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Best path: {best_path['slack']}ns slack, {best_path['startpoint']}→{best_path['endpoint']}\"\n",
        "\n",
        "        else:\n",
        "            # General summary\n",
        "            slack_values = [p['slack'] for p in all_slack_data]\n",
        "            return f\"{len(all_slack_data)} paths: slack range {min(slack_values):.3f} to {max(slack_values):.3f}ns, all positive (pass timing)\"\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        # Create focused context to avoid overwhelming the model\n",
        "        summary_context = self._create_focused_context(self._get_all_slack_data(), question)\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] Timing Analysis Question:\n",
        "\n",
        "Data: {summary_context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer briefly (2-4 lines): [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            import threading\n",
        "            import time\n",
        "\n",
        "            result = [None]\n",
        "            exception = [None]\n",
        "\n",
        "            def generate_worker():\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = self.llm_model.generate(\n",
        "                            inputs,\n",
        "                            attention_mask=attention_mask,\n",
        "                            max_new_tokens=50,  # Reduced for faster generation\n",
        "                            num_return_sequences=1,\n",
        "                            temperature=0.3,  # Lower temp for consistency\n",
        "                            do_sample=False,   # Deterministic\n",
        "                            pad_token_id=self.tokenizer.eos_token_id,\n",
        "                            eos_token_id=self.tokenizer.eos_token_id,\n",
        "                            early_stopping=True\n",
        "                        )\n",
        "                        result[0] = outputs\n",
        "                except Exception as e:\n",
        "                    exception[0] = e\n",
        "\n",
        "            # Start generation in a thread\n",
        "            thread = threading.Thread(target=generate_worker)\n",
        "            thread.start()\n",
        "            thread.join(timeout=15)  # 15 second timeout\n",
        "\n",
        "            if thread.is_alive():\n",
        "                print(\"DEBUG: LLM generation timed out after 15s, killing thread and using fallback...\")\n",
        "                # Thread is still alive, can't kill it cleanly, but let it continue in background\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if exception[0]:\n",
        "                print(f\"DEBUG: LLM generation failed: {exception[0]}, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if result[0] is None:\n",
        "                print(\"DEBUG: No result from LLM, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            outputs = result[0]\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "\n",
        "            # If answer is too short or seems incomplete, use fallback\n",
        "            if len(answer.strip()) < 10:\n",
        "                print(\"DEBUG: LLM response too short, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return self._generate_fallback_answer(question, None)\n",
        "\n",
        "    def _generate_fallback_answer(self, question: str, context_or_data) -> str:\n",
        "        \"\"\"Generate fallback answer when LLM fails\"\"\"\n",
        "        print(\"DEBUG: Generating fallback answer...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Always get fresh data for fallback\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Handle specific question types with direct logic\n",
        "        if \"worst slack\" in question_lower or \"reason\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "                clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "                hold_req = worst_path.get('hold_time_requirement', 'N/A')\n",
        "\n",
        "                reason_parts = []\n",
        "                if clock_skew != 'N/A':\n",
        "                    try:\n",
        "                        if float(clock_skew) > 0.4:\n",
        "                            reason_parts.append(f\"High clock skew ({clock_skew}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "                if hold_req != 'N/A':\n",
        "                    try:\n",
        "                        if float(hold_req) > 0.1:\n",
        "                            reason_parts.append(f\"High hold time requirement ({hold_req}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                if not reason_parts:\n",
        "                    reason_parts.append(\"Slack is positive but small margin\")\n",
        "\n",
        "                return f\"\"\"Worst slack: {worst_path['slack']:.3f}ns for {worst_path['startpoint']} → {worst_path['endpoint']}\n",
        "\n",
        "Potential reasons:\n",
        "{chr(10).join('- ' + reason for reason in reason_parts)}\n",
        "\n",
        "Note: This path still passes timing (positive slack) but has the smallest margin.\"\"\"\n",
        "\n",
        "        elif \"reason\" in question_lower or \"why\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                return f\"\"\"Timing Analysis Summary:\n",
        "- Total paths: {len(all_slack_data)}\n",
        "- All paths PASS timing (positive slack)\n",
        "- Slack range: {min(p['slack'] for p in all_slack_data):.3f}ns to {max(p['slack'] for p in all_slack_data):.3f}ns\n",
        "\n",
        "Potential timing concerns:\n",
        "- Small slack margins (both < 1ns)\n",
        "- Clock skew and hold time requirements may impact design margin\"\"\"\n",
        "\n",
        "        else:\n",
        "            return f\"Analysis unavailable due to LLM timeout. Raw data: {len(all_slack_data)} paths processed.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                current_slack = slack_values[i-1]\n",
        "                if current_slack < 0:\n",
        "                    context += f\"  Slack analysis: TIMING FAILURE (negative slack = violation)\\n\"\n",
        "                elif current_slack < 0.1:\n",
        "                    context += f\"  Slack analysis: CRITICAL (very small positive margin)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: TIMING PASS (adequate positive margin)\\n\"\n",
        "\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may impact timing margin)\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- POSITIVE slack = timing PASS (data arrives before required time)\\n\"\n",
        "        context += \"- NEGATIVE slack = timing FAILURE (violation)\\n\"\n",
        "        context += \"- Slack < 0.1ns = critical margin (close to violation)\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Current data shows ONLY positive slacks (all paths PASS)\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "90fd5ff9934946f580366c33cc32b8be",
            "384bb512dcf84618a98d14764a390ba8",
            "0f020033709e44549f912a249a6b52da",
            "428974ef9b1748bcbadf634c8d23a253",
            "f44a3bee8a8243bba40db74975986fc1",
            "786a158f3d58411e868954e98dc8f7ab",
            "23ab49b129fb4d8e9b57923bb09c9669",
            "4ab02e6b745342c7802d8549d8f222f1",
            "4acf8832e0f6494394f2af3b4f3bce58",
            "27170cf1aadd495a9e4d138b25978337",
            "2204485f8d244817990180e6b157bf2b"
          ]
        },
        "id": "8w764_zHtfjD",
        "outputId": "18c39dd5-9067-4ef6-825f-cafec31ad95a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90fd5ff9934946f580366c33cc32b8be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 659 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: if clock skews are more +ve, can slacks improve or degrade?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'if clock skews are more +ve, can slacks improve or degrade?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'if clock skews are more +ve, can slacks improve or degrade?'\n",
            "DEBUG: Detected recommendation pattern 'improve', forcing simple classification\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'filtering' (clock skew)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.05s\n",
            "Answer: 🔬 CLOCK SKEW vs SLACK RELATIONSHIP:\n",
            "\n",
            "📊 CURRENT DATA:\n",
            "• Current clock skew: 0.500ns\n",
            "• Worst slack: 0.325ns\n",
            "• Best slack: 2.430ns\n",
            "\n",
            "🧠 TECHNICAL EXPLANATION:\n",
            "\n",
            "Clock skew affects slack through timing paths:\n",
            "\n",
            "🔸 POSITIVE CLOCK SKEW (launch clock arrives LATER):\n",
            "   • Data has MORE time to propagate\n",
            "   • → SLACK IMPROVES (becomes more positive)\n",
            "   • → Better timing margin\n",
            "\n",
            "🔸 NEGATIVE CLOCK SKEW (launch clock arrives EARLIER):\n",
            "   • Data has LESS time to propagate\n",
            "   • → SLACK DEGRADES (becomes less positive)\n",
            "   • → Worse timing margin\n",
            "\n",
            "📐 MATHEMATICAL RELATIONSHIP:\n",
            "Slack = Required_Time - Arrival_Time\n",
            "If clock_skew increases (more positive):\n",
            "→ Required_Time increases\n",
            "→ Slack = (Required_Time + skew) - Arrival_Time\n",
            "→ Slack IMPROVES ✅\n",
            "\n",
            "🎯 ANSWER TO YOUR QUESTION:\n",
            "If clock skews become MORE POSITIVE:\n",
            "→ SLACKS WILL IMPROVE (become more positive)\n",
            "→ Better timing margins\n",
            "→ More robust design\n",
            "\n",
            "⚠️  PRACTICAL CONSIDERATIONS:\n",
            "• Positive skew helps setup timing\n",
            "• But may hurt hold timing\n",
            "• Balance between setup and hold is critical\n",
            "• Current design shows moderate skew (0.5ns)\n",
            "\n",
            "Question: how can we improve slack?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'how can we improve slack?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'how can we improve slack?'\n",
            "DEBUG: Detected recommendation pattern 'improve', forcing simple classification\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'filtering' (recommendations)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.03s\n",
            "Answer: 📊 CURRENT TIMING STATUS:\n",
            "• Worst slack: 0.325ns\n",
            "• Best slack: 2.430ns\n",
            "• Average slack: 1.740ns\n",
            "• All paths PASS timing ✅\n",
            "\n",
            "🎯 TOP 10 SLACK IMPROVEMENT RECOMMENDATIONS:\n",
            "\n",
            "1. 🔧 BALANCE CLOCK SKEW\n",
            "   Current worst skew: 1.753ns\n",
            "   → Implement balanced clock distribution\n",
            "   → Add buffer cells in high-skew regions\n",
            "   → Optimize clock tree synthesis\n",
            "\n",
            "2. ⏰ OPTIMIZE HOLD TIME REQUIREMENTS\n",
            "   Current worst hold time: 0.100ns\n",
            "   → Add hold buffers in critical paths\n",
            "   → Optimize flip-flop timing\n",
            "\n",
            "2. 📐 OPTIMIZE DESIGN TOPOLOGY\n",
            "   Worst path: chip_core/housekeeping/_6778_ → chip_core/housekeeping/_6778_\n",
            "   → Housekeeping modules often have timing sensitivity\n",
            "   → Consider register pipelining\n",
            "   → Review logic synthesis constraints\n",
            "   → Optimize wire routing and placement\n",
            "\n",
            "3. 📈 IMPROVE TIMING MARGINS\n",
            "   Current margins: 0.325ns to 2.430ns\n",
            "   → Target minimum slack > 0.5ns for robustness\n",
            "   → Consider operating condition guardbands\n",
            "   → Add timing margin in synthesis\n",
            "\n",
            "4. 🚀 SPEED GRADE OPTIMIZATION\n",
            "   → Evaluate slower speed grades for better timing\n",
            "   → Trade-off performance vs reliability\n",
            "   → Consider multi-clock domain partitioning\n",
            "\n",
            "5. 🌡️ TEMPERATURE/VOLTAGE ANALYSIS\n",
            "   → Analyze timing across temperature corners\n",
            "   → Consider voltage scaling optimization\n",
            "   → Review process corner sensitivity\n",
            "\n",
            "6. 6. 📋 DESIGN RULE OPTIMIZATION\n",
            "   → Minimize long wires\n",
            "→ Add repeaters in nets > threshold\n",
            "→ Optimize fanout distribution\n",
            "\n",
            "7. 7. 🔄 LOGIC OPTIMIZATION\n",
            "   → Use carry chains efficiently\n",
            "→ Balance combinational logic\n",
            "→ Pipeline critical sections\n",
            "\n",
            "8. 8. ⚡ POWER OPTIMIZATION\n",
            "   → Clock gating for unused blocks\n",
            "→ Dynamic voltage scaling\n",
            "→ Reduce switching activity\n",
            "\n",
            "9. 9. 🎯 CONSTRAINT REFINEMENT\n",
            "   → Review timing constraints\n",
            "→ Add false/multicycle paths\n",
            "→ Optimize I/O timing\n",
            "\n",
            "10. 10. 🧪 ANALYSIS IMPROVEMENT\n",
            "   #  → Run Monte Carlo analysis\n",
            "→ Add statistical timing\n",
            "→ Review design coverage\n",
            "\n",
            "⚠️  IMPORTANT: Current design PASSES timing. These recommendations optimize margins for robustness.\n",
            "\n",
            "Question: show top 10 worst slack\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'show top 10 worst slack'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'show top 10 worst slack'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: show top 10 worst slack\n",
            "DEBUG: Found 659 paths\n",
            "DEBUG: Extracted number: 10\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.03s\n",
            "Answer: Top 10 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "3. Slack: 0.6174ns - Path from chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6469_ in group hkspi_clk\n",
            "4. Slack: 0.628ns - Path from chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6449_ in group hkspi_clk\n",
            "5. Slack: 0.6306ns - Path from chip_core/housekeeping/_6437_ to chip_core/housekeeping/_6435_ in group hkspi_clk\n",
            "6. Slack: 0.6453ns - Path from chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6470_ in group hkspi_clk\n",
            "7. Slack: 0.6522ns - Path from chip_core/housekeeping/_6460_ to chip_core/housekeeping/_6462_ in group hkspi_clk\n",
            "8. Slack: 0.6596ns - Path from chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6437_ in group hkspi_clk\n",
            "9. Slack: 0.6613ns - Path from chip_core/housekeeping/_6654_ to chip_core/housekeeping/_6459_ in group hkspi_clk\n",
            "10. Slack: 0.6626ns - Path from chip_core/housekeeping/_6466_ to chip_core/housekeeping/_6466_ in group hkspi_clk\n",
            "\n",
            "Question: show top 10 worst skews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'show top 10 worst skews'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'show top 10 worst skews'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: show top 10 worst skews\n",
            "DEBUG: Found 659 paths\n",
            "DEBUG: Extracted number: 10\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.03s\n",
            "Answer: Top 10 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "3. Slack: 0.6174ns - Path from chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6469_ in group hkspi_clk\n",
            "4. Slack: 0.628ns - Path from chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6449_ in group hkspi_clk\n",
            "5. Slack: 0.6306ns - Path from chip_core/housekeeping/_6437_ to chip_core/housekeeping/_6435_ in group hkspi_clk\n",
            "6. Slack: 0.6453ns - Path from chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6470_ in group hkspi_clk\n",
            "7. Slack: 0.6522ns - Path from chip_core/housekeeping/_6460_ to chip_core/housekeeping/_6462_ in group hkspi_clk\n",
            "8. Slack: 0.6596ns - Path from chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6437_ in group hkspi_clk\n",
            "9. Slack: 0.6613ns - Path from chip_core/housekeeping/_6654_ to chip_core/housekeeping/_6459_ in group hkspi_clk\n",
            "10. Slack: 0.6626ns - Path from chip_core/housekeeping/_6466_ to chip_core/housekeeping/_6466_ in group hkspi_clk\n",
            "\n",
            "Question: show top 10 worst clock skews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'show top 10 worst clock skews'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'show top 10 worst clock skews'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: show top 10 worst clock skews\n",
            "DEBUG: Found 659 paths\n",
            "DEBUG: Extracted number: 10\n",
            "DEBUG: Using direct processing (no LLM - it's too slow!)\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.03s\n",
            "Answer: Top 10 worst slack paths:\n",
            "1. Slack: 0.3252ns - Path from chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ in group hkspi_clk\n",
            "2. Slack: 0.6112ns - Path from chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ in group hkspi_clk\n",
            "3. Slack: 0.6174ns - Path from chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6469_ in group hkspi_clk\n",
            "4. Slack: 0.628ns - Path from chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6449_ in group hkspi_clk\n",
            "5. Slack: 0.6306ns - Path from chip_core/housekeeping/_6437_ to chip_core/housekeeping/_6435_ in group hkspi_clk\n",
            "6. Slack: 0.6453ns - Path from chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6470_ in group hkspi_clk\n",
            "7. Slack: 0.6522ns - Path from chip_core/housekeeping/_6460_ to chip_core/housekeeping/_6462_ in group hkspi_clk\n",
            "8. Slack: 0.6596ns - Path from chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6437_ in group hkspi_clk\n",
            "9. Slack: 0.6613ns - Path from chip_core/housekeeping/_6654_ to chip_core/housekeeping/_6459_ in group hkspi_clk\n",
            "10. Slack: 0.6626ns - Path from chip_core/housekeeping/_6466_ to chip_core/housekeeping/_6466_ in group hkspi_clk\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import json\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from typing import List, Dict, Any, Optional\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Suppress ChromaDB telemetry errors\n",
        "logging.getLogger(\"chromadb.telemetry.product.posthog\").setLevel(logging.ERROR)\n",
        "\n",
        "class ImprovedLocalTimingRAG:\n",
        "    def __init__(self, model_name: str = \"codellama/CodeLlama-7b-Instruct-hf\"):\n",
        "        self.model_name = model_name\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.llm_model, self.tokenizer = self._load_local_llm()\n",
        "\n",
        "        # Get device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use in-memory database to avoid file permission issues\n",
        "        self._setup_database()\n",
        "\n",
        "        self.history = []\n",
        "        self.current_path_index = 0  # Track current path for \"next\" queries\n",
        "\n",
        "    def _setup_database(self):\n",
        "        \"\"\"Setup ChromaDB with in-memory storage\"\"\"\n",
        "        try:\n",
        "            # Use in-memory database to avoid file permission issues\n",
        "            self.client = chromadb.Client()\n",
        "            # Try to get existing collection, if it exists, delete it first\n",
        "            try:\n",
        "                existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                self.client.delete_collection(name=\"timing_reports\")\n",
        "            except:\n",
        "                pass  # Collection doesn't exist, which is fine\n",
        "\n",
        "            self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "            print(\"Using in-memory database\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up database: {e}\")\n",
        "            # Fallback to persistent client with a different path\n",
        "            try:\n",
        "                # Clear existing database\n",
        "                if os.path.exists(\"./temp_chroma_db\"):\n",
        "                    shutil.rmtree(\"./temp_chroma_db\")\n",
        "\n",
        "                self.client = chromadb.PersistentClient(path=\"./temp_chroma_db\")\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using persistent database at ./temp_chroma_db\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Error with persistent database: {e2}\")\n",
        "                # Last resort - create a new in-memory client\n",
        "                self.client = chromadb.Client()\n",
        "                try:\n",
        "                    existing_collection = self.client.get_collection(name=\"timing_reports\")\n",
        "                    self.client.delete_collection(name=\"timing_reports\")\n",
        "                except:\n",
        "                    pass\n",
        "                self.collection = self.client.create_collection(name=\"timing_reports\")\n",
        "                print(\"Using fallback in-memory database\")\n",
        "\n",
        "    def _load_local_llm(self):\n",
        "        \"\"\"Load the local LLM and tokenizer with proper attention mask handling\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading {self.model_name}...\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            # Set pad token if not set\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            # Set padding side to left for better generation\n",
        "            tokenizer.padding_side = \"left\"\n",
        "\n",
        "            print(f\"Successfully loaded {self.model_name}\")\n",
        "            return model, tokenizer\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            print(\"Falling back to DialoGPT-large...\")\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"microsoft/DialoGPT-large\",\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "                if tokenizer.pad_token is None:\n",
        "                    tokenizer.pad_token = tokenizer.eos_token\n",
        "                tokenizer.padding_side = \"left\"\n",
        "                return model, tokenizer\n",
        "            except Exception as e2:\n",
        "                print(f\"Error loading fallback model: {e2}\")\n",
        "                return None, None\n",
        "\n",
        "    def _read_json_file(self, file_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Read JSON file with aggressive repair for malformed JSON\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Try normal parsing first\n",
        "            try:\n",
        "                return json.loads(content)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON parsing failed: {e}\")\n",
        "                print(\"Attempting aggressive JSON repair...\")\n",
        "\n",
        "                # Aggressive JSON repair\n",
        "                repaired_content = self._repair_json(content)\n",
        "                return json.loads(repaired_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"File reading failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _repair_json(self, content: str) -> str:\n",
        "        \"\"\"Aggressively repair malformed JSON\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Fix 1: Remove trailing commas\n",
        "        content = re.sub(r',\\s*}', '}', content)\n",
        "        content = re.sub(r',\\s*]', ']', content)\n",
        "\n",
        "        # Fix 2: Add missing commas between objects/arrays\n",
        "        content = re.sub(r'}\\s*{', '}, {', content)\n",
        "        content = re.sub(r']\\s*\\[', '], [', content)\n",
        "        content = re.sub(r'}\\s*\\[', '}, [', content)\n",
        "        content = re.sub(r']\\s*{', '], {', content)\n",
        "\n",
        "        # Fix 3: Handle specific line 34558 issue - look for missing comma patterns\n",
        "        lines = content.split('\\n')\n",
        "        if len(lines) > 34557:\n",
        "            # Check the problematic line and surrounding context\n",
        "            problem_line = lines[34557]  # 0-indexed\n",
        "            print(f\"Problem line 34558: {repr(problem_line)}\")\n",
        "\n",
        "            # Try to fix common patterns on this line\n",
        "            if problem_line.strip().endswith('}') and not problem_line.strip().endswith(',}'):\n",
        "                # Look at the next line to see if it starts with {\n",
        "                if len(lines) > 34558 and lines[34558].strip().startswith('{'):\n",
        "                    lines[34557] = problem_line.rstrip() + ','\n",
        "                    content = '\\n'.join(lines)\n",
        "                    print(\"Fixed missing comma at line 34558\")\n",
        "\n",
        "        # Fix 4: More aggressive comma insertion\n",
        "        # Look for patterns like: } followed by { on next line\n",
        "        content = re.sub(r'}\\s*\\n\\s*{', '},\\n{', content)\n",
        "        content = re.sub(r']\\s*\\n\\s*\\[', '],\\n[', content)\n",
        "\n",
        "        # Fix 5: Handle unclosed strings or other issues\n",
        "        # This is a last resort - try to balance braces and brackets\n",
        "        open_braces = content.count('{') - content.count('}')\n",
        "        open_brackets = content.count('[') - content.count(']')\n",
        "\n",
        "        if open_braces > 0:\n",
        "            content += '}' * open_braces\n",
        "            print(f\"Added {open_braces} closing braces\")\n",
        "        if open_brackets > 0:\n",
        "            content += ']' * open_brackets\n",
        "            print(f\"Added {open_brackets} closing brackets\")\n",
        "\n",
        "        return content\n",
        "\n",
        "    def index_timing_reports(self, directory: str):\n",
        "        \"\"\"Index all JSON files in the directory\"\"\"\n",
        "        print(\"=== Indexing timing reports ===\")\n",
        "\n",
        "        json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "        print(f\"Found {len(json_files)} JSON files to index\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            print(f\"Indexing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                data = self._read_json_file(file_path)\n",
        "                if not data:\n",
        "                    print(f\"Failed to read {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract text and metadata for each path\n",
        "                for i, path in enumerate(data.get('paths', [])):\n",
        "                    # Create a comprehensive text representation\n",
        "                    text_parts = []\n",
        "\n",
        "                    # Add path metadata\n",
        "                    if 'startpoint' in path:\n",
        "                        text_parts.append(f\"Startpoint: {path['startpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'endpoint' in path:\n",
        "                        text_parts.append(f\"Endpoint: {path['endpoint'].get('instance', 'N/A')}\")\n",
        "                    if 'report' in path:\n",
        "                        report = path['report']\n",
        "                        text_parts.append(f\"Group: {report.get('group', 'N/A')}\")\n",
        "                        text_parts.append(f\"Path Type: {report.get('path_type', 'N/A')}\")\n",
        "\n",
        "                    # Add summary information\n",
        "                    if 'summary' in path:\n",
        "                        summary = path['summary']\n",
        "                        if 'slack' in summary:\n",
        "                            text_parts.append(f\"Slack: {summary['slack']}\")\n",
        "                        if 'hold_time_requirement' in summary and summary['hold_time_requirement'] is not None:\n",
        "                            text_parts.append(f\"Hold Time Requirement: {summary['hold_time_requirement']}\")\n",
        "                        if 'clock_skew' in summary and summary['clock_skew'] is not None:\n",
        "                            text_parts.append(f\"Clock Skew: {summary['clock_skew']}\")\n",
        "\n",
        "                    # Add launch clock path stages\n",
        "                    if 'launch_clock_path' in path and 'stages' in path['launch_clock_path']:\n",
        "                        text_parts.append(\"Launch Clock Path:\")\n",
        "                        for stage in path['launch_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add data path stages\n",
        "                    if 'data_path' in path and 'stages' in path['data_path']:\n",
        "                        text_parts.append(\"Data Path:\")\n",
        "                        for stage in path['data_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Add capture clock path stages\n",
        "                    if 'capture_clock_path' in path and 'stages' in path['capture_clock_path']:\n",
        "                        text_parts.append(\"Capture Clock Path:\")\n",
        "                        for stage in path['capture_clock_path']['stages']:\n",
        "                            if stage.get('type') == 'cell_pin':\n",
        "                                text_parts.append(f\"  {stage.get('name', 'N/A')} ({stage.get('cell_type', 'N/A')})\")\n",
        "\n",
        "                    # Combine all text\n",
        "                    full_text = \"\\n\".join(text_parts)\n",
        "\n",
        "                    # Generate embedding\n",
        "                    embedding = self.embedding_model.encode(full_text).tolist()\n",
        "\n",
        "                    # Store in ChromaDB\n",
        "                    self.collection.add(\n",
        "                        embeddings=[embedding],\n",
        "                        documents=[full_text],\n",
        "                        metadatas=[{\n",
        "                            'filename': filename,\n",
        "                            'path_index': i,\n",
        "                            'startpoint': path.get('startpoint', {}).get('instance', 'N/A'),\n",
        "                            'endpoint': path.get('endpoint', {}).get('instance', 'N/A'),\n",
        "                            'slack': path.get('summary', {}).get('slack', 'N/A'),\n",
        "                            'hold_time_requirement': path.get('summary', {}).get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': path.get('summary', {}).get('clock_skew', 'N/A'),\n",
        "                            'group': path.get('report', {}).get('group', 'N/A')\n",
        "                        }],\n",
        "                        ids=[f\"{filename}_{i}\"]\n",
        "                    )\n",
        "\n",
        "                print(f\"Successfully indexed {filename} with {len(data.get('paths', []))} paths\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error indexing {filename}: {e}\")\n",
        "\n",
        "        print(\"Indexing complete!\")\n",
        "\n",
        "    def _get_all_slack_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all slack-related data from the collection\"\"\"\n",
        "        print(\"DEBUG: Getting all slack data from collection...\")\n",
        "        all_data = []\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Calling collection.get()...\")\n",
        "            results = self.collection.get()\n",
        "            print(f\"DEBUG: Collection.get() returned {len(results.get('metadatas', []))} entries\")\n",
        "\n",
        "            for i, metadata in enumerate(results['metadatas']):\n",
        "                if metadata.get('slack') != 'N/A':\n",
        "                    try:\n",
        "                        slack_value = float(metadata['slack'])\n",
        "                        all_data.append({\n",
        "                            'slack': slack_value,\n",
        "                            'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                            'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                            'group': metadata.get('group', 'N/A'),\n",
        "                            'hold_time_requirement': metadata.get('hold_time_requirement', 'N/A'),\n",
        "                            'clock_skew': metadata.get('clock_skew', 'N/A'),\n",
        "                            'document': results['documents'][i],\n",
        "                            'path_index': metadata.get('path_index', i)\n",
        "                        })\n",
        "                    except (ValueError, TypeError):\n",
        "                        continue\n",
        "\n",
        "            print(f\"DEBUG: Processed {len(all_data)} slack data entries\")\n",
        "            return all_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in _get_all_slack_data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_clock_skew_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all clock skew data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew_value = float(metadata['clock_skew'])\n",
        "                    all_data.append({\n",
        "                        'clock_skew': clock_skew_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _get_hold_time_data(self) -> List[Dict]:\n",
        "        \"\"\"Get all hold time requirement data from the collection\"\"\"\n",
        "        all_data = []\n",
        "        results = self.collection.get()\n",
        "\n",
        "        for i, metadata in enumerate(results['metadatas']):\n",
        "            if metadata.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time_value = float(metadata['hold_time_requirement'])\n",
        "                    all_data.append({\n",
        "                        'hold_time_requirement': hold_time_value,\n",
        "                        'startpoint': metadata.get('startpoint', 'N/A'),\n",
        "                        'endpoint': metadata.get('endpoint', 'N/A'),\n",
        "                        'group': metadata.get('group', 'N/A'),\n",
        "                        'slack': metadata.get('slack', 'N/A'),\n",
        "                        'document': results['documents'][i],\n",
        "                        'path_index': metadata.get('path_index', i)\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        return all_data\n",
        "\n",
        "    def _classify_question_with_llm(self, question: str) -> str:\n",
        "        \"\"\"Use CodeLlama to classify the question type with timeout\"\"\"\n",
        "        import time\n",
        "\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            print(\"DEBUG: LLM not available, returning 'general'\")\n",
        "            return \"general\"\n",
        "\n",
        "        print(f\"DEBUG: LLM classification for: '{question}'\")\n",
        "\n",
        "        # Much simpler prompt for faster classification\n",
        "        prompt = f\"\"\"<s>[INST] Classify this timing question:\n",
        "\n",
        "- ranking: worst/best/top questions\n",
        "- counting: how many/total questions\n",
        "- filtering: show/find questions\n",
        "- general: other questions\n",
        "\n",
        "Question: \"{question}\"\n",
        "\n",
        "Category: [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            print(\"DEBUG: Tokenizing classification prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Shorter\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(\"DEBUG: Creating attention mask...\")\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM classification generation...\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.llm_model.generate(\n",
        "                    inputs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=3,  # Very short for classification\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.1,\n",
        "                    do_sample=False,  # Deterministic for speed\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"DEBUG: LLM generation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "            print(\"DEBUG: Decoding classification response...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            category = response.split(\"[/INST]\")[-1].strip().lower()\n",
        "\n",
        "            print(f\"DEBUG: Raw LLM response: '{response}'\")\n",
        "            print(f\"DEBUG: Extracted category: '{category}'\")\n",
        "\n",
        "            # Clean up the response\n",
        "            category = category.replace(\"category:\", \"\").strip()\n",
        "\n",
        "            # Map to high-level categories\n",
        "            category = category.strip().lower()\n",
        "            if category in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"general\"]:\n",
        "                print(f\"DEBUG: Valid category found: '{category}'\")\n",
        "                return category\n",
        "            else:\n",
        "                print(f\"DEBUG: Invalid category '{category}', returning 'general'\")\n",
        "                return \"general\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM question classification: {e}\")\n",
        "            return \"general\"\n",
        "\n",
        "    def _detect_query_complexity(self, question: str) -> str:\n",
        "        \"\"\"Detect if question needs LLM processing or direct processing\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Simple data retrieval patterns\n",
        "        simple_patterns = [\n",
        "            \"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\",  # Basic ranking\n",
        "            \"total\", \"count\", \"number of\",                           # Simple counts (NO conditions)\n",
        "            \"how many\",                                              # counting questions\n",
        "            \"paths are\", \"are there\", \"paths total\",                # Simple counting variations\n",
        "            \"average\", \"mean\", \"statistics\", \"distribution\",       # Basic statistics\n",
        "            \"clock skew\", \"skew\", \"hold time\",                     # Specific metrics\n",
        "            \"startpoint\", \"endpoint\", \"show\",                       # Data display\n",
        "            \"next\", \"previous\"                                      # Navigation\n",
        "        ]\n",
        "\n",
        "        # Simple timing status patterns (can be handled fast)\n",
        "        timing_status_patterns = [\n",
        "            \"failing\", \"violation\", \"fail\", \"failed\",            # Timing status\n",
        "            \"passing\", \"pass\", \"passed\",                          # Timing status\n",
        "            \"critical\", \"borderline\"                             # Timing status\n",
        "        ]\n",
        "\n",
        "        # Complex analytical patterns\n",
        "        complex_patterns = [\n",
        "            \"why\", \"why is\", \"why are\", \"reason\", \"cause\",         # Explanations\n",
        "            \"analyze\", \"analysis\", \"pattern\", \"correlation\",       # Analysis\n",
        "            \"compare\", \"difference\", \"between\",                    # Comparisons\n",
        "            \"what if\", \"impact\", \"effect\",                         # Causal analysis\n",
        "            \"less than\", \"greater than\", \"more than\", \"between\",   # Conditional queries\n",
        "            \"above\", \"below\", \"equal to\", \"higher than\", \"lower than\",  # Additional conditions\n",
        "            \"can slacks\", \"if clock\", \"relationship\", \"how does\",  # Technical reasoning\n",
        "            \"positive clock\", \"negative clock\", \"skew effect\"      # Clock skew analysis\n",
        "        ]\n",
        "\n",
        "        # Recommendation patterns (should handle with direct logic, not LLM)\n",
        "        recommendation_patterns = [\n",
        "            \"recommend\", \"suggest\", \"optimize\", \"improve\",\n",
        "            \"how can we\", \"what can we do\", \"how to improve\",\n",
        "            \"make better\", \"improve slack\", \"better slack\"\n",
        "        ]\n",
        "\n",
        "        # Check for simple timing status patterns first\n",
        "        for pattern in timing_status_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for recommendation patterns (handle with direct logic)\n",
        "        for pattern in recommendation_patterns:\n",
        "            if pattern in question_lower:\n",
        "                print(f\"DEBUG: Detected recommendation pattern '{pattern}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Force simple classification for certain problematic phrases\n",
        "        problematic_phrases = [\n",
        "            \"reason for worst slack\",\n",
        "            \"why worst slack\",\n",
        "            \"worst slack reason\"\n",
        "        ]\n",
        "        for phrase in problematic_phrases:\n",
        "            if phrase in question_lower:\n",
        "                print(f\"DEBUG: Detected problematic phrase '{phrase}', forcing simple classification\")\n",
        "                return \"simple\"\n",
        "\n",
        "        # Check for complex indicators\n",
        "        for pattern in complex_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"complex\"\n",
        "\n",
        "        # Check for simple indicators\n",
        "        for pattern in simple_patterns:\n",
        "            if pattern in question_lower:\n",
        "                return \"simple\"\n",
        "\n",
        "        return \"complex\"  # Default to complex for safety\n",
        "\n",
        "    def _classify_question(self, question: str, data: List[Dict]) -> str:\n",
        "        \"\"\"Smart classification: route between fast and LLM processing\"\"\"\n",
        "        print(f\"DEBUG: Classifying question: '{question}'\")\n",
        "\n",
        "        # Detect complexity first\n",
        "        complexity = self._detect_query_complexity(question)\n",
        "        print(f\"DEBUG: Query complexity: {complexity}\")\n",
        "\n",
        "        if complexity == \"simple\":\n",
        "            print(\"DEBUG: Using fast pattern matching for simple query...\")\n",
        "            question_lower = question.lower()\n",
        "\n",
        "            # Ranking patterns\n",
        "            if any(word in question_lower for word in [\"worst\", \"best\", \"top\", \"bottom\", \"highest\", \"lowest\", \"rank\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'ranking'\")\n",
        "                return \"ranking\"\n",
        "            # Counting patterns\n",
        "            elif any(word in question_lower for word in [\"how many\", \"total\", \"count\", \"number of\", \"are there\", \"paths are\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'counting'\")\n",
        "                return \"counting\"\n",
        "            # Statistics patterns\n",
        "            elif any(word in question_lower for word in [\"average\", \"mean\", \"median\", \"statistics\", \"distribution\", \"range\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'statistics'\")\n",
        "                return \"statistics\"\n",
        "            # Clock skew patterns\n",
        "            elif any(word in question_lower for word in [\"clock skew\", \"skew\", \"clock_skew\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (clock skew)\")\n",
        "                return \"filtering\"\n",
        "            # Hold time patterns\n",
        "            elif any(word in question_lower for word in [\"hold time\", \"hold_time\", \"hold time requirement\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (hold time)\")\n",
        "                return \"filtering\"\n",
        "            # Timing status patterns\n",
        "            elif any(word in question_lower for word in [\"failing\", \"violation\", \"crash\", \"crash\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (timing status)\")\n",
        "                return \"filtering\"\n",
        "            # Recommendation patterns\n",
        "            elif any(word in question_lower for word in [\"recommend\", \"suggest\", \"optimize\", \"improve\", \"how can we\", \"what can we do\", \"make better\", \"better slack\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering' (recommendations)\")\n",
        "                return \"filtering\"\n",
        "            # Filtering patterns\n",
        "            elif any(word in question_lower for word in [\"startpoint\", \"endpoint\", \"show\", \"find\", \"search\", \"filter\", \"where\", \"which\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'filtering'\")\n",
        "                return \"filtering\"\n",
        "            # Navigation patterns\n",
        "            elif any(word in question_lower for word in [\"next\", \"previous\", \"browse\", \"iterate\", \"go to\"]):\n",
        "                print(\"DEBUG: Pattern matched as 'navigation'\")\n",
        "                return \"navigation\"\n",
        "            else:\n",
        "                print(\"DEBUG: Pattern matched as 'general'\")\n",
        "                return \"general\"\n",
        "        else:\n",
        "            # Complex query - return 'complex' category\n",
        "            print(f\"DEBUG: Complex query detected: '{question}', returning 'complex'\")\n",
        "            return \"complex\"\n",
        "\n",
        "    def _handle_ranking_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle ranking queries with metric detection\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Handling ranking query: {question}\")\n",
        "        print(f\"DEBUG: Found {len(all_slack_data)} paths\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for specific metric requests\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            print(f\"DEBUG: Clock skew ranking requested\")\n",
        "            return self._handle_clock_skew_ranking(question, all_slack_data)\n",
        "        elif \"hold time\" in question_lower or \"hold_time\" in question_lower:\n",
        "            print(f\"DEBUG: Hold time ranking requested\")\n",
        "            return self._handle_hold_time_ranking(question, all_slack_data)\n",
        "\n",
        "        # Default to slack ranking\n",
        "        # Extract number from question for fallback\n",
        "        n = self._extract_number_from_question(question)\n",
        "        print(f\"DEBUG: Extracted number: {n}\")\n",
        "\n",
        "        # Skip LLM entirely - it's too slow!\n",
        "        print(f\"DEBUG: Using direct processing (no LLM - it's too slow!)\")\n",
        "        return self._handle_ranking_fallback(question, all_slack_data, n)\n",
        "\n",
        "    def _handle_ranking_fallback(self, question: str, all_slack_data: List[Dict], n: int) -> str:\n",
        "        \"\"\"Fallback ranking handler without LLM\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check if asking for reasons/analysis specifically\n",
        "        if \"reason\" in question_lower or (\"why\" in question_lower and \"worst\" in question_lower):\n",
        "            return self._analyze_worst_slack_reasons(all_slack_data)\n",
        "\n",
        "        # Sort paths by slack\n",
        "        if \"worst\" in question_lower or \"bottom\" in question_lower:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "            direction = \"worst\"\n",
        "        else:\n",
        "            sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'], reverse=True)\n",
        "            direction = \"best\"\n",
        "\n",
        "        # Get top N paths\n",
        "        n = min(n, len(all_slack_data))\n",
        "        top_paths = sorted_paths[:n]\n",
        "\n",
        "        result = f\"Top {n} {direction} slack paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            result += f\"{i}. Slack: {path['slack']}ns - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']}\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _analyze_worst_slack_reasons(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Analyze reasons for worst slack\"\"\"\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        second_worst = sorted(all_slack_data, key=lambda x: x['slack'])[1] if len(all_slack_data) > 1 else worst_path\n",
        "\n",
        "        analysis_parts = []\n",
        "\n",
        "        # Analyze the worst path\n",
        "        analysis_parts.append(f\"📊 WORST SLACK ANALYSIS:\")\n",
        "        analysis_parts.append(f\"📍 Worst path: {worst_path['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"🔄 From: {worst_path['startpoint']} → {worst_path['endpoint']}\")\n",
        "\n",
        "        # Clock skew analysis\n",
        "        clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "        if clock_skew != 'N/A':\n",
        "            analysis_parts.append(f\"⏰ Clock skew: {clock_skew:.3f}ns\")\n",
        "            try:\n",
        "                if float(clock_skew) > 0.4:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH clock skew - impacts timing margin\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Moderate clock skew\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Hold time analysis\n",
        "        hold_time = worst_path.get('hold_time_requirement', 'N/A')\n",
        "        if hold_time != 'N/A':\n",
        "            analysis_parts.append(f\"🔒 Hold time requirement: {hold_time}ns\")\n",
        "            try:\n",
        "                if float(hold_time) > 0.1:\n",
        "                    analysis_parts.append(\"   ⚠️ HIGH hold time requirement\")\n",
        "                else:\n",
        "                    analysis_parts.append(\"   ✅ Normal hold time requirement\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Comparative analysis\n",
        "        analysis_parts.append(f\"\\n📈 COMPARATIVE ANALYSIS:\")\n",
        "        analysis_parts.append(f\"🎯 Slack range: {worst_path['slack']:.3f}ns to {second_worst['slack']:.3f}ns\")\n",
        "        analysis_parts.append(f\"💰 Margin difference: {second_worst['slack'] - worst_path['slack']:.3f}ns\")\n",
        "\n",
        "        # Summary assessment\n",
        "        analysis_parts.append(f\"\\n✅ TIMING STATUS:\")\n",
        "        analysis_parts.append(f\"🎯 Both paths PASS timing (positive slack)\")\n",
        "        analysis_parts.append(f\"⚠️ Small margins indicate timing sensitivity\")\n",
        "        analysis_parts.append(f\"💡 Consider design optimizations for robustness\")\n",
        "\n",
        "        return \"\\n\".join(analysis_parts)\n",
        "\n",
        "    def _generate_slack_improvement_recommendations(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Generate comprehensive slack improvement recommendations based on actual data\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Determine number of recommendations requested\n",
        "        num_points = 10  # Default\n",
        "        if \"5 points\" in question_lower or \"5 point\" in question_lower:\n",
        "                num_points = 5\n",
        "        elif \"3 points\" in question_lower or \"3 point\" in question_lower:\n",
        "            num_points = 3\n",
        "\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        recommendations = []\n",
        "\n",
        "        # Analyze current timing situation\n",
        "        slack_values = [p['slack'] for p in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "\n",
        "        recommendations.append(f\"📊 CURRENT TIMING STATUS:\")\n",
        "        recommendations.append(f\"• Worst slack: {worst_path['slack']:.3f}ns\")\n",
        "        recommendations.append(f\"• Best slack: {best_path['slack']:.3f}ns\")\n",
        "        recommendations.append(f\"• Average slack: {avg_slack:.3f}ns\")\n",
        "        recommendations.append(f\"• All paths PASS timing ✅\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        recommendations.append(f\"🎯 TOP {num_points} SLACK IMPROVEMENT RECOMMENDATIONS:\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Clock skew optimization\n",
        "        clock_skews = [p.get('clock_skew', 0) for p in all_slack_data if p.get('clock_skew') != 'N/A']\n",
        "        if clock_skews and max(clock_skews) > 0.4:\n",
        "            recommendations.append(f\"1. 🔧 BALANCE CLOCK SKEW\")\n",
        "            recommendations.append(f\"   Current worst skew: {max(clock_skews):.3f}ns\")\n",
        "            recommendations.append(f\"   → Implement balanced clock distribution\")\n",
        "            recommendations.append(f\"   → Add buffer cells in high-skew regions\")\n",
        "            recommendations.append(f\"   → Optimize clock tree synthesis\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        # Hold time optimization\n",
        "        hold_times = [p.get('hold_time_requirement', 0) for p in all_slack_data if p.get('hold_time_requirement') != 'N/A']\n",
        "        if hold_times and max(hold_times) > 0.1:\n",
        "            recommendations.append(f\"2. ⏰ OPTIMIZE HOLD TIME REQUIREMENTS\")\n",
        "            recommendations.append(f\"   Current worst hold time: {max(hold_times):.3f}ns\")\n",
        "            recommendations.append(f\"   → Add hold buffers in critical paths\")\n",
        "            recommendations.append(f\"   → Optimize flip-flop timing\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        # Design optimization based on path analysis\n",
        "        recommendations.append(f\"{2 if clock_skews and max(clock_skews) > 0.4 else 3 if hold_times and max(hold_times) > 0.1 else 1}. 📐 OPTIMIZE DESIGN TOPOLOGY\")\n",
        "        recommendations.append(f\"   Worst path: {worst_path['startpoint']} → {worst_path['endpoint']}\")\n",
        "        if \"housekeeping\" in worst_path.get('startpoint', ''):\n",
        "            recommendations.append(f\"   → Housekeeping modules often have timing sensitivity\")\n",
        "            recommendations.append(f\"   → Consider register pipelining\")\n",
        "        recommendations.append(f\"   → Review logic synthesis constraints\")\n",
        "        recommendations.append(f\"   → Optimize wire routing and placement\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Slack margin improvement\n",
        "        recommendations.append(f\"{3 if clock_skews and max(clock_skews) > 0.4 else 4 if hold_times and max(hold_times) > 0.1 else 2}. 📈 IMPROVE TIMING MARGINS\")\n",
        "        recommendations.append(f\"   Current margins: {min_slack:.3f}ns to {max(slack_values):.3f}ns\")\n",
        "        recommendations.append(f\"   → Target minimum slack > 0.5ns for robustness\")\n",
        "        recommendations.append(f\"   → Consider operating condition guardbands\")\n",
        "        recommendations.append(f\"   → Add timing margin in synthesis\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Speed grade optimization\n",
        "        recommendations.append(f\"{4 if clock_skews and max(clock_skews) > 0.4 else 5 if hold_times and max(hold_times) > 0.1 else 3}. 🚀 SPEED GRADE OPTIMIZATION\")\n",
        "        recommendations.append(f\"   → Evaluate slower speed grades for better timing\")\n",
        "        recommendations.append(f\"   → Trade-off performance vs reliability\")\n",
        "        recommendations.append(f\"   → Consider multi-clock domain partitioning\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Temperature and voltage optimization\n",
        "        recommendations.append(f\"{5 if clock_skews and max(clock_skews) > 0.4 else 6 if hold_times and max(hold_times) > 0.1 else 4}. 🌡️ TEMPERATURE/VOLTAGE ANALYSIS\")\n",
        "        recommendations.append(f\"   → Analyze timing across temperature corners\")\n",
        "        recommendations.append(f\"   → Consider voltage scaling optimization\")\n",
        "        recommendations.append(f\"   → Review process corner sensitivity\")\n",
        "        recommendations.append(\"\")\n",
        "\n",
        "        # Add remaining recommendations to reach requested count\n",
        "        remaining_count = num_points - (5 if clock_skews and max(clock_skews) > 0.4 else 5 if hold_times and max(hold_times) > 0.1 else 5)\n",
        "\n",
        "        additional_recommendations = [\n",
        "            (\"6. 📋 DESIGN RULE OPTIMIZATION\", \"→ Minimize long wires\\n→ Add repeaters in nets > threshold\\n→ Optimize fanout distribution\"),\n",
        "            (\"7. 🔄 LOGIC OPTIMIZATION\", \"→ Use carry chains efficiently\\n→ Balance combinational logic\\n→ Pipeline critical sections\"),\n",
        "            (\"8. ⚡ POWER OPTIMIZATION\", \"→ Clock gating for unused blocks\\n→ Dynamic voltage scaling\\n→ Reduce switching activity\"),\n",
        "            (\"9. 🎯 CONSTRAINT REFINEMENT\", \"→ Review timing constraints\\n→ Add false/multicycle paths\\n→ Optimize I/O timing\"),\n",
        "            (\"10. 🧪 ANALYSIS IMPROVEMENT\", \"#  → Run Monte Carlo analysis\\n→ Add statistical timing\\n→ Review design coverage\")\n",
        "        ]\n",
        "\n",
        "        for i in range(min(remaining_count, len(additional_recommendations))):\n",
        "            # Calculate proper numbering based on previously added recommendations\n",
        "            base_num = 5\n",
        "            if clock_skews and max(clock_skews) > 0.4:\n",
        "                base_num = 6\n",
        "            elif hold_times and max(hold_times) > 0.1:\n",
        "                base_num = 6\n",
        "            else:\n",
        "                base_num = 4\n",
        "\n",
        "            idx = base_num + i\n",
        "            rec = additional_recommendations[i]\n",
        "            recommendations.append(f\"{idx}. {rec[0]}\")\n",
        "            recommendations.append(f\"   {rec[1]}\")\n",
        "            recommendations.append(\"\")\n",
        "\n",
        "        recommendations.append(\"⚠️  IMPORTANT: Current design PASSES timing. These recommendations optimize margins for robustness.\")\n",
        "\n",
        "        return \"\\n\".join(recommendations)\n",
        "\n",
        "    def _generate_technical_reasoning(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Generate technical reasoning about timing relationships\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Clock skew vs slack analysis\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            return self._explain_clock_skew_relationship(all_slack_data, question)\n",
        "\n",
        "        # General timing relationships\n",
        "        return self._explain_timing_relationships(all_slack_data, question)\n",
        "\n",
        "    def _explain_clock_skew_relationship(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Explain the relationship between clock skew and slack\"\"\"\n",
        "        worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "        best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get actual clock skew values\n",
        "        clock_skews = [p.get('clock_skew', 0) for p in all_slack_data if p.get('clock_skew') != 'N/A']\n",
        "        current_skew = clock_skews[0] if clock_skews else 0.5  # Use first available skew\n",
        "\n",
        "        explanation = []\n",
        "        explanation.append(\"🔬 CLOCK SKEW vs SLACK RELATIONSHIP:\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"📊 CURRENT DATA:\")\n",
        "        explanation.append(f\"• Current clock skew: {current_skew:.3f}ns\")\n",
        "        explanation.append(f\"• Worst slack: {worst_path['slack']:.3f}ns\")\n",
        "        explanation.append(f\"• Best slack: {best_path['slack']:.3f}ns\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"🧠 TECHNICAL EXPLANATION:\")\n",
        "        explanation.append(\"\")\n",
        "        explanation.append(\"Clock skew affects slack through timing paths:\")\n",
        "        explanation.append(\"\")\n",
        "        explanation.append(\"🔸 POSITIVE CLOCK SKEW (launch clock arrives LATER):\")\n",
        "        explanation.append(\"   • Data has MORE time to propagate\")\n",
        "        explanation.append(\"   • → SLACK IMPROVES (becomes more positive)\")\n",
        "        explanation.append(\"   • → Better timing margin\")\n",
        "        explanation.append(\"\")\n",
        "        explanation.append(\"🔸 NEGATIVE CLOCK SKEW (launch clock arrives EARLIER):\")\n",
        "        explanation.append(\"   • Data has LESS time to propagate\")\n",
        "        explanation.append(\"   • → SLACK DEGRADES (becomes less positive)\")\n",
        "        explanation.append(\"   • → Worse timing margin\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"📐 MATHEMATICAL RELATIONSHIP:\")\n",
        "        explanation.append(\"Slack = Required_Time - Arrival_Time\")\n",
        "        explanation.append(\"If clock_skew increases (more positive):\")\n",
        "        explanation.append(\"→ Required_Time increases\")\n",
        "        explanation.append(\"→ Slack = (Required_Time + skew) - Arrival_Time\")\n",
        "        explanation.append(\"→ Slack IMPROVES ✅\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"🎯 ANSWER TO YOUR QUESTION:\")\n",
        "        explanation.append(\"If clock skews become MORE POSITIVE:\")\n",
        "        explanation.append(\"→ SLACKS WILL IMPROVE (become more positive)\")\n",
        "        explanation.append(\"→ Better timing margins\")\n",
        "        explanation.append(\"→ More robust design\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"⚠️  PRACTICAL CONSIDERATIONS:\")\n",
        "        explanation.append(\"• Positive skew helps setup timing\")\n",
        "        explanation.append(\"• But may hurt hold timing\")\n",
        "        explanation.append(\"• Balance between setup and hold is critical\")\n",
        "        explanation.append(\"• Current design shows moderate skew (0.5ns)\")\n",
        "\n",
        "        return \"\\n\".join(explanation)\n",
        "\n",
        "    def _explain_timing_relationships(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"General timing relationship explanations\"\"\"\n",
        "        explanation = []\n",
        "        explanation.append(\"🔬 TIMING RELATIONSHIPS EXPLANATION:\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        # Basic timing concepts\n",
        "        explanation.append(\"📚 FUNDAMENTAL TIMING CONCEPTS:\")\n",
        "        explanation.append(\"• Setup Time: Data must be stable before clock edge\")\n",
        "        explanation.append(\"• Hold Time: Data must remain stable after clock edge\")\n",
        "        explanation.append(\"• Slack: Margin between arrival and required time\")\n",
        "        explanation.append(\"• Clock Skew: Difference in clock arrival times\")\n",
        "        explanation.append(\"\")\n",
        "\n",
        "        explanation.append(\"🎯 KEY RELATIONSHIPS:\")\n",
        "        explanation.append(\"• More positive slack = Better timing margin\")\n",
        "        explanation.append(\"• Clock skew affects both setup and hold timing\")\n",
        "        explanation.append(\"• Temperature/voltage variations impact timing\")\n",
        "        explanation.append(\"• Process corners affect all timing parameters\")\n",
        "\n",
        "        return \"\\n\".join(explanation)\n",
        "\n",
        "    def _handle_clock_skew_ranking(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle clock skew ranking queries\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available.\"\n",
        "\n",
        "        # Extract number from question\n",
        "        n = self._extract_number_from_question(question)\n",
        "\n",
        "        # Filter paths that have clock skew data\n",
        "        paths_with_skew = []\n",
        "        for path in all_slack_data:\n",
        "            if path.get('clock_skew') != 'N/A':\n",
        "                try:\n",
        "                    clock_skew = float(path['clock_skew'])\n",
        "                    paths_with_skew.append({\n",
        "                        'clock_skew': clock_skew,\n",
        "                        'startpoint': path['startpoint'],\n",
        "                        'endpoint': path['endpoint'],\n",
        "                        'group': path['group'],\n",
        "                        'slack': path['slack']\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        if not paths_with_skew:\n",
        "            return \"No clock skew data found in timing reports\"\n",
        "\n",
        "        # Sort by clock skew (default to worst = highest skew)\n",
        "        question_lower = question.lower()\n",
        "        if \"best\" in question_lower:\n",
        "            sorted_paths = sorted(paths_with_skew, key=lambda x: x['clock_skew'])\n",
        "            direction = \"best\"\n",
        "        else:\n",
        "            sorted_paths = sorted(paths_with_skew, key=lambda x: x['clock_skew'], reverse=True)\n",
        "            direction = \"worst\"\n",
        "\n",
        "        # Get top N paths\n",
        "        top_paths = sorted_paths[:min(n, len(sorted_paths))]\n",
        "\n",
        "        result = f\"Top {len(top_paths)} {direction} clock skew paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            skew_status = \"⚠️ HIGH\" if path['clock_skew'] > 0.4 else \"📍 NORMAL\"\n",
        "            result += f\"{i}. Clock skew: {path['clock_skew']:.3f}ns [{skew_status}] - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']} (Slack: {path['slack']:.3f}ns)\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_hold_time_ranking(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle hold time ranking queries\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available.\"\n",
        "\n",
        "        # Extract number from question\n",
        "        n = self._extract_number_from_question(question)\n",
        "\n",
        "        # Filter paths that have hold time data\n",
        "        paths_with_hold_time = []\n",
        "        for path in all_slack_data:\n",
        "            if path.get('hold_time_requirement') != 'N/A':\n",
        "                try:\n",
        "                    hold_time = float(path['hold_time_requirement'])\n",
        "                    paths_with_hold_time.append({\n",
        "                        'hold_time_requirement': hold_time,\n",
        "                        'startpoint': path['startpoint'],\n",
        "                        'endpoint': path['endpoint'],\n",
        "                        'group': path['group'],\n",
        "                        'slack': path['slack']\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    continue\n",
        "\n",
        "        if not paths_with_hold_time:\n",
        "            return \"No hold time requirement data found in timing reports\"\n",
        "\n",
        "        # Sort by hold time (default to worst = highest hold time)\n",
        "        question_lower = question.lower()\n",
        "        if \"best\" in question_lower:\n",
        "            sorted_paths = sorted(paths_with_hold_time, key=lambda x: x['hold_time_requirement'])\n",
        "            direction = \"best\"\n",
        "        else:\n",
        "            sorted_paths = sorted(paths_with_hold_time, key=lambda x: x['hold_time_requirement'], reverse=True)\n",
        "            direction = \"worst\"\n",
        "\n",
        "        # Get top N paths\n",
        "        top_paths = sorted_paths[:min(n, len(sorted_paths))]\n",
        "\n",
        "        result = f\"Top {len(top_paths)} {direction} hold time requirement paths:\\n\"\n",
        "        for i, path in enumerate(top_paths, 1):\n",
        "            hold_status = \"⚠️ HIGH\" if path['hold_time_requirement'] > 0.1 else \"📍 NORMAL\"\n",
        "            result += f\"{i}. Hold time: {path['hold_time_requirement']:.3f}ns [{hold_status}] - Path from {path['startpoint']} to {path['endpoint']} in group {path['group']} (Slack: {path['slack']:.3f}ns)\\n\"\n",
        "\n",
        "        return result.strip()\n",
        "\n",
        "    def _handle_counting_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle counting queries with condition parsing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct counting (no LLM)...\")\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Handle simple total counts first\n",
        "        if any(phrase in question_lower for phrase in [\"are there\", \"paths are\", \"how many\", \"total paths\", \"paths total\"]):\n",
        "            # Simple counting - just return total\n",
        "            return f\"Total number of timing paths: {len(all_slack_data)}\"\n",
        "\n",
        "        # Check for conditional counts\n",
        "        if \"slack\" in question_lower:\n",
        "            # Parse conditions like \"slack less than 1ns\", \"slack greater than 1ns\"\n",
        "            if \"less than\" in question_lower or \"below\" in question_lower or \"<\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"less\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] < threshold)\n",
        "                    return f\"Paths with slack less than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"greater than\" in question_lower or \"above\" in question_lower or \"more than\" in question_lower or \">\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"greater\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] > threshold)\n",
        "                    return f\"Paths with slack greater than {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"equal to\" in question_lower or \"==\" in question_lower or \"=\" in question_lower:\n",
        "                # Extract threshold value\n",
        "                threshold = self._extract_threshold_from_question(question, \"equal\")\n",
        "                if threshold is not None:\n",
        "                    count = sum(1 for path in all_slack_data if path['slack'] == threshold)\n",
        "                    return f\"Paths with slack equal to {threshold}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "            elif \"between\" in question_lower:\n",
        "                # Extract range values\n",
        "                min_val, max_val = self._extract_range_from_question(question)\n",
        "                if min_val is not None and max_val is not None:\n",
        "                    count = sum(1 for path in all_slack_data if min_val <= path['slack'] <= max_val)\n",
        "                    return f\"Paths with slack between {min_val}ns and {max_val}ns: {count} out of {len(all_slack_data)}\"\n",
        "\n",
        "        # Default to total count\n",
        "        total_paths = len(all_slack_data)\n",
        "        return f\"Total number of timing paths: {total_paths}\"\n",
        "\n",
        "    def _handle_statistics_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle statistics queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct statistics (no LLM)...\")\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        avg_slack = sum(slack_values) / len(slack_values)\n",
        "        min_slack = min(slack_values)\n",
        "        max_slack = max(slack_values)\n",
        "\n",
        "        return f\"Slack statistics:\\n- Average: {avg_slack:.3f}ns\\n- Minimum: {min_slack:.3f}ns\\n- Maximum: {max_slack:.3f}ns\\n- Total paths: {len(slack_values)}\"\n",
        "\n",
        "    def _handle_filtering_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle filtering queries using fast direct processing\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        print(f\"DEBUG: Using direct filtering (no LLM)...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Handle technical reasoning queries\n",
        "        if any(word in question_lower for word in [\"can slacks\", \"if clock\", \"relationship\", \"how does\", \"positive clock\", \"negative clock\", \"skew effect\"]):\n",
        "            return self._generate_technical_reasoning(all_slack_data, question)\n",
        "\n",
        "        # Handle recommendation queries with comprehensive advice\n",
        "        if any(word in question_lower for word in [\"recommend\", \"suggest\", \"optimize\", \"improve\", \"how can we\", \"what can we do\", \"make better\", \"better slack\"]):\n",
        "            return self._generate_slack_improvement_recommendations(all_slack_data, question)\n",
        "\n",
        "        # Check for timing status queries first\n",
        "        if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\", \"passing\", \"pass\", \"critical\", \"borderline\"]):\n",
        "            failing_paths = []\n",
        "            passing_paths = []\n",
        "\n",
        "            for path in all_slack_data:\n",
        "                slack = path['slack']\n",
        "                if slack < 0:\n",
        "                    failing_paths.append(path)\n",
        "                else:\n",
        "                    passing_paths.append(path)\n",
        "\n",
        "            results = []\n",
        "            if any(word in question_lower for word in [\"failing\", \"violation\", \"fail\", \"failed\"]):\n",
        "                if failing_paths:\n",
        "                    results.append(\"🔴 FAILING PATHS (Negative Slack = Timing Violation):\")\n",
        "                    for path in failing_paths:\n",
        "                        results.append(f\"  📍 {path['startpoint']} → {path['endpoint']}: Slack={path['slack']:.3f}ns [VIOLATION]\")\n",
        "                else:\n",
        "                    results.append(\"✅ GOOD NEWS: NO FAILING PATHS!\")\n",
        "                    results.append(\"All paths have positive slack values (timing passes)\")\n",
        "                    results.append(f\"📊 Summary: {len(passing_paths)} paths PASS timing\")\n",
        "\n",
        "            elif any(word in question_lower for word in [\"passing\", \"pass\", \"critica\"]):\n",
        "                critical_count = sum(1 for p in passing_paths if 0 <= p['slack'] < 0.1)\n",
        "                results.append(f\"🟢 TIMING STATUS SUMMARY:\")\n",
        "                results.append(f\"  📈 PASSING PATHS: {len(passing_paths)} paths\")\n",
        "                results.append(f\"  📈 FAILING PATHS: {len(failing_paths)} paths\")\n",
        "                results.append(f\"  ⚠️ CRITICAL PATHS: {critical_count} paths with <0.1ns margin\")\n",
        "\n",
        "            return \"\\n\".join(results) if results else \"No timing status data available\"\n",
        "\n",
        "        # Check if asking for clock skew specifically\n",
        "        if \"clock skew\" in question_lower or \"skew\" in question_lower:\n",
        "            result = \"Clock skew information for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                clock_skew = path.get('clock_skew', 'N/A')\n",
        "                if clock_skew != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: {clock_skew}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Clock skew: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for hold time requirements specifically\n",
        "        elif \"hold time\" in question_lower:\n",
        "            result = \"Hold time requirements for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                hold_time = path.get('hold_time_requirement', 'N/A')\n",
        "                if hold_time != 'N/A':\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: {hold_time}ns - Slack: {path['slack']}ns\\n\"\n",
        "                else:\n",
        "                    result += f\"{i}. Path {path['startpoint']} to {path['endpoint']} - Hold time requirement: Not available - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        # Check if asking for startpoints/endpoints specifically\n",
        "        elif \"startpoint\" in question_lower and \"endpoint\" in question_lower:\n",
        "            result = \"Startpoints and endpoints for all paths:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Startpoint: {path['startpoint']} - Endpoint: {path['endpoint']} - Slack: {path['slack']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "        else:\n",
        "            # Generic filtering - show all paths with all details\n",
        "            result = \"All timing paths with details:\\n\"\n",
        "            for i, path in enumerate(all_slack_data, 1):\n",
        "                result += f\"{i}. Slack: {path['slack']}ns - Start: {path['startpoint']} - End: {path['endpoint']} - Group: {path['group']}\\n\"\n",
        "                if path.get('clock_skew') != 'N/A':\n",
        "                    result += f\"   Clock skew: {path['clock_skew']}ns\\n\"\n",
        "                if path.get('hold_time_requirement') != 'N/A':\n",
        "                    result += f\"   Hold time requirement: {path['hold_time_requirement']}ns\\n\"\n",
        "            return result.strip()\n",
        "\n",
        "    def _handle_navigation_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle navigation queries (next path, etc.)\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No slack data available.\"\n",
        "\n",
        "        # Sort paths by slack (worst to best)\n",
        "        sorted_paths = sorted(all_slack_data, key=lambda x: x['slack'])\n",
        "\n",
        "        # Get the next path after current index\n",
        "        if self.current_path_index < len(sorted_paths):\n",
        "            next_path = sorted_paths[self.current_path_index]\n",
        "            self.current_path_index += 1\n",
        "            return f\"Next path slack: {next_path['slack']}ns for the path from {next_path['startpoint']} to {next_path['endpoint']} in group {next_path['group']}.\"\n",
        "        else:\n",
        "            return \"No more paths available. All paths have been shown.\"\n",
        "\n",
        "    def _extract_number_from_question(self, question: str) -> int:\n",
        "        \"\"\"Extract number from question (e.g., 'top 2 worst' -> 2)\"\"\"\n",
        "        import re\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns like \"top 2\", \"worst 3\", \"2 worst\", etc.\n",
        "        patterns = [\n",
        "            r'top\\s+(\\d+)',\n",
        "            r'worst\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+worst',\n",
        "            r'(\\d+)\\s+best',\n",
        "            r'best\\s+(\\d+)',\n",
        "            r'(\\d+)\\s+paths?'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, question_lower)\n",
        "            if match:\n",
        "                return int(match.group(1))\n",
        "\n",
        "        # Default to 2 if no number found\n",
        "        return 2\n",
        "\n",
        "    def _extract_threshold_from_question(self, question: str, condition_type: str) -> float:\n",
        "        \"\"\"Extract numerical threshold from questions like 'slack less than 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for patterns with numbers followed by 'ns'\n",
        "        patterns = [\n",
        "            r'(\\d+\\.?\\d*)\\s*ns',  # \"1ns\", \"1.5ns\", etc.\n",
        "            r'(\\d+\\.?\\d*)',       # Just numbers\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, question_lower)\n",
        "            if matches:\n",
        "                try:\n",
        "                    value = float(matches[-1])  # Take the last number found\n",
        "                    return value\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_range_from_question(self, question: str) -> tuple:\n",
        "        \"\"\"Extract range values from questions like 'slack between 0.5ns and 1ns'\"\"\"\n",
        "        import re\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Look for \"between X and Y\" patterns\n",
        "        pattern = r'between\\s+(\\d+\\.?\\d*)\\s+ns?\\s+and\\s+(\\d+\\.?\\d*)\\s+ns?'\n",
        "        match = re.search(pattern, question_lower)\n",
        "        if match:\n",
        "            try:\n",
        "                min_val = float(match.group(1))\n",
        "                max_val = float(match.group(2))\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        # Fallback: extract all numbers\n",
        "        numbers = re.findall(r'(\\d+\\.?\\d*)', question_lower)\n",
        "        if len(numbers) >= 2:\n",
        "            try:\n",
        "                min_val = float(numbers[0])\n",
        "                max_val = float(numbers[1])\n",
        "                return min_val, max_val\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def _create_focused_context(self, all_slack_data: List[Dict], question: str) -> str:\n",
        "        \"\"\"Create focused context to avoid overwhelming LLM\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available.\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Focus on relevant data based on question\n",
        "        if \"worst\" in question_lower or \"bad\" in question_lower:\n",
        "            worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Worst path: {worst_path['slack']}ns slack, {worst_path['startpoint']}→{worst_path['endpoint']}, clock_skew:{worst_path.get('clock_skew', 'N/A')}, hold_time:{worst_path.get('hold_time_requirement', 'N/A')}\"\n",
        "\n",
        "        elif \"best\" in question_lower or \"good\" in question_lower:\n",
        "            best_path = max(all_slack_data, key=lambda x: x['slack'])\n",
        "            return f\"Best path: {best_path['slack']}ns slack, {best_path['startpoint']}→{best_path['endpoint']}\"\n",
        "\n",
        "        else:\n",
        "            # General summary\n",
        "            slack_values = [p['slack'] for p in all_slack_data]\n",
        "            return f\"{len(all_slack_data)} paths: slack range {min(slack_values):.3f} to {max(slack_values):.3f}ns, all positive (pass timing)\"\n",
        "\n",
        "    def _generate_llm_response(self, question: str, context: str) -> str:\n",
        "        \"\"\"Generate response using CodeLlama with proper attention mask and timeout\"\"\"\n",
        "        if not self.llm_model or not self.tokenizer:\n",
        "            return \"LLM not available for response generation.\"\n",
        "\n",
        "        # Create focused context to avoid overwhelming the model\n",
        "        summary_context = self._create_focused_context(self._get_all_slack_data(), question)\n",
        "\n",
        "        prompt = f\"\"\"<s>[INST] Timing Analysis Question:\n",
        "\n",
        "Data: {summary_context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer briefly (2-4 lines): [/INST]\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"DEBUG: Tokenizing prompt...\")\n",
        "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "            inputs = inputs.to(self.device)\n",
        "\n",
        "            print(f\"DEBUG: Input shape: {inputs.shape}\")\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = (inputs != self.tokenizer.pad_token_id).long()\n",
        "\n",
        "            print(\"DEBUG: Starting LLM generation...\")\n",
        "            import threading\n",
        "            import time\n",
        "\n",
        "            result = [None]\n",
        "            exception = [None]\n",
        "\n",
        "            def generate_worker():\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = self.llm_model.generate(\n",
        "                            inputs,\n",
        "                            attention_mask=attention_mask,\n",
        "                            max_new_tokens=50,  # Reduced for faster generation\n",
        "                            num_return_sequences=1,\n",
        "                            temperature=0.3,  # Lower temp for consistency\n",
        "                            do_sample=False,   # Deterministic\n",
        "                            pad_token_id=self.tokenizer.eos_token_id,\n",
        "                            eos_token_id=self.tokenizer.eos_token_id,\n",
        "                            early_stopping=True\n",
        "                        )\n",
        "                        result[0] = outputs\n",
        "                except Exception as e:\n",
        "                    exception[0] = e\n",
        "\n",
        "            # Start generation in a thread\n",
        "            thread = threading.Thread(target=generate_worker)\n",
        "            thread.start()\n",
        "            thread.join(timeout=15)  # 15 second timeout\n",
        "\n",
        "            if thread.is_alive():\n",
        "                print(\"DEBUG: LLM generation timed out after 15s, killing thread and using fallback...\")\n",
        "                # Thread is still alive, can't kill it cleanly, but let it continue in background\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if exception[0]:\n",
        "                print(f\"DEBUG: LLM generation failed: {exception[0]}, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            if result[0] is None:\n",
        "                print(\"DEBUG: No result from LLM, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            outputs = result[0]\n",
        "\n",
        "            print(\"DEBUG: LLM generation completed, decoding...\")\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            print(f\"DEBUG: Response decoded, length: {len(answer)}\")\n",
        "\n",
        "            # If answer is too short or seems incomplete, use fallback\n",
        "            if len(answer.strip()) < 10:\n",
        "                print(\"DEBUG: LLM response too short, using fallback...\")\n",
        "                return self._generate_fallback_answer(question, None)\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in LLM response generation: {e}\")\n",
        "            return self._generate_fallback_answer(question, None)\n",
        "\n",
        "    def _generate_fallback_answer(self, question: str, context_or_data) -> str:\n",
        "        \"\"\"Generate fallback answer when LLM fails\"\"\"\n",
        "        print(\"DEBUG: Generating fallback answer...\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Always get fresh data for fallback\n",
        "        all_slack_data = self._get_all_slack_data()\n",
        "\n",
        "        # Handle specific question types with direct logic\n",
        "        if \"worst slack\" in question_lower or \"reason\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                worst_path = min(all_slack_data, key=lambda x: x['slack'])\n",
        "                clock_skew = worst_path.get('clock_skew', 'N/A')\n",
        "                hold_req = worst_path.get('hold_time_requirement', 'N/A')\n",
        "\n",
        "                reason_parts = []\n",
        "                if clock_skew != 'N/A':\n",
        "                    try:\n",
        "                        if float(clock_skew) > 0.4:\n",
        "                            reason_parts.append(f\"High clock skew ({clock_skew}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "                if hold_req != 'N/A':\n",
        "                    try:\n",
        "                        if float(hold_req) > 0.1:\n",
        "                            reason_parts.append(f\"High hold time requirement ({hold_req}ns)\")\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                if not reason_parts:\n",
        "                    reason_parts.append(\"Slack is positive but small margin\")\n",
        "\n",
        "                return f\"\"\"Worst slack: {worst_path['slack']:.3f}ns for {worst_path['startpoint']} → {worst_path['endpoint']}\n",
        "\n",
        "Potential reasons:\n",
        "{chr(10).join('- ' + reason for reason in reason_parts)}\n",
        "\n",
        "Note: This path still passes timing (positive slack) but has the smallest margin.\"\"\"\n",
        "\n",
        "        elif \"reason\" in question_lower or \"why\" in question_lower:\n",
        "            if all_slack_data:\n",
        "                return f\"\"\"Timing Analysis Summary:\n",
        "- Total paths: {len(all_slack_data)}\n",
        "- All paths PASS timing (positive slack)\n",
        "- Slack range: {min(p['slack'] for p in all_slack_data):.3f}ns to {max(p['slack'] for p in all_slack_data):.3f}ns\n",
        "\n",
        "Potential timing concerns:\n",
        "- Small slack margins (both < 1ns)\n",
        "- Clock skew and hold time requirements may impact design margin\"\"\"\n",
        "\n",
        "        else:\n",
        "            return f\"Analysis unavailable due to LLM timeout. Raw data: {len(all_slack_data)} paths processed.\"\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        import time\n",
        "        query_start = time.time()\n",
        "\n",
        "        print(f\"DEBUG: Query method called with: '{question}'\")\n",
        "\n",
        "        try:\n",
        "            # Add to history\n",
        "            print(\"DEBUG: Adding to history...\")\n",
        "            self.history.append({'question': question, 'answer': ''})\n",
        "\n",
        "            # Get all slack data for comprehensive analysis\n",
        "            print(\"DEBUG: Getting all slack data...\")\n",
        "            all_slack_data = self._get_all_slack_data()\n",
        "            print(f\"DEBUG: Retrieved {len(all_slack_data)} slack data entries\")\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error in initial query setup: {e}\")\n",
        "            return f\"Error in query setup: {e}\"\n",
        "\n",
        "        # Classify the question\n",
        "        classify_start = time.time()\n",
        "        print(\"DEBUG: Classifying question...\")\n",
        "        question_type = self._classify_question(question, all_slack_data)\n",
        "        classify_time = time.time() - classify_start\n",
        "        print(f\"DEBUG: Question classified as: '{question_type}' (took {classify_time:.2f}s)\")\n",
        "\n",
        "        # Generate response based on high-level question type\n",
        "        handler_start = time.time()\n",
        "        print(f\"DEBUG: Routing to handler for type: {question_type}\")\n",
        "\n",
        "        if question_type == \"complex\":\n",
        "            print(\"DEBUG: Calling complex query handler\")\n",
        "            result = self._handle_complex_query(question, all_slack_data)\n",
        "        elif question_type == \"navigation\":\n",
        "            print(\"DEBUG: Calling navigation handler\")\n",
        "            result = self._handle_navigation_query(question, all_slack_data)\n",
        "        elif question_type == \"ranking\":\n",
        "            print(\"DEBUG: Calling ranking handler\")\n",
        "            result = self._handle_ranking_query(question, all_slack_data)\n",
        "        elif question_type == \"counting\":\n",
        "            print(\"DEBUG: Calling counting handler\")\n",
        "            result = self._handle_counting_query(question, all_slack_data)\n",
        "        elif question_type == \"statistics\":\n",
        "            print(\"DEBUG: Calling statistics handler\")\n",
        "            result = self._handle_statistics_query(question, all_slack_data)\n",
        "        elif question_type == \"filtering\":\n",
        "            print(\"DEBUG: Calling filtering handler\")\n",
        "            result = self._handle_filtering_query(question, all_slack_data)\n",
        "\n",
        "        # Add final timing\n",
        "        handler_end = time.time()\n",
        "        query_end = time.time()\n",
        "        handler_time = handler_end - handler_start\n",
        "        total_time = query_end - query_start\n",
        "        print(f\"DEBUG: Handler completed in {handler_time:.2f}s, total query time: {total_time:.2f}s\")\n",
        "\n",
        "        # Add else clause for unmatched types\n",
        "        if question_type not in [\"ranking\", \"counting\", \"statistics\", \"filtering\", \"navigation\", \"complex\"]:\n",
        "            result = f\"I don't understand the question type. Please ask about rankings (worst/best paths), counts (how many paths), statistics (slack analysis), or filtering (show paths).\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _handle_complex_query(self, question: str, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Handle complex queries using LLM with structured context\"\"\"\n",
        "        if not all_slack_data:\n",
        "            return \"No timing data available for analysis.\"\n",
        "\n",
        "        print(\"DEBUG: Using LLM for complex query analysis...\")\n",
        "\n",
        "        # Prepare comprehensive data context for LLM\n",
        "        data_context = self._prepare_comprehensive_context(all_slack_data)\n",
        "\n",
        "        # Use the LLM for complex analysis\n",
        "        return self._generate_llm_response(question, data_context)\n",
        "\n",
        "    def _prepare_comprehensive_context(self, all_slack_data: List[Dict]) -> str:\n",
        "        \"\"\"Prepare comprehensive timing data context for LLM analysis\"\"\"\n",
        "        context = \"TIMING ANALYSIS DATA:\\n\"\n",
        "        context += f\"Total paths analyzed: {len(all_slack_data)}\\n\\n\"\n",
        "\n",
        "        # Add summary statistics\n",
        "        slack_values = [path['slack'] for path in all_slack_data]\n",
        "        context += f\"SLACK SUMMARY:\\n\"\n",
        "        context += f\"- Minimum slack: {min(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Maximum slack: {max(slack_values):.3f}ns\\n\"\n",
        "        context += f\"- Average slack: {sum(slack_values)/len(slack_values):.3f}ns\\n\\n\"\n",
        "\n",
        "        # Add individual path details\n",
        "        context += f\"DETAILED PATH ANALYSIS:\\n\"\n",
        "        for i, path in enumerate(all_slack_data, 1):\n",
        "            context += f\"Path {i}:\\n\"\n",
        "            context += f\"  Startpoint: {path['startpoint']}\\n\"\n",
        "            context += f\"  Endpoint: {path['endpoint']}\\n\"\n",
        "            context += f\"  Slack: {path['slack']}ns\\n\"\n",
        "            context += f\"  Group: {path['group']}\\n\"\n",
        "\n",
        "            # Add clock skew if available\n",
        "            if path.get('clock_skew'):\n",
        "                clock_skew = path['clock_skew']\n",
        "                context += f\"  Clock skew: {clock_skew}ns\\n\"\n",
        "\n",
        "                # Add interpretation\n",
        "                current_slack = slack_values[i-1]\n",
        "                if current_slack < 0:\n",
        "                    context += f\"  Slack analysis: TIMING FAILURE (negative slack = violation)\\n\"\n",
        "                elif current_slack < 0.1:\n",
        "                    context += f\"  Slack analysis: CRITICAL (very small positive margin)\\n\"\n",
        "                else:\n",
        "                    context += f\"  Slack analysis: TIMING PASS (adequate positive margin)\\n\"\n",
        "\n",
        "                if clock_skew > 0.4:\n",
        "                    context += f\"  Clock skew analysis: HIGH (may impact timing margin)\\n\"\n",
        "\n",
        "            # Add hold time if available\n",
        "            if path.get('hold_time_requirement'):\n",
        "                hold_time = path['hold_time_requirement']\n",
        "                context += f\"  Hold time requirement: {hold_time}ns\\n\"\n",
        "\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add analysis guidance\n",
        "        context += \"ANALYSIS GUIDANCE:\\n\"\n",
        "        context += \"- POSITIVE slack = timing PASS (data arrives before required time)\\n\"\n",
        "        context += \"- NEGATIVE slack = timing FAILURE (violation)\\n\"\n",
        "        context += \"- Slack < 0.1ns = critical margin (close to violation)\\n\"\n",
        "        context += \"- Clock skew > 0.4ns typically impacts timing margin\\n\"\n",
        "        context += \"- Current data shows ONLY positive slacks (all paths PASS)\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "def main():\n",
        "    # Create RAG system\n",
        "    rag = ImprovedLocalTimingRAG()\n",
        "\n",
        "    # Index timing reports\n",
        "    rag.index_timing_reports('./timing_reports/')\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n=== Improved Timing RAG System Ready ===\")\n",
        "    print(\"Ask questions about your timing data. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if question:\n",
        "            answer = rag.query(question)\n",
        "            print(f\"Answer: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "015f311773fb4a09b40d46677f764c41",
            "012bafda3cbe45bc83a47c6ca01a6b81",
            "1f01111afce84d82a65dccf4b2ba5fa0",
            "c86dde567c304a4eaa36b35df8af0fde",
            "1f3bc8d7e72e43df881889c634ee4bfe",
            "7a375caa353e468a891f41e2abc3adab",
            "e7535dc2e43e47f894d96ad56b9eac18",
            "610a7bae572c4e5f80eec672ac862792",
            "41c6ced0159f42aaa1967bea5eb7237c",
            "4a05056fd57745488691556fcba5e2cb",
            "fa5f4804912e4320bca4de46c0404cf1"
          ]
        },
        "id": "bb3ZrDfRupqo",
        "outputId": "1cedf9a6-04c1-40c4-b21b-36448eb55081"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading codellama/CodeLlama-7b-Instruct-hf...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "015f311773fb4a09b40d46677f764c41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded codellama/CodeLlama-7b-Instruct-hf\n",
            "Using device: cuda\n",
            "Using in-memory database\n",
            "=== Indexing timing reports ===\n",
            "Found 1 JSON files to index\n",
            "Indexing caravel.min-hkspi_clk-min_timing_full.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully indexed caravel.min-hkspi_clk-min_timing_full.json with 659 paths\n",
            "Indexing complete!\n",
            "\n",
            "=== Improved Timing RAG System Ready ===\n",
            "Ask questions about your timing data. Type 'quit' to exit.\n",
            "\n",
            "Question: Show top 10 worst clock skews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'Show top 10 worst clock skews'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'Show top 10 worst clock skews'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: Show top 10 worst clock skews\n",
            "DEBUG: Found 659 paths\n",
            "DEBUG: Clock skew ranking requested\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.08s\n",
            "Answer: Top 10 worst clock skew paths:\n",
            "1. Clock skew: 1.753ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6746_ in group hkspi_clk (Slack: 1.813ns)\n",
            "2. Clock skew: 1.753ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6623_ in group hkspi_clk (Slack: 1.829ns)\n",
            "3. Clock skew: 1.752ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6977_ in group hkspi_clk (Slack: 2.013ns)\n",
            "4. Clock skew: 1.751ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6929_ in group hkspi_clk (Slack: 1.998ns)\n",
            "5. Clock skew: 1.751ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6975_ in group hkspi_clk (Slack: 1.998ns)\n",
            "6. Clock skew: 1.751ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6927_ in group hkspi_clk (Slack: 1.999ns)\n",
            "7. Clock skew: 1.750ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7091_ in group hkspi_clk (Slack: 1.616ns)\n",
            "8. Clock skew: 1.750ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6931_ in group hkspi_clk (Slack: 2.038ns)\n",
            "9. Clock skew: 1.750ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6867_ in group hkspi_clk (Slack: 2.157ns)\n",
            "10. Clock skew: 1.750ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6915_ in group hkspi_clk (Slack: 1.496ns)\n",
            "\n",
            "Question: what is the worst clock skew?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'what is the worst clock skew?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'what is the worst clock skew?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'ranking'\n",
            "DEBUG: Question classified as: 'ranking' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: ranking\n",
            "DEBUG: Calling ranking handler\n",
            "DEBUG: Handling ranking query: what is the worst clock skew?\n",
            "DEBUG: Found 659 paths\n",
            "DEBUG: Clock skew ranking requested\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.08s\n",
            "Answer: Top 2 worst clock skew paths:\n",
            "1. Clock skew: 1.753ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6746_ in group hkspi_clk (Slack: 1.813ns)\n",
            "2. Clock skew: 1.753ns [⚠️ HIGH] - Path from chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6623_ in group hkspi_clk (Slack: 1.829ns)\n",
            "\n",
            "Question: for better hold time slack , should clock skew be more or less?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: Query method called with: 'for better hold time slack , should clock skew be more or less?'\n",
            "DEBUG: Adding to history...\n",
            "DEBUG: Getting all slack data...\n",
            "DEBUG: Getting all slack data from collection...\n",
            "DEBUG: Calling collection.get()...\n",
            "DEBUG: Collection.get() returned 659 entries\n",
            "DEBUG: Processed 659 slack data entries\n",
            "DEBUG: Retrieved 659 slack data entries\n",
            "DEBUG: Classifying question...\n",
            "DEBUG: Classifying question: 'for better hold time slack , should clock skew be more or less?'\n",
            "DEBUG: Query complexity: simple\n",
            "DEBUG: Using fast pattern matching for simple query...\n",
            "DEBUG: Pattern matched as 'filtering' (clock skew)\n",
            "DEBUG: Question classified as: 'filtering' (took 0.00s)\n",
            "DEBUG: Routing to handler for type: filtering\n",
            "DEBUG: Calling filtering handler\n",
            "DEBUG: Using direct filtering (no LLM)...\n",
            "DEBUG: Handler completed in 0.00s, total query time: 0.06s\n",
            "Answer: Clock skew information for all paths:\n",
            "1. Path chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6778_ - Clock skew: 0.4998999999999967ns - Slack: 0.3252ns\n",
            "2. Path chip_core/housekeeping/_6656_ to chip_core/housekeeping/_6654_ - Clock skew: 0.4468000000000001ns - Slack: 0.6112ns\n",
            "3. Path chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6469_ - Clock skew: 0.4463999999999999ns - Slack: 0.6174ns\n",
            "4. Path chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6449_ - Clock skew: 0.4526999999999999ns - Slack: 0.628ns\n",
            "5. Path chip_core/housekeeping/_6437_ to chip_core/housekeeping/_6435_ - Clock skew: 0.44589999999999996ns - Slack: 0.6306ns\n",
            "6. Path chip_core/housekeeping/_6469_ to chip_core/housekeeping/_6470_ - Clock skew: 0.4465999999999999ns - Slack: 0.6453ns\n",
            "7. Path chip_core/housekeeping/_6460_ to chip_core/housekeeping/_6462_ - Clock skew: 0.4454ns - Slack: 0.6522ns\n",
            "8. Path chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6437_ - Clock skew: 0.4458ns - Slack: 0.6596ns\n",
            "9. Path chip_core/housekeeping/_6654_ to chip_core/housekeeping/_6459_ - Clock skew: 0.4404000000000001ns - Slack: 0.6613ns\n",
            "10. Path chip_core/housekeeping/_6466_ to chip_core/housekeeping/_6466_ - Clock skew: 0.4438000000000002ns - Slack: 0.6626ns\n",
            "11. Path chip_core/housekeeping/_6445_ to chip_core/housekeeping/_6445_ - Clock skew: 0.4469000000000003ns - Slack: 0.6636ns\n",
            "12. Path chip_core/housekeeping/_6448_ to chip_core/housekeeping/_6455_ - Clock skew: 0.4477ns - Slack: 0.6756ns\n",
            "13. Path chip_core/housekeeping/_6445_ to chip_core/housekeeping/_6656_ - Clock skew: 0.4469000000000003ns - Slack: 0.6908ns\n",
            "14. Path chip_core/housekeeping/_6468_ to chip_core/housekeeping/_6457_ - Clock skew: 0.4459000000000002ns - Slack: 0.7053ns\n",
            "15. Path chip_core/housekeeping/_6460_ to chip_core/housekeeping/_6460_ - Clock skew: 0.44379999999999975ns - Slack: 0.7207ns\n",
            "16. Path chip_core/housekeeping/_6466_ to chip_core/housekeeping/_6467_ - Clock skew: 0.44310000000000005ns - Slack: 0.7261ns\n",
            "17. Path chip_core/housekeeping/_6654_ to chip_core/housekeeping/_6456_ - Clock skew: 0.4387000000000001ns - Slack: 0.7265ns\n",
            "18. Path chip_core/housekeeping/_6470_ to chip_core/housekeeping/_6448_ - Clock skew: 0.4526999999999999ns - Slack: 0.7311ns\n",
            "19. Path chip_core/housekeeping/_6464_ to chip_core/housekeeping/_6464_ - Clock skew: 0.44379999999999975ns - Slack: 0.7766ns\n",
            "20. Path chip_core/housekeeping/_6776_ to chip_core/housekeeping/_6776_ - Clock skew: 0.49969999999999715ns - Slack: 0.7807ns\n",
            "21. Path chip_core/housekeeping/_6774_ to chip_core/housekeeping/_6774_ - Clock skew: 0.49960000000000093ns - Slack: 0.7993ns\n",
            "22. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6465_ - Clock skew: 0.40339999999999976ns - Slack: 0.834ns\n",
            "23. Path chip_core/housekeeping/_6654_ to chip_core/housekeeping/_6468_ - Clock skew: 0.4408000000000001ns - Slack: 0.8464ns\n",
            "24. Path chip_core/housekeeping/_6440_ to chip_core/housekeeping/_6441_ - Clock skew: 0.44290000000000007ns - Slack: 0.8749ns\n",
            "25. Path chip_core/housekeeping/_6439_ to chip_core/housekeeping/_6439_ - Clock skew: 0.44290000000000007ns - Slack: 0.8768ns\n",
            "26. Path chip_core/housekeeping/_6439_ to chip_core/housekeeping/_6440_ - Clock skew: 0.44290000000000007ns - Slack: 0.8801ns\n",
            "27. Path chip_core/housekeeping/_6441_ to chip_core/housekeeping/_6442_ - Clock skew: 0.4424999999999999ns - Slack: 0.885ns\n",
            "28. Path chip_core/housekeeping/_6778_ to chip_core/housekeeping/_6779_ - Clock skew: 0.4953999999999965ns - Slack: 0.8867ns\n",
            "29. Path chip_core/housekeeping/_6443_ to chip_core/housekeeping/_6444_ - Clock skew: 0.44289999999999985ns - Slack: 0.8877ns\n",
            "30. Path chip_core/housekeeping/_6443_ to chip_core/housekeeping/_6443_ - Clock skew: 0.44289999999999985ns - Slack: 0.888ns\n",
            "31. Path chip_core/housekeeping/_6438_ to chip_core/housekeeping/_6438_ - Clock skew: 0.44289999999999985ns - Slack: 0.8896ns\n",
            "32. Path chip_core/housekeeping/_6446_ to chip_core/housekeeping/_6447_ - Clock skew: 0.4469000000000003ns - Slack: 0.8914ns\n",
            "33. Path chip_core/housekeeping/_6779_ to chip_core/housekeeping/_6780_ - Clock skew: 0.49969999999999715ns - Slack: 0.8965ns\n",
            "34. Path chip_core/housekeeping/_6655_ to chip_core/housekeeping/_6458_ - Clock skew: 0.4465000000000001ns - Slack: 0.8967ns\n",
            "35. Path chip_core/housekeeping/_6774_ to chip_core/housekeeping/_6775_ - Clock skew: 0.49960000000000093ns - Slack: 0.8969ns\n",
            "36. Path chip_core/housekeeping/_6780_ to chip_core/housekeeping/_6781_ - Clock skew: 0.4988000000000028ns - Slack: 0.9092ns\n",
            "37. Path chip_core/housekeeping/_6776_ to chip_core/housekeeping/_6777_ - Clock skew: 0.49979999999999336ns - Slack: 0.9155ns\n",
            "38. Path chip_core/housekeeping/_6437_ to chip_core/housekeeping/_6657_ - Clock skew: 0.45409999999999995ns - Slack: 0.9193ns\n",
            "39. Path chip_core/housekeeping/_6435_ to chip_core/housekeeping/_6655_ - Clock skew: 0.44699999999999984ns - Slack: 0.9408ns\n",
            "40. Path chip_core/housekeeping/_6445_ to chip_core/housekeeping/_6446_ - Clock skew: 0.4471000000000003ns - Slack: 0.9506ns\n",
            "41. Path chip_core/housekeeping/_6437_ to chip_core/housekeeping/_6658_ - Clock skew: 0.45310000000000006ns - Slack: 0.977ns\n",
            "42. Path chip_core/housekeeping/_6461_ to chip_core/housekeeping/_6461_ - Clock skew: 0.4439000000000002ns - Slack: 1.0506ns\n",
            "43. Path chip_core/housekeeping/_6434_ to chip_core/housekeeping/_6434_ - Clock skew: 0.4977000000000018ns - Slack: 1.0576ns\n",
            "44. Path chip_core/housekeeping/_6462_ to chip_core/housekeeping/_6463_ - Clock skew: 0.4438ns - Slack: 1.1003ns\n",
            "45. Path chip_core/housekeeping/_6706_ to chip_core/housekeeping/_6706_ - Clock skew: 0.5449999999999999ns - Slack: 1.2632ns\n",
            "46. Path chip_core/housekeeping/_7133_ to chip_core/housekeeping/_7133_ - Clock skew: 0.5411999999999999ns - Slack: 1.324ns\n",
            "47. Path chip_core/housekeeping/_6877_ to chip_core/housekeeping/_6877_ - Clock skew: 0.5461999999999998ns - Slack: 1.326ns\n",
            "48. Path chip_core/housekeeping/_6705_ to chip_core/housekeeping/_6705_ - Clock skew: 0.5452999999999997ns - Slack: 1.326ns\n",
            "49. Path chip_core/housekeeping/_6571_ to chip_core/housekeeping/_6571_ - Clock skew: 0.5453000000000001ns - Slack: 1.3267ns\n",
            "50. Path chip_core/housekeeping/_7134_ to chip_core/housekeeping/_7134_ - Clock skew: 0.5407000000000002ns - Slack: 1.3354ns\n",
            "51. Path chip_core/housekeeping/_6616_ to chip_core/housekeeping/_6616_ - Clock skew: 0.5460000000000003ns - Slack: 1.3612ns\n",
            "52. Path chip_core/housekeeping/_7102_ to chip_core/housekeeping/_7102_ - Clock skew: 0.5407000000000002ns - Slack: 1.3722ns\n",
            "53. Path chip_core/housekeeping/_6957_ to chip_core/housekeeping/_6957_ - Clock skew: 0.5402ns - Slack: 1.3835ns\n",
            "54. Path chip_core/housekeeping/_6488_ to chip_core/housekeeping/_6488_ - Clock skew: 0.5427ns - Slack: 1.393ns\n",
            "55. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6808_ - Clock skew: 1.6988999999999999ns - Slack: 1.3996ns\n",
            "56. Path chip_core/housekeeping/_7038_ to chip_core/housekeeping/_7038_ - Clock skew: 0.5430999999999999ns - Slack: 1.4084ns\n",
            "57. Path chip_core/housekeeping/_7037_ to chip_core/housekeeping/_7037_ - Clock skew: 0.544ns - Slack: 1.4223ns\n",
            "58. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6914_ - Clock skew: 1.7184000000000001ns - Slack: 1.4284ns\n",
            "59. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6508_ - Clock skew: 1.6796ns - Slack: 1.4362ns\n",
            "60. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6505_ - Clock skew: 1.6792999999999998ns - Slack: 1.4459ns\n",
            "61. Path chip_core/housekeeping/_6950_ to chip_core/housekeeping/_6950_ - Clock skew: 0.5428999999999999ns - Slack: 1.4486ns\n",
            "62. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6504_ - Clock skew: 1.691ns - Slack: 1.4511ns\n",
            "63. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6978_ - Clock skew: 1.7187ns - Slack: 1.4627ns\n",
            "64. Path chip_core/housekeeping/_6949_ to chip_core/housekeeping/_6949_ - Clock skew: 0.5453000000000001ns - Slack: 1.4651ns\n",
            "65. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6503_ - Clock skew: 1.691ns - Slack: 1.4821ns\n",
            "66. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6661_ - Clock skew: 1.684ns - Slack: 1.492ns\n",
            "67. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6660_ - Clock skew: 1.6796999999999997ns - Slack: 1.4957ns\n",
            "68. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6915_ - Clock skew: 1.7499ns - Slack: 1.4959ns\n",
            "69. Path chip_core/housekeeping/_6512_ to chip_core/housekeeping/_6512_ - Clock skew: 0.5438000000000001ns - Slack: 1.4961ns\n",
            "70. Path chip_core/housekeeping/_6831_ to chip_core/housekeeping/_6831_ - Clock skew: 0.5415999999999999ns - Slack: 1.4987ns\n",
            "71. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6626_ - Clock skew: 1.7059ns - Slack: 1.4996ns\n",
            "72. Path chip_core/housekeeping/_6513_ to chip_core/housekeeping/_6513_ - Clock skew: 0.5396000000000001ns - Slack: 1.5072ns\n",
            "73. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6625_ - Clock skew: 1.6985ns - Slack: 1.5086ns\n",
            "74. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6627_ - Clock skew: 1.6916999999999998ns - Slack: 1.5099ns\n",
            "75. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7010_ - Clock skew: 1.7139ns - Slack: 1.5124ns\n",
            "76. Path chip_core/housekeeping/_6674_ to chip_core/housekeeping/_6674_ - Clock skew: 0.544ns - Slack: 1.5158ns\n",
            "77. Path chip_core/housekeeping/_6737_ to chip_core/housekeeping/_6737_ - Clock skew: 0.5444999999999998ns - Slack: 1.5165ns\n",
            "78. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6624_ - Clock skew: 1.6984000000000001ns - Slack: 1.5169ns\n",
            "79. Path chip_core/housekeeping/_6514_ to chip_core/housekeeping/_6514_ - Clock skew: 0.5406999999999997ns - Slack: 1.5204ns\n",
            "80. Path chip_core/housekeeping/_6484_ to chip_core/housekeeping/_6484_ - Clock skew: 0.544ns - Slack: 1.5209ns\n",
            "81. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6628_ - Clock skew: 1.684ns - Slack: 1.5224ns\n",
            "82. Path chip_core/housekeeping/_6515_ to chip_core/housekeeping/_6515_ - Clock skew: 0.5410000000000004ns - Slack: 1.5225ns\n",
            "83. Path chip_core/housekeeping/_7100_ to chip_core/housekeeping/_7100_ - Clock skew: 0.5446ns - Slack: 1.5277ns\n",
            "84. Path chip_core/housekeeping/_6511_ to chip_core/housekeeping/_6511_ - Clock skew: 0.5438000000000001ns - Slack: 1.5299ns\n",
            "85. Path chip_core/housekeeping/_6832_ to chip_core/housekeeping/_6832_ - Clock skew: 0.5415999999999999ns - Slack: 1.5304ns\n",
            "86. Path chip_core/housekeeping/_6662_ to chip_core/housekeeping/_6662_ - Clock skew: 0.5415999999999999ns - Slack: 1.5312ns\n",
            "87. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6820_ - Clock skew: 1.6327999999999998ns - Slack: 1.5348ns\n",
            "88. Path chip_core/housekeeping/_6516_ to chip_core/housekeeping/_6516_ - Clock skew: 0.5409999999999999ns - Slack: 1.5368ns\n",
            "89. Path chip_core/housekeeping/_6814_ to chip_core/housekeeping/_6814_ - Clock skew: 0.5425ns - Slack: 1.5373ns\n",
            "90. Path chip_core/housekeeping/_6514_ to chip_core/housekeeping/_6498_ - Clock skew: 0.5408ns - Slack: 1.5419ns\n",
            "91. Path chip_core/housekeeping/_6810_ to chip_core/housekeeping/_6810_ - Clock skew: 0.5417999999999998ns - Slack: 1.542ns\n",
            "92. Path chip_core/housekeeping/_6829_ to chip_core/housekeeping/_6829_ - Clock skew: 0.5438000000000001ns - Slack: 1.5441ns\n",
            "93. Path chip_core/housekeeping/_6835_ to chip_core/housekeeping/_6835_ - Clock skew: 0.5438000000000001ns - Slack: 1.5451ns\n",
            "94. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6666_ - Clock skew: 1.6798ns - Slack: 1.5466ns\n",
            "95. Path chip_core/housekeeping/_6535_ to chip_core/housekeeping/_6535_ - Clock skew: 0.5442ns - Slack: 1.5491ns\n",
            "96. Path chip_core/housekeeping/_6536_ to chip_core/housekeeping/_6536_ - Clock skew: 0.5441999999999996ns - Slack: 1.5514ns\n",
            "97. Path chip_core/housekeeping/_6510_ to chip_core/housekeeping/_6510_ - Clock skew: 0.5438000000000001ns - Slack: 1.5535ns\n",
            "98. Path chip_core/housekeeping/_7137_ to chip_core/housekeeping/_7137_ - Clock skew: 0.5413000000000001ns - Slack: 1.5565ns\n",
            "99. Path chip_core/housekeeping/_6830_ to chip_core/housekeeping/_6830_ - Clock skew: 0.5440999999999998ns - Slack: 1.5618ns\n",
            "100. Path chip_core/housekeeping/_6538_ to chip_core/housekeeping/_6538_ - Clock skew: 0.5442999999999998ns - Slack: 1.5628ns\n",
            "101. Path chip_core/housekeeping/_6512_ to chip_core/housekeeping/_6496_ - Clock skew: 0.5436999999999999ns - Slack: 1.5631ns\n",
            "102. Path chip_core/housekeeping/_6813_ to chip_core/housekeeping/_6813_ - Clock skew: 0.5425ns - Slack: 1.5638ns\n",
            "103. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6961_ - Clock skew: 1.6694000000000002ns - Slack: 1.5644ns\n",
            "104. Path chip_core/housekeeping/_7041_ to chip_core/housekeeping/_7041_ - Clock skew: 0.5411999999999999ns - Slack: 1.5687ns\n",
            "105. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6697_ - Clock skew: 1.6735999999999998ns - Slack: 1.5737ns\n",
            "106. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6895_ - Clock skew: 1.7124ns - Slack: 1.5741ns\n",
            "107. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6699_ - Clock skew: 1.6737999999999997ns - Slack: 1.576ns\n",
            "108. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6849_ - Clock skew: 1.7005000000000001ns - Slack: 1.5792ns\n",
            "109. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6700_ - Clock skew: 1.6737ns - Slack: 1.5818ns\n",
            "110. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6754_ - Clock skew: 1.7055ns - Slack: 1.5827ns\n",
            "111. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6698_ - Clock skew: 1.6735999999999998ns - Slack: 1.5835ns\n",
            "112. Path chip_core/housekeeping/_6549_ to chip_core/housekeeping/_6549_ - Clock skew: 0.5285000000000002ns - Slack: 1.5858ns\n",
            "113. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6817_ - Clock skew: 1.6735ns - Slack: 1.5859ns\n",
            "114. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6530_ - Clock skew: 1.7124ns - Slack: 1.5887ns\n",
            "115. Path chip_core/housekeeping/_6833_ to chip_core/housekeeping/_6833_ - Clock skew: 0.5457000000000001ns - Slack: 1.5893ns\n",
            "116. Path chip_core/housekeeping/_7051_ to chip_core/housekeeping/_7051_ - Clock skew: 0.5432000000000001ns - Slack: 1.5902ns\n",
            "117. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6759_ - Clock skew: 1.7057999999999998ns - Slack: 1.5904ns\n",
            "118. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7075_ - Clock skew: 1.7496000000000003ns - Slack: 1.5911ns\n",
            "119. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6761_ - Clock skew: 1.7059ns - Slack: 1.5913ns\n",
            "120. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6665_ - Clock skew: 1.7074ns - Slack: 1.5923ns\n",
            "121. Path chip_core/housekeeping/_7095_ to chip_core/housekeeping/_7095_ - Clock skew: 0.5404ns - Slack: 1.5926ns\n",
            "122. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6819_ - Clock skew: 1.6822000000000001ns - Slack: 1.5927ns\n",
            "123. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6667_ - Clock skew: 1.7106000000000001ns - Slack: 1.5934ns\n",
            "124. Path chip_core/housekeeping/_7105_ to chip_core/housekeeping/_7105_ - Clock skew: 0.5412000000000003ns - Slack: 1.5945ns\n",
            "125. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6509_ - Clock skew: 1.6801000000000001ns - Slack: 1.5962ns\n",
            "126. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6533_ - Clock skew: 1.7127999999999999ns - Slack: 1.5963ns\n",
            "127. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6852_ - Clock skew: 1.6779ns - Slack: 1.5972ns\n",
            "128. Path chip_core/housekeeping/_7050_ to chip_core/housekeeping/_7050_ - Clock skew: 0.5425ns - Slack: 1.5972ns\n",
            "129. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6701_ - Clock skew: 1.6691999999999998ns - Slack: 1.5974ns\n",
            "130. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6532_ - Clock skew: 1.7127000000000001ns - Slack: 1.5979ns\n",
            "131. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6846_ - Clock skew: 1.6832ns - Slack: 1.5988ns\n",
            "132. Path chip_core/housekeeping/_6822_ to chip_core/housekeeping/_6822_ - Clock skew: 0.5433999999999997ns - Slack: 1.6003ns\n",
            "133. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6580_ - Clock skew: 1.6910999999999998ns - Slack: 1.6003ns\n",
            "134. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6783_ - Clock skew: 1.7382000000000002ns - Slack: 1.6024ns\n",
            "135. Path chip_core/housekeeping/_7045_ to chip_core/housekeeping/_7045_ - Clock skew: 0.5437000000000003ns - Slack: 1.6025ns\n",
            "136. Path chip_core/housekeeping/_7101_ to chip_core/housekeeping/_7101_ - Clock skew: 0.5444ns - Slack: 1.6026ns\n",
            "137. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6534_ - Clock skew: 1.7125000000000001ns - Slack: 1.604ns\n",
            "138. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6845_ - Clock skew: 1.7004ns - Slack: 1.6047ns\n",
            "139. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6757_ - Clock skew: 1.6916999999999998ns - Slack: 1.6051ns\n",
            "140. Path chip_core/housekeeping/_7108_ to chip_core/housekeeping/_7108_ - Clock skew: 0.5457000000000001ns - Slack: 1.6055ns\n",
            "141. Path chip_core/housekeeping/_7103_ to chip_core/housekeeping/_7103_ - Clock skew: 0.5404ns - Slack: 1.6058ns\n",
            "142. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6711_ - Clock skew: 1.7124ns - Slack: 1.6097ns\n",
            "143. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6782_ - Clock skew: 1.7382000000000002ns - Slack: 1.6101ns\n",
            "144. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6851_ - Clock skew: 1.6727999999999998ns - Slack: 1.6111ns\n",
            "145. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6758_ - Clock skew: 1.684ns - Slack: 1.6113ns\n",
            "146. Path chip_core/housekeeping/_6702_ to chip_core/housekeeping/_6702_ - Clock skew: 0.5453000000000001ns - Slack: 1.6119ns\n",
            "147. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6760_ - Clock skew: 1.692ns - Slack: 1.6124ns\n",
            "148. Path chip_core/housekeeping/_6663_ to chip_core/housekeeping/_6663_ - Clock skew: 0.5415999999999999ns - Slack: 1.614ns\n",
            "149. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7091_ - Clock skew: 1.7500000000000002ns - Slack: 1.6157ns\n",
            "150. Path chip_core/housekeeping/_6611_ to chip_core/housekeeping/_6611_ - Clock skew: 0.5488000000000004ns - Slack: 1.6162ns\n",
            "151. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6707_ - Clock skew: 1.7124ns - Slack: 1.6171ns\n",
            "152. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6582_ - Clock skew: 1.6918ns - Slack: 1.6172ns\n",
            "153. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6755_ - Clock skew: 1.6895999999999998ns - Slack: 1.6177ns\n",
            "154. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6487_ - Clock skew: 1.6653999999999998ns - Slack: 1.6183ns\n",
            "155. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6531_ - Clock skew: 1.7127000000000001ns - Slack: 1.6186ns\n",
            "156. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6793_ - Clock skew: 1.7106999999999999ns - Slack: 1.6191ns\n",
            "157. Path chip_core/housekeeping/_6811_ to chip_core/housekeeping/_6811_ - Clock skew: 0.5417999999999998ns - Slack: 1.6196ns\n",
            "158. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6812_ - Clock skew: 1.6529999999999998ns - Slack: 1.6197ns\n",
            "159. Path chip_core/housekeeping/_6881_ to chip_core/housekeeping/_6881_ - Clock skew: 0.5453000000000001ns - Slack: 1.6202ns\n",
            "160. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6848_ - Clock skew: 1.6685ns - Slack: 1.6212ns\n",
            "161. Path chip_core/housekeeping/_7097_ to chip_core/housekeeping/_7097_ - Clock skew: 0.5411999999999999ns - Slack: 1.6231ns\n",
            "162. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6583_ - Clock skew: 1.6895999999999998ns - Slack: 1.6233ns\n",
            "163. Path chip_core/housekeeping/_7073_ to chip_core/housekeeping/_7073_ - Clock skew: 0.5434999999999999ns - Slack: 1.6237ns\n",
            "164. Path chip_core/housekeeping/_7090_ to chip_core/housekeeping/_7090_ - Clock skew: 0.5434000000000001ns - Slack: 1.6259ns\n",
            "165. Path chip_core/housekeeping/_7140_ to chip_core/housekeeping/_7140_ - Clock skew: 0.5423ns - Slack: 1.6263ns\n",
            "166. Path chip_core/housekeeping/_7135_ to chip_core/housekeeping/_7135_ - Clock skew: 0.5404ns - Slack: 1.6278ns\n",
            "167. Path chip_core/housekeeping/_6883_ to chip_core/housekeeping/_6883_ - Clock skew: 0.5460000000000003ns - Slack: 1.6296ns\n",
            "168. Path chip_core/housekeeping/_6953_ to chip_core/housekeeping/_6953_ - Clock skew: 0.5405000000000002ns - Slack: 1.6298ns\n",
            "169. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6579_ - Clock skew: 1.684ns - Slack: 1.6328ns\n",
            "170. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6850_ - Clock skew: 1.6703ns - Slack: 1.6341ns\n",
            "171. Path chip_core/housekeeping/_6973_ to chip_core/housekeeping/_6973_ - Clock skew: 0.5441000000000003ns - Slack: 1.636ns\n",
            "172. Path chip_core/housekeeping/_6710_ to chip_core/housekeeping/_6710_ - Clock skew: 0.5460000000000003ns - Slack: 1.6367ns\n",
            "173. Path chip_core/housekeeping/_6704_ to chip_core/housekeeping/_6704_ - Clock skew: 0.5452999999999997ns - Slack: 1.6374ns\n",
            "174. Path chip_core/housekeeping/_7093_ to chip_core/housekeeping/_7093_ - Clock skew: 0.5453000000000001ns - Slack: 1.6395ns\n",
            "175. Path chip_core/housekeeping/_6539_ to chip_core/housekeeping/_6539_ - Clock skew: 0.5442ns - Slack: 1.6403ns\n",
            "176. Path chip_core/housekeeping/_7138_ to chip_core/housekeeping/_7138_ - Clock skew: 0.5442ns - Slack: 1.6448ns\n",
            "177. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6790_ - Clock skew: 1.7106999999999999ns - Slack: 1.6456ns\n",
            "178. Path chip_core/housekeeping/_7096_ to chip_core/housekeeping/_7096_ - Clock skew: 0.5423ns - Slack: 1.6555ns\n",
            "179. Path chip_core/housekeeping/_7116_ to chip_core/housekeeping/_7116_ - Clock skew: 0.5430999999999999ns - Slack: 1.6582ns\n",
            "180. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6586_ - Clock skew: 1.6805ns - Slack: 1.6586ns\n",
            "181. Path chip_core/housekeeping/_6864_ to chip_core/housekeeping/_6834_ - Clock skew: 0.5461999999999998ns - Slack: 1.6593ns\n",
            "182. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6821_ - Clock skew: 1.7049ns - Slack: 1.6595ns\n",
            "183. Path chip_core/housekeeping/_6573_ to chip_core/housekeeping/_6573_ - Clock skew: 0.5453000000000001ns - Slack: 1.6611ns\n",
            "184. Path chip_core/housekeeping/_6522_ to chip_core/housekeeping/_6522_ - Clock skew: 0.544ns - Slack: 1.6613ns\n",
            "185. Path chip_core/housekeeping/_6879_ to chip_core/housekeeping/_6879_ - Clock skew: 0.5461ns - Slack: 1.6631ns\n",
            "186. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6847_ - Clock skew: 1.7097ns - Slack: 1.6635ns\n",
            "187. Path chip_core/housekeeping/_6715_ to chip_core/housekeeping/_6715_ - Clock skew: 0.5406ns - Slack: 1.6669ns\n",
            "188. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6752_ - Clock skew: 1.6744ns - Slack: 1.6672ns\n",
            "189. Path chip_core/housekeeping/_6703_ to chip_core/housekeeping/_6703_ - Clock skew: 0.5452999999999997ns - Slack: 1.6687ns\n",
            "190. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6984_ - Clock skew: 1.7217ns - Slack: 1.67ns\n",
            "191. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6988_ - Clock skew: 1.712ns - Slack: 1.6704ns\n",
            "192. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6584_ - Clock skew: 1.6803000000000001ns - Slack: 1.6708ns\n",
            "193. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6585_ - Clock skew: 1.6813999999999998ns - Slack: 1.6709ns\n",
            "194. Path chip_core/housekeeping/_7076_ to chip_core/housekeeping/_7076_ - Clock skew: 0.5458000000000003ns - Slack: 1.671ns\n",
            "195. Path chip_core/housekeeping/_7039_ to chip_core/housekeeping/_7039_ - Clock skew: 0.5412000000000003ns - Slack: 1.6714ns\n",
            "196. Path chip_core/housekeeping/_7044_ to chip_core/housekeeping/_7044_ - Clock skew: 0.5442ns - Slack: 1.6716ns\n",
            "197. Path chip_core/housekeeping/_7106_ to chip_core/housekeeping/_7106_ - Clock skew: 0.5437999999999996ns - Slack: 1.672ns\n",
            "198. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6986_ - Clock skew: 1.7222000000000002ns - Slack: 1.672ns\n",
            "199. Path chip_core/housekeeping/_7042_ to chip_core/housekeeping/_7042_ - Clock skew: 0.5440999999999998ns - Slack: 1.6728ns\n",
            "200. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6987_ - Clock skew: 1.7121000000000002ns - Slack: 1.6741ns\n",
            "201. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6588_ - Clock skew: 1.6805ns - Slack: 1.6748ns\n",
            "202. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6629_ - Clock skew: 1.6813ns - Slack: 1.6804ns\n",
            "203. Path chip_core/housekeeping/_6572_ to chip_core/housekeeping/_6572_ - Clock skew: 0.5453999999999999ns - Slack: 1.6815ns\n",
            "204. Path chip_core/housekeeping/_7139_ to chip_core/housekeeping/_7139_ - Clock skew: 0.5440999999999998ns - Slack: 1.6822ns\n",
            "205. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6809_ - Clock skew: 1.6914999999999998ns - Slack: 1.6826ns\n",
            "206. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6983_ - Clock skew: 1.7217ns - Slack: 1.6882ns\n",
            "207. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6587_ - Clock skew: 1.6813999999999998ns - Slack: 1.6884ns\n",
            "208. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6631_ - Clock skew: 1.6813999999999998ns - Slack: 1.6896ns\n",
            "209. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6803_ - Clock skew: 1.6820000000000002ns - Slack: 1.6897ns\n",
            "210. Path chip_core/housekeeping/_7107_ to chip_core/housekeeping/_7107_ - Clock skew: 0.5457999999999998ns - Slack: 1.6898ns\n",
            "211. Path chip_core/housekeeping/_7094_ to chip_core/housekeeping/_7094_ - Clock skew: 0.5425ns - Slack: 1.6905ns\n",
            "212. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6630_ - Clock skew: 1.6815ns - Slack: 1.6909ns\n",
            "213. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6982_ - Clock skew: 1.7077000000000002ns - Slack: 1.6918ns\n",
            "214. Path chip_core/housekeeping/_7104_ to chip_core/housekeeping/_7104_ - Clock skew: 0.544ns - Slack: 1.6954ns\n",
            "215. Path chip_core/housekeeping/_6520_ to chip_core/housekeeping/_6520_ - Clock skew: 0.5446ns - Slack: 1.696ns\n",
            "216. Path chip_core/housekeeping/_6884_ to chip_core/housekeeping/_6884_ - Clock skew: 0.5460000000000003ns - Slack: 1.6966ns\n",
            "217. Path chip_core/housekeeping/_6537_ to chip_core/housekeeping/_6537_ - Clock skew: 0.5446ns - Slack: 1.6966ns\n",
            "218. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6753_ - Clock skew: 1.6863ns - Slack: 1.6967ns\n",
            "219. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6633_ - Clock skew: 1.6813999999999998ns - Slack: 1.6972ns\n",
            "220. Path chip_core/housekeeping/_6521_ to chip_core/housekeeping/_6521_ - Clock skew: 0.5436999999999999ns - Slack: 1.6976ns\n",
            "221. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6632_ - Clock skew: 1.6813999999999998ns - Slack: 1.6998ns\n",
            "222. Path chip_core/housekeeping/_6833_ to chip_core/housekeeping/_6664_ - Clock skew: 0.5457000000000001ns - Slack: 1.7001ns\n",
            "223. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6789_ - Clock skew: 1.7106999999999999ns - Slack: 1.7017ns\n",
            "224. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6971_ - Clock skew: 1.7101999999999997ns - Slack: 1.7023ns\n",
            "225. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6801_ - Clock skew: 1.7047999999999999ns - Slack: 1.7026ns\n",
            "226. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6709_ - Clock skew: 1.7123000000000002ns - Slack: 1.7027ns\n",
            "227. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6581_ - Clock skew: 1.6918ns - Slack: 1.7041ns\n",
            "228. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6797_ - Clock skew: 1.7047999999999999ns - Slack: 1.7057ns\n",
            "229. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6972_ - Clock skew: 1.7103ns - Slack: 1.706ns\n",
            "230. Path chip_core/housekeeping/_6518_ to chip_core/housekeeping/_6518_ - Clock skew: 0.5446ns - Slack: 1.706ns\n",
            "231. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6791_ - Clock skew: 1.7106999999999999ns - Slack: 1.7063ns\n",
            "232. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6708_ - Clock skew: 1.7104000000000001ns - Slack: 1.7083ns\n",
            "233. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6794_ - Clock skew: 1.7207000000000001ns - Slack: 1.7149ns\n",
            "234. Path chip_core/housekeeping/_7099_ to chip_core/housekeeping/_7099_ - Clock skew: 0.5435999999999996ns - Slack: 1.717ns\n",
            "235. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6892_ - Clock skew: 1.707ns - Slack: 1.7174ns\n",
            "236. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6756_ - Clock skew: 1.6891ns - Slack: 1.7182ns\n",
            "237. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6792_ - Clock skew: 1.7106999999999999ns - Slack: 1.7182ns\n",
            "238. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6981_ - Clock skew: 1.6696000000000002ns - Slack: 1.7199ns\n",
            "239. Path chip_core/housekeeping/_7040_ to chip_core/housekeeping/_7040_ - Clock skew: 0.5430999999999999ns - Slack: 1.7201ns\n",
            "240. Path chip_core/housekeeping/_6864_ to chip_core/housekeeping/_6836_ - Clock skew: 0.5491999999999999ns - Slack: 1.7218ns\n",
            "241. Path chip_core/housekeeping/_7120_ to chip_core/housekeeping/_7120_ - Clock skew: 0.5406ns - Slack: 1.7247ns\n",
            "242. Path chip_core/housekeeping/_6523_ to chip_core/housekeeping/_6523_ - Clock skew: 0.5438000000000001ns - Slack: 1.7267ns\n",
            "243. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6891_ - Clock skew: 1.7070999999999998ns - Slack: 1.7282ns\n",
            "244. Path chip_core/housekeeping/_6880_ to chip_core/housekeeping/_6880_ - Clock skew: 0.5459999999999998ns - Slack: 1.7298ns\n",
            "245. Path chip_core/housekeeping/_6882_ to chip_core/housekeeping/_6882_ - Clock skew: 0.5434000000000001ns - Slack: 1.7302ns\n",
            "246. Path chip_core/housekeeping/_6517_ to chip_core/housekeeping/_6517_ - Clock skew: 0.5446ns - Slack: 1.7315ns\n",
            "247. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6744_ - Clock skew: 1.746ns - Slack: 1.7315ns\n",
            "248. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6966_ - Clock skew: 1.6937ns - Slack: 1.7321ns\n",
            "249. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6970_ - Clock skew: 1.6794ns - Slack: 1.738ns\n",
            "250. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6477_ - Clock skew: 1.6910999999999998ns - Slack: 1.739ns\n",
            "251. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6639_ - Clock skew: 1.7184ns - Slack: 1.7396ns\n",
            "252. Path chip_core/housekeeping/_6815_ to chip_core/housekeeping/_6815_ - Clock skew: 0.5425ns - Slack: 1.7399ns\n",
            "253. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6985_ - Clock skew: 1.6695ns - Slack: 1.7409ns\n",
            "254. Path chip_core/housekeeping/_6878_ to chip_core/housekeeping/_6878_ - Clock skew: 0.5459ns - Slack: 1.7409ns\n",
            "255. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6453_ - Clock skew: 1.7319999999999998ns - Slack: 1.742ns\n",
            "256. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6968_ - Clock skew: 1.6794ns - Slack: 1.7423ns\n",
            "257. Path chip_core/housekeeping/_6621_ to chip_core/housekeeping/_6621_ - Clock skew: 0.5476000000000001ns - Slack: 1.7443ns\n",
            "258. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6450_ - Clock skew: 1.7319999999999998ns - Slack: 1.7452ns\n",
            "259. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6640_ - Clock skew: 1.7216999999999998ns - Slack: 1.75ns\n",
            "260. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6451_ - Clock skew: 1.7182999999999997ns - Slack: 1.7501ns\n",
            "261. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6840_ - Clock skew: 1.6721000000000001ns - Slack: 1.7515ns\n",
            "262. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6452_ - Clock skew: 1.7319999999999998ns - Slack: 1.7538ns\n",
            "263. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6885_ - Clock skew: 1.6752ns - Slack: 1.7549ns\n",
            "264. Path chip_core/housekeeping/_7136_ to chip_core/housekeeping/_7136_ - Clock skew: 0.5430999999999999ns - Slack: 1.7556ns\n",
            "265. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6473_ - Clock skew: 1.6823ns - Slack: 1.7558ns\n",
            "266. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6887_ - Clock skew: 1.6695999999999998ns - Slack: 1.7567ns\n",
            "267. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6886_ - Clock skew: 1.672ns - Slack: 1.7572ns\n",
            "268. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6643_ - Clock skew: 1.7218999999999998ns - Slack: 1.758ns\n",
            "269. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6965_ - Clock skew: 1.6847ns - Slack: 1.758ns\n",
            "270. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6807_ - Clock skew: 1.6622000000000001ns - Slack: 1.7595ns\n",
            "271. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6806_ - Clock skew: 1.6621ns - Slack: 1.7595ns\n",
            "272. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6732_ - Clock skew: 1.7140999999999997ns - Slack: 1.7606ns\n",
            "273. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6799_ - Clock skew: 1.7304000000000002ns - Slack: 1.7607ns\n",
            "274. Path chip_core/housekeeping/_6636_ to chip_core/housekeeping/_6636_ - Clock skew: 0.5455999999999999ns - Slack: 1.7614ns\n",
            "275. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6733_ - Clock skew: 1.7184ns - Slack: 1.762ns\n",
            "276. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6738_ - Clock skew: 1.6823ns - Slack: 1.7642ns\n",
            "277. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6802_ - Clock skew: 1.7047ns - Slack: 1.7653ns\n",
            "278. Path chip_core/housekeeping/_6818_ to chip_core/housekeeping/_6818_ - Clock skew: 0.5411999999999999ns - Slack: 1.7668ns\n",
            "279. Path chip_core/housekeeping/_6576_ to chip_core/housekeeping/_6576_ - Clock skew: 0.5445000000000002ns - Slack: 1.7674ns\n",
            "280. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6641_ - Clock skew: 1.7182ns - Slack: 1.768ns\n",
            "281. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6736_ - Clock skew: 1.714ns - Slack: 1.7682ns\n",
            "282. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6475_ - Clock skew: 1.6777ns - Slack: 1.7682ns\n",
            "283. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6472_ - Clock skew: 1.6823ns - Slack: 1.7692ns\n",
            "284. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6734_ - Clock skew: 1.7140999999999997ns - Slack: 1.7694ns\n",
            "285. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6740_ - Clock skew: 1.6817999999999997ns - Slack: 1.7697ns\n",
            "286. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6888_ - Clock skew: 1.7076999999999998ns - Slack: 1.7698ns\n",
            "287. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6843_ - Clock skew: 1.672ns - Slack: 1.7716ns\n",
            "288. Path chip_core/housekeeping/_6694_ to chip_core/housekeeping/_6694_ - Clock skew: 0.5447000000000002ns - Slack: 1.7717ns\n",
            "289. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6842_ - Clock skew: 1.6718ns - Slack: 1.7734ns\n",
            "290. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6454_ - Clock skew: 1.7178ns - Slack: 1.7738ns\n",
            "291. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6844_ - Clock skew: 1.6721000000000001ns - Slack: 1.7746ns\n",
            "292. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6804_ - Clock skew: 1.6621ns - Slack: 1.7747ns\n",
            "293. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6642_ - Clock skew: 1.7180999999999997ns - Slack: 1.775ns\n",
            "294. Path chip_core/housekeeping/_6918_ to chip_core/housekeeping/_6918_ - Clock skew: 0.5449999999999999ns - Slack: 1.7752ns\n",
            "295. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6839_ - Clock skew: 1.675ns - Slack: 1.7753ns\n",
            "296. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6739_ - Clock skew: 1.6823ns - Slack: 1.777ns\n",
            "297. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6785_ - Clock skew: 1.6798999999999997ns - Slack: 1.7784ns\n",
            "298. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6787_ - Clock skew: 1.6798ns - Slack: 1.7787ns\n",
            "299. Path chip_core/housekeeping/_6651_ to chip_core/housekeeping/_6651_ - Clock skew: 0.5475000000000003ns - Slack: 1.7791ns\n",
            "300. Path chip_core/housekeeping/_7098_ to chip_core/housekeeping/_7098_ - Clock skew: 0.5442ns - Slack: 1.7792ns\n",
            "301. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6870_ - Clock skew: 1.6685ns - Slack: 1.7795ns\n",
            "302. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7084_ - Clock skew: 1.6718ns - Slack: 1.7799ns\n",
            "303. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6735_ - Clock skew: 1.7069ns - Slack: 1.7805ns\n",
            "304. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6838_ - Clock skew: 1.6695999999999998ns - Slack: 1.7809ns\n",
            "305. Path chip_core/housekeeping/_7043_ to chip_core/housekeeping/_7043_ - Clock skew: 0.5430999999999999ns - Slack: 1.7813ns\n",
            "306. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6837_ - Clock skew: 1.6752999999999998ns - Slack: 1.7815ns\n",
            "307. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7126_ - Clock skew: 1.6918ns - Slack: 1.7827ns\n",
            "308. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6471_ - Clock skew: 1.6826ns - Slack: 1.7827ns\n",
            "309. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6476_ - Clock skew: 1.6777999999999997ns - Slack: 1.7853ns\n",
            "310. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6796_ - Clock skew: 1.7304000000000002ns - Slack: 1.7855ns\n",
            "311. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6474_ - Clock skew: 1.6777999999999997ns - Slack: 1.7856ns\n",
            "312. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7061_ - Clock skew: 1.6937ns - Slack: 1.7857ns\n",
            "313. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6934_ - Clock skew: 1.6937ns - Slack: 1.7872ns\n",
            "314. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6786_ - Clock skew: 1.6805999999999999ns - Slack: 1.7873ns\n",
            "315. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6876_ - Clock skew: 1.6743ns - Slack: 1.7874ns\n",
            "316. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6937_ - Clock skew: 1.7123000000000002ns - Slack: 1.7882ns\n",
            "317. Path chip_core/housekeeping/_6591_ to chip_core/housekeeping/_6591_ - Clock skew: 0.5432999999999999ns - Slack: 1.7899ns\n",
            "318. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6798_ - Clock skew: 1.7304000000000002ns - Slack: 1.7904ns\n",
            "319. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6550_ - Clock skew: 1.6857999999999997ns - Slack: 1.7911ns\n",
            "320. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6675_ - Clock skew: 1.6826ns - Slack: 1.7917ns\n",
            "321. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6788_ - Clock skew: 1.6714999999999998ns - Slack: 1.7919ns\n",
            "322. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6620_ - Clock skew: 1.7290999999999999ns - Slack: 1.7938ns\n",
            "323. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6478_ - Clock skew: 1.6912ns - Slack: 1.7941ns\n",
            "324. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7000_ - Clock skew: 1.6775999999999998ns - Slack: 1.795ns\n",
            "325. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6622_ - Clock skew: 1.73ns - Slack: 1.7951ns\n",
            "326. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6784_ - Clock skew: 1.6805ns - Slack: 1.7965ns\n",
            "327. Path chip_core/housekeeping/_6902_ to chip_core/housekeeping/_6902_ - Clock skew: 0.5428999999999999ns - Slack: 1.7976ns\n",
            "328. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7077_ - Clock skew: 1.6689ns - Slack: 1.7991ns\n",
            "329. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6800_ - Clock skew: 1.7212000000000003ns - Slack: 1.7992ns\n",
            "330. Path chip_core/housekeeping/_7021_ to chip_core/housekeeping/_7021_ - Clock skew: 0.5406ns - Slack: 1.7997ns\n",
            "331. Path chip_core/housekeeping/_6719_ to chip_core/housekeeping/_6719_ - Clock skew: 0.5438000000000001ns - Slack: 1.7999ns\n",
            "332. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7078_ - Clock skew: 1.6689ns - Slack: 1.8005ns\n",
            "333. Path chip_core/housekeeping/_6524_ to chip_core/housekeeping/_6524_ - Clock skew: 0.5437999999999996ns - Slack: 1.8007ns\n",
            "334. Path chip_core/housekeeping/_6749_ to chip_core/housekeeping/_6749_ - Clock skew: 0.5446ns - Slack: 1.8009ns\n",
            "335. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6875_ - Clock skew: 1.6743ns - Slack: 1.801ns\n",
            "336. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6551_ - Clock skew: 1.6857999999999997ns - Slack: 1.8014ns\n",
            "337. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6619_ - Clock skew: 1.7296999999999998ns - Slack: 1.802ns\n",
            "338. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6795_ - Clock skew: 1.7212000000000003ns - Slack: 1.8026ns\n",
            "339. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6548_ - Clock skew: 1.6859ns - Slack: 1.8046ns\n",
            "340. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6997_ - Clock skew: 1.6447ns - Slack: 1.8048ns\n",
            "341. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6890_ - Clock skew: 1.7076ns - Slack: 1.805ns\n",
            "342. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6673_ - Clock skew: 1.6826ns - Slack: 1.8052ns\n",
            "343. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7081_ - Clock skew: 1.6617999999999997ns - Slack: 1.8057ns\n",
            "344. Path chip_core/housekeeping/_6942_ to chip_core/housekeeping/_6942_ - Clock skew: 0.5402ns - Slack: 1.8068ns\n",
            "345. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6855_ - Clock skew: 1.6973999999999998ns - Slack: 1.8072ns\n",
            "346. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6872_ - Clock skew: 1.6752ns - Slack: 1.8079ns\n",
            "347. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6873_ - Clock skew: 1.7095999999999998ns - Slack: 1.8093ns\n",
            "348. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6889_ - Clock skew: 1.6752ns - Slack: 1.8094ns\n",
            "349. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6671_ - Clock skew: 1.6777ns - Slack: 1.8096ns\n",
            "350. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7128_ - Clock skew: 1.6773999999999998ns - Slack: 1.8097ns\n",
            "351. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7001_ - Clock skew: 1.6304999999999998ns - Slack: 1.8119ns\n",
            "352. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6742_ - Clock skew: 1.7149ns - Slack: 1.8121ns\n",
            "353. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7066_ - Clock skew: 1.6746ns - Slack: 1.8123ns\n",
            "354. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6859_ - Clock skew: 1.7099999999999997ns - Slack: 1.8126ns\n",
            "355. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6746_ - Clock skew: 1.7530000000000001ns - Slack: 1.8129ns\n",
            "356. Path chip_core/housekeeping/_6483_ to chip_core/housekeeping/_6483_ - Clock skew: 0.5438999999999998ns - Slack: 1.8129ns\n",
            "357. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6805_ - Clock skew: 1.6622000000000001ns - Slack: 1.8138ns\n",
            "358. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6853_ - Clock skew: 1.6973ns - Slack: 1.814ns\n",
            "359. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6672_ - Clock skew: 1.6775999999999998ns - Slack: 1.8146ns\n",
            "360. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7082_ - Clock skew: 1.6727ns - Slack: 1.8155ns\n",
            "361. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6741_ - Clock skew: 1.6819ns - Slack: 1.8185ns\n",
            "362. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6935_ - Clock skew: 1.6695ns - Slack: 1.8186ns\n",
            "363. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6857_ - Clock skew: 1.7003000000000001ns - Slack: 1.8191ns\n",
            "364. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6519_ - Clock skew: 1.6912ns - Slack: 1.8191ns\n",
            "365. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6933_ - Clock skew: 1.6695ns - Slack: 1.8198ns\n",
            "366. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6856_ - Clock skew: 1.7106000000000001ns - Slack: 1.8212ns\n",
            "367. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7062_ - Clock skew: 1.6619ns - Slack: 1.8264ns\n",
            "368. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7112_ - Clock skew: 1.6828ns - Slack: 1.8278ns\n",
            "369. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6623_ - Clock skew: 1.7529ns - Slack: 1.8291ns\n",
            "370. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7003_ - Clock skew: 1.6857ns - Slack: 1.8291ns\n",
            "371. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6614_ - Clock skew: 1.7104000000000001ns - Slack: 1.8296ns\n",
            "372. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7110_ - Clock skew: 1.6706999999999999ns - Slack: 1.8296ns\n",
            "373. Path chip_core/housekeeping/_7053_ to chip_core/housekeeping/_7053_ - Clock skew: 0.5406999999999997ns - Slack: 1.8323ns\n",
            "374. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6871_ - Clock skew: 1.7093999999999998ns - Slack: 1.8343ns\n",
            "375. Path chip_core/housekeeping/_6481_ to chip_core/housekeeping/_6481_ - Clock skew: 0.5439000000000003ns - Slack: 1.8348ns\n",
            "376. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6860_ - Clock skew: 1.7105ns - Slack: 1.8355ns\n",
            "377. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6869_ - Clock skew: 1.7097ns - Slack: 1.8365ns\n",
            "378. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6824_ - Clock skew: 1.6985ns - Slack: 1.8371ns\n",
            "379. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7002_ - Clock skew: 1.6590999999999998ns - Slack: 1.8392ns\n",
            "380. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6652_ - Clock skew: 1.6885000000000001ns - Slack: 1.8399ns\n",
            "381. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7080_ - Clock skew: 1.6708999999999998ns - Slack: 1.8406ns\n",
            "382. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7111_ - Clock skew: 1.6439000000000001ns - Slack: 1.8406ns\n",
            "383. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7131_ - Clock skew: 1.7104000000000001ns - Slack: 1.8416ns\n",
            "384. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6724_ - Clock skew: 1.6664ns - Slack: 1.8419ns\n",
            "385. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6745_ - Clock skew: 1.7317ns - Slack: 1.842ns\n",
            "386. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6670_ - Clock skew: 1.6420000000000001ns - Slack: 1.8421ns\n",
            "387. Path chip_core/housekeeping/_6941_ to chip_core/housekeeping/_6941_ - Clock skew: 0.5402ns - Slack: 1.8439ns\n",
            "388. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6650_ - Clock skew: 1.6885000000000001ns - Slack: 1.8448ns\n",
            "389. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7109_ - Clock skew: 1.6369999999999998ns - Slack: 1.8459ns\n",
            "390. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7031_ - Clock skew: 1.6750999999999998ns - Slack: 1.846ns\n",
            "391. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7029_ - Clock skew: 1.6784000000000001ns - Slack: 1.8466ns\n",
            "392. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7067_ - Clock skew: 1.6727999999999998ns - Slack: 1.8469ns\n",
            "393. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7035_ - Clock skew: 1.672ns - Slack: 1.849ns\n",
            "394. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6823_ - Clock skew: 1.6986999999999999ns - Slack: 1.8501ns\n",
            "395. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7064_ - Clock skew: 1.6710999999999998ns - Slack: 1.8507ns\n",
            "396. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6940_ - Clock skew: 1.6792ns - Slack: 1.851ns\n",
            "397. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6969_ - Clock skew: 1.6826999999999999ns - Slack: 1.8514ns\n",
            "398. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6668_ - Clock skew: 1.6422ns - Slack: 1.8515ns\n",
            "399. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6743_ - Clock skew: 1.7313999999999998ns - Slack: 1.8523ns\n",
            "400. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6669_ - Clock skew: 1.6418000000000001ns - Slack: 1.8535ns\n",
            "401. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7083_ - Clock skew: 1.6918ns - Slack: 1.854ns\n",
            "402. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6826_ - Clock skew: 1.6986999999999999ns - Slack: 1.8542ns\n",
            "403. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6500_ - Clock skew: 1.6420000000000001ns - Slack: 1.8549ns\n",
            "404. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7115_ - Clock skew: 1.6855999999999998ns - Slack: 1.8559ns\n",
            "405. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6998_ - Clock skew: 1.6432999999999998ns - Slack: 1.8566ns\n",
            "406. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6495_ - Clock skew: 1.68ns - Slack: 1.8578ns\n",
            "407. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6609_ - Clock skew: 1.6889ns - Slack: 1.8586ns\n",
            "408. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7113_ - Clock skew: 1.6445999999999998ns - Slack: 1.8587ns\n",
            "409. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6499_ - Clock skew: 1.6422999999999999ns - Slack: 1.8597ns\n",
            "410. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6527_ - Clock skew: 1.6821ns - Slack: 1.86ns\n",
            "411. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7065_ - Clock skew: 1.6445999999999998ns - Slack: 1.8611ns\n",
            "412. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6526_ - Clock skew: 1.6820000000000002ns - Slack: 1.8617ns\n",
            "413. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7013_ - Clock skew: 1.6883000000000001ns - Slack: 1.8621ns\n",
            "414. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6723_ - Clock skew: 1.6664ns - Slack: 1.8622ns\n",
            "415. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6726_ - Clock skew: 1.6786999999999999ns - Slack: 1.8644ns\n",
            "416. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6612_ - Clock skew: 1.6895999999999998ns - Slack: 1.8651ns\n",
            "417. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6967_ - Clock skew: 1.6682ns - Slack: 1.8653ns\n",
            "418. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6725_ - Clock skew: 1.6664ns - Slack: 1.8657ns\n",
            "419. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6645_ - Clock skew: 1.6988ns - Slack: 1.8669ns\n",
            "420. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7125_ - Clock skew: 1.6422999999999999ns - Slack: 1.8679ns\n",
            "421. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6525_ - Clock skew: 1.6664ns - Slack: 1.8688ns\n",
            "422. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6841_ - Clock skew: 1.6752999999999998ns - Slack: 1.8691ns\n",
            "423. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6910_ - Clock skew: 1.731ns - Slack: 1.8694ns\n",
            "424. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6721_ - Clock skew: 1.6805ns - Slack: 1.8722ns\n",
            "425. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6874_ - Clock skew: 1.6743ns - Slack: 1.873ns\n",
            "426. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6646_ - Clock skew: 1.7057999999999998ns - Slack: 1.8731ns\n",
            "427. Path chip_core/housekeeping/_6954_ to chip_core/housekeeping/_6954_ - Clock skew: 0.5434000000000001ns - Slack: 1.874ns\n",
            "428. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6648_ - Clock skew: 1.7057999999999998ns - Slack: 1.874ns\n",
            "429. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7030_ - Clock skew: 1.6695ns - Slack: 1.8746ns\n",
            "430. Path chip_core/housekeeping/_6485_ to chip_core/housekeeping/_6485_ - Clock skew: 0.544ns - Slack: 1.8772ns\n",
            "431. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7004_ - Clock skew: 1.6855999999999998ns - Slack: 1.8779ns\n",
            "432. Path chip_core/housekeeping/_6486_ to chip_core/housekeeping/_6486_ - Clock skew: 0.5438999999999998ns - Slack: 1.8784ns\n",
            "433. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7017_ - Clock skew: 1.7004ns - Slack: 1.8807ns\n",
            "434. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6854_ - Clock skew: 1.6729ns - Slack: 1.8809ns\n",
            "435. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6647_ - Clock skew: 1.6918999999999997ns - Slack: 1.8825ns\n",
            "436. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6718_ - Clock skew: 1.6804ns - Slack: 1.8838ns\n",
            "437. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6717_ - Clock skew: 1.6794999999999998ns - Slack: 1.8842ns\n",
            "438. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6921_ - Clock skew: 1.6973ns - Slack: 1.8855ns\n",
            "439. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7127_ - Clock skew: 1.6439000000000001ns - Slack: 1.8863ns\n",
            "440. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7063_ - Clock skew: 1.7095ns - Slack: 1.8871ns\n",
            "441. Path chip_core/housekeeping/_6771_ to chip_core/housekeeping/_6771_ - Clock skew: 0.5446ns - Slack: 1.8874ns\n",
            "442. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6696_ - Clock skew: 1.7312ns - Slack: 1.8877ns\n",
            "443. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7032_ - Clock skew: 1.6775ns - Slack: 1.8885ns\n",
            "444. Path chip_core/housekeeping/_7054_ to chip_core/housekeeping/_7054_ - Clock skew: 0.5411000000000001ns - Slack: 1.8897ns\n",
            "445. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7130_ - Clock skew: 1.6746ns - Slack: 1.8901ns\n",
            "446. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6692_ - Clock skew: 1.7377ns - Slack: 1.8902ns\n",
            "447. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6644_ - Clock skew: 1.684ns - Slack: 1.8906ns\n",
            "448. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6825_ - Clock skew: 1.6420000000000001ns - Slack: 1.8915ns\n",
            "449. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7034_ - Clock skew: 1.6853999999999998ns - Slack: 1.8922ns\n",
            "450. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6590_ - Clock skew: 1.6862000000000001ns - Slack: 1.8935ns\n",
            "451. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7068_ - Clock skew: 1.6811ns - Slack: 1.8963ns\n",
            "452. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6529_ - Clock skew: 1.6819ns - Slack: 1.8972ns\n",
            "453. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6905_ - Clock skew: 1.7005000000000001ns - Slack: 1.8976ns\n",
            "454. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6528_ - Clock skew: 1.6657ns - Slack: 1.898ns\n",
            "455. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6912_ - Clock skew: 1.7184000000000001ns - Slack: 1.8997ns\n",
            "456. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6827_ - Clock skew: 1.6215ns - Slack: 1.8998ns\n",
            "457. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6593_ - Clock skew: 1.6733ns - Slack: 1.902ns\n",
            "458. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6653_ - Clock skew: 1.7123000000000002ns - Slack: 1.9021ns\n",
            "459. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7027_ - Clock skew: 1.7121000000000002ns - Slack: 1.9025ns\n",
            "460. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6606_ - Clock skew: 1.6853ns - Slack: 1.9031ns\n",
            "461. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6589_ - Clock skew: 1.6733999999999998ns - Slack: 1.9033ns\n",
            "462. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6903_ - Clock skew: 1.7095ns - Slack: 1.9057ns\n",
            "463. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6909_ - Clock skew: 1.7009999999999998ns - Slack: 1.9063ns\n",
            "464. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6613_ - Clock skew: 1.7125000000000001ns - Slack: 1.9065ns\n",
            "465. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6750_ - Clock skew: 1.7306000000000001ns - Slack: 1.9069ns\n",
            "466. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6592_ - Clock skew: 1.6735ns - Slack: 1.9071ns\n",
            "467. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7019_ - Clock skew: 1.7103ns - Slack: 1.9075ns\n",
            "468. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6979_ - Clock skew: 1.7469ns - Slack: 1.9077ns\n",
            "469. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6974_ - Clock skew: 1.7239000000000002ns - Slack: 1.9078ns\n",
            "470. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6608_ - Clock skew: 1.6853ns - Slack: 1.9091ns\n",
            "471. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6980_ - Clock skew: 1.7466000000000002ns - Slack: 1.91ns\n",
            "472. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6938_ - Clock skew: 1.6874999999999998ns - Slack: 1.9101ns\n",
            "473. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6828_ - Clock skew: 1.6215ns - Slack: 1.9101ns\n",
            "474. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6720_ - Clock skew: 1.6803000000000001ns - Slack: 1.9108ns\n",
            "475. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6748_ - Clock skew: 1.7254000000000003ns - Slack: 1.9114ns\n",
            "476. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7129_ - Clock skew: 1.6329ns - Slack: 1.9115ns\n",
            "477. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6897_ - Clock skew: 1.7126ns - Slack: 1.9129ns\n",
            "478. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7014_ - Clock skew: 1.6823ns - Slack: 1.9129ns\n",
            "479. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6911_ - Clock skew: 1.7074ns - Slack: 1.9132ns\n",
            "480. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7022_ - Clock skew: 1.7099ns - Slack: 1.9149ns\n",
            "481. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6917_ - Clock skew: 1.6969999999999998ns - Slack: 1.9164ns\n",
            "482. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6922_ - Clock skew: 1.6617999999999997ns - Slack: 1.9166ns\n",
            "483. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6901_ - Clock skew: 1.7005000000000001ns - Slack: 1.9169ns\n",
            "484. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6925_ - Clock skew: 1.7329ns - Slack: 1.9169ns\n",
            "485. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6858_ - Clock skew: 1.6874999999999998ns - Slack: 1.9169ns\n",
            "486. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6913_ - Clock skew: 1.7074ns - Slack: 1.917ns\n",
            "487. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6747_ - Clock skew: 1.7251999999999998ns - Slack: 1.9186ns\n",
            "488. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6552_ - Clock skew: 1.6859999999999997ns - Slack: 1.9194ns\n",
            "489. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6999_ - Clock skew: 1.6828999999999998ns - Slack: 1.9203ns\n",
            "490. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6615_ - Clock skew: 1.7103ns - Slack: 1.9205ns\n",
            "491. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7016_ - Clock skew: 1.6777ns - Slack: 1.9212ns\n",
            "492. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6939_ - Clock skew: 1.7101ns - Slack: 1.9212ns\n",
            "493. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6893_ - Clock skew: 1.7127999999999999ns - Slack: 1.9213ns\n",
            "494. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7033_ - Clock skew: 1.6371ns - Slack: 1.9218ns\n",
            "495. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6604_ - Clock skew: 1.6853ns - Slack: 1.9228ns\n",
            "496. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6610_ - Clock skew: 1.6908ns - Slack: 1.9244ns\n",
            "497. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6617_ - Clock skew: 1.7101999999999997ns - Slack: 1.9269ns\n",
            "498. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6919_ - Clock skew: 1.7095999999999998ns - Slack: 1.9282ns\n",
            "499. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7026_ - Clock skew: 1.7077000000000002ns - Slack: 1.929ns\n",
            "500. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6595_ - Clock skew: 1.6744ns - Slack: 1.9327ns\n",
            "501. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7018_ - Clock skew: 1.6773999999999998ns - Slack: 1.933ns\n",
            "502. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6695_ - Clock skew: 1.7232ns - Slack: 1.9334ns\n",
            "503. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6693_ - Clock skew: 1.7377ns - Slack: 1.9342ns\n",
            "504. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7132_ - Clock skew: 1.6811ns - Slack: 1.935ns\n",
            "505. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6993_ - Clock skew: 1.7485000000000002ns - Slack: 1.9372ns\n",
            "506. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6990_ - Clock skew: 1.7469ns - Slack: 1.9374ns\n",
            "507. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6575_ - Clock skew: 1.7302000000000002ns - Slack: 1.9384ns\n",
            "508. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6596_ - Clock skew: 1.684ns - Slack: 1.943ns\n",
            "509. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6649_ - Clock skew: 1.6912ns - Slack: 1.9434ns\n",
            "510. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6996_ - Clock skew: 1.7268999999999999ns - Slack: 1.9435ns\n",
            "511. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6577_ - Clock skew: 1.7303ns - Slack: 1.945ns\n",
            "512. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6578_ - Clock skew: 1.7301ns - Slack: 1.9458ns\n",
            "513. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7079_ - Clock skew: 1.6832999999999998ns - Slack: 1.9466ns\n",
            "514. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6618_ - Clock skew: 1.7103ns - Slack: 1.9466ns\n",
            "515. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6598_ - Clock skew: 1.6794999999999998ns - Slack: 1.9476ns\n",
            "516. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7025_ - Clock skew: 1.672ns - Slack: 1.9477ns\n",
            "517. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6926_ - Clock skew: 1.7074ns - Slack: 1.9484ns\n",
            "518. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7005_ - Clock skew: 1.7174000000000003ns - Slack: 1.9485ns\n",
            "519. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6751_ - Clock skew: 1.7196ns - Slack: 1.9492ns\n",
            "520. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6923_ - Clock skew: 1.6876999999999998ns - Slack: 1.9496ns\n",
            "521. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6920_ - Clock skew: 1.6866999999999999ns - Slack: 1.9496ns\n",
            "522. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7015_ - Clock skew: 1.6438ns - Slack: 1.9505ns\n",
            "523. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6900_ - Clock skew: 1.6794ns - Slack: 1.9505ns\n",
            "524. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7114_ - Clock skew: 1.6853999999999998ns - Slack: 1.9518ns\n",
            "525. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6894_ - Clock skew: 1.6682ns - Slack: 1.9526ns\n",
            "526. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6713_ - Clock skew: 1.6350999999999998ns - Slack: 1.9527ns\n",
            "527. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6602_ - Clock skew: 1.6786999999999999ns - Slack: 1.9539ns\n",
            "528. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6722_ - Clock skew: 1.6786999999999999ns - Slack: 1.9562ns\n",
            "529. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6594_ - Clock skew: 1.6744ns - Slack: 1.9565ns\n",
            "530. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6634_ - Clock skew: 1.7201999999999997ns - Slack: 1.9574ns\n",
            "531. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7060_ - Clock skew: 1.7139ns - Slack: 1.9598ns\n",
            "532. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6479_ - Clock skew: 1.7218000000000002ns - Slack: 1.9604ns\n",
            "533. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7020_ - Clock skew: 1.7076ns - Slack: 1.9606ns\n",
            "534. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6898_ - Clock skew: 1.687ns - Slack: 1.962ns\n",
            "535. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7069_ - Clock skew: 1.7145ns - Slack: 1.9645ns\n",
            "536. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6907_ - Clock skew: 1.6752ns - Slack: 1.9645ns\n",
            "537. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6687_ - Clock skew: 1.6691999999999998ns - Slack: 1.965ns\n",
            "538. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6601_ - Clock skew: 1.6691999999999998ns - Slack: 1.9666ns\n",
            "539. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6600_ - Clock skew: 1.6784000000000001ns - Slack: 1.9669ns\n",
            "540. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6690_ - Clock skew: 1.6664ns - Slack: 1.967ns\n",
            "541. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6689_ - Clock skew: 1.6691999999999998ns - Slack: 1.9674ns\n",
            "542. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6480_ - Clock skew: 1.7218000000000002ns - Slack: 1.9678ns\n",
            "543. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6930_ - Clock skew: 1.7305ns - Slack: 1.968ns\n",
            "544. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6899_ - Clock skew: 1.6876999999999998ns - Slack: 1.9689ns\n",
            "545. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7092_ - Clock skew: 1.7466000000000002ns - Slack: 1.9694ns\n",
            "546. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6924_ - Clock skew: 1.6912999999999998ns - Slack: 1.9703ns\n",
            "547. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6482_ - Clock skew: 1.7219ns - Slack: 1.9705ns\n",
            "548. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6688_ - Clock skew: 1.6691999999999998ns - Slack: 1.9709ns\n",
            "549. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6599_ - Clock skew: 1.6786999999999999ns - Slack: 1.971ns\n",
            "550. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6597_ - Clock skew: 1.6744ns - Slack: 1.9721ns\n",
            "551. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7074_ - Clock skew: 1.7139ns - Slack: 1.9731ns\n",
            "552. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6570_ - Clock skew: 1.6354999999999997ns - Slack: 1.9738ns\n",
            "553. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6729_ - Clock skew: 1.7019ns - Slack: 1.9743ns\n",
            "554. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7024_ - Clock skew: 1.6831000000000003ns - Slack: 1.975ns\n",
            "555. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6816_ - Clock skew: 1.6529999999999998ns - Slack: 1.976ns\n",
            "556. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6574_ - Clock skew: 1.7303ns - Slack: 1.9766ns\n",
            "557. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_7036_ - Clock skew: 1.6777999999999997ns - Slack: 1.9772ns\n",
            "558. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6569_ - Clock skew: 1.6356ns - Slack: 1.9773ns\n",
            "559. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6989_ - Clock skew: 1.7009999999999998ns - Slack: 1.9777ns\n",
            "560. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6976_ - Clock skew: 1.7258000000000002ns - Slack: 1.9793ns\n",
            "561. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7070_ - Clock skew: 1.7083000000000002ns - Slack: 1.9808ns\n",
            "562. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7071_ - Clock skew: 1.7145ns - Slack: 1.981ns\n",
            "563. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6992_ - Clock skew: 1.7144000000000001ns - Slack: 1.9836ns\n",
            "564. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6716_ - Clock skew: 1.6352999999999998ns - Slack: 1.9846ns\n",
            "565. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7028_ - Clock skew: 1.7101ns - Slack: 1.9867ns\n",
            "566. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6605_ - Clock skew: 1.7103ns - Slack: 1.9871ns\n",
            "567. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6769_ - Clock skew: 1.7303ns - Slack: 1.9874ns\n",
            "568. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6712_ - Clock skew: 1.6127999999999998ns - Slack: 1.9898ns\n",
            "569. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6906_ - Clock skew: 1.6752ns - Slack: 1.9902ns\n",
            "570. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6904_ - Clock skew: 1.6876999999999998ns - Slack: 1.9903ns\n",
            "571. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7023_ - Clock skew: 1.6814000000000002ns - Slack: 1.9927ns\n",
            "572. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7056_ - Clock skew: 1.7221ns - Slack: 1.9928ns\n",
            "573. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7006_ - Clock skew: 1.7087ns - Slack: 1.9928ns\n",
            "574. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6773_ - Clock skew: 1.7306000000000001ns - Slack: 1.9934ns\n",
            "575. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6936_ - Clock skew: 1.6912999999999998ns - Slack: 1.9941ns\n",
            "576. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6714_ - Clock skew: 1.6127999999999998ns - Slack: 1.9944ns\n",
            "577. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6960_ - Clock skew: 1.7169999999999999ns - Slack: 1.995ns\n",
            "578. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7087_ - Clock skew: 1.724ns - Slack: 1.9951ns\n",
            "579. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6638_ - Clock skew: 1.7391999999999999ns - Slack: 1.9953ns\n",
            "580. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7072_ - Clock skew: 1.7077000000000002ns - Slack: 1.9967ns\n",
            "581. Path chip_core/housekeeping/_7121_ to chip_core/housekeeping/_7121_ - Clock skew: 0.5404999999999998ns - Slack: 1.9977ns\n",
            "582. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6929_ - Clock skew: 1.7512ns - Slack: 1.9981ns\n",
            "583. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6637_ - Clock skew: 1.7323999999999997ns - Slack: 1.9984ns\n",
            "584. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6975_ - Clock skew: 1.7512ns - Slack: 1.9984ns\n",
            "585. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6963_ - Clock skew: 1.7135ns - Slack: 1.9985ns\n",
            "586. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6927_ - Clock skew: 1.7512ns - Slack: 1.9993ns\n",
            "587. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6607_ - Clock skew: 1.6853ns - Slack: 2.0012ns\n",
            "588. Path chip_core/housekeeping/_6862_ to chip_core/housekeeping/_6862_ - Clock skew: 0.544ns - Slack: 2.0015ns\n",
            "589. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7085_ - Clock skew: 1.7012000000000003ns - Slack: 2.0088ns\n",
            "590. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6865_ - Clock skew: 1.7275000000000003ns - Slack: 2.0094ns\n",
            "591. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7012_ - Clock skew: 1.7496000000000003ns - Slack: 2.0102ns\n",
            "592. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7011_ - Clock skew: 1.7009999999999998ns - Slack: 2.0114ns\n",
            "593. Path chip_core/housekeeping/_6465_ to chip_core/housekeeping/_6635_ - Clock skew: 1.7391999999999999ns - Slack: 2.0119ns\n",
            "594. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6977_ - Clock skew: 1.7519000000000002ns - Slack: 2.0129ns\n",
            "595. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6770_ - Clock skew: 1.7301ns - Slack: 2.0143ns\n",
            "596. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7088_ - Clock skew: 1.7222000000000002ns - Slack: 2.015ns\n",
            "597. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6864_ - Clock skew: 1.7464000000000002ns - Slack: 2.0152ns\n",
            "598. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6772_ - Clock skew: 1.7212000000000003ns - Slack: 2.0161ns\n",
            "599. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7057_ - Clock skew: 1.6838ns - Slack: 2.0187ns\n",
            "600. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6868_ - Clock skew: 1.7468000000000001ns - Slack: 2.0198ns\n",
            "601. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6958_ - Clock skew: 1.7099ns - Slack: 2.0198ns\n",
            "602. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7055_ - Clock skew: 1.6831000000000003ns - Slack: 2.0208ns\n",
            "603. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7117_ - Clock skew: 1.6746999999999999ns - Slack: 2.021ns\n",
            "604. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7009_ - Clock skew: 1.6831000000000003ns - Slack: 2.0241ns\n",
            "605. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7123_ - Clock skew: 1.7099ns - Slack: 2.0248ns\n",
            "606. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6861_ - Clock skew: 1.7275000000000003ns - Slack: 2.025ns\n",
            "607. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6896_ - Clock skew: 1.687ns - Slack: 2.0275ns\n",
            "608. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6932_ - Clock skew: 1.7469ns - Slack: 2.0279ns\n",
            "609. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6866_ - Clock skew: 1.7266000000000001ns - Slack: 2.0285ns\n",
            "610. Path chip_core/housekeeping/_7049_ to chip_core/housekeeping/_7049_ - Clock skew: 0.5411999999999999ns - Slack: 2.031ns\n",
            "611. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6995_ - Clock skew: 1.7493ns - Slack: 2.0329ns\n",
            "612. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7119_ - Clock skew: 1.672ns - Slack: 2.0359ns\n",
            "613. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7122_ - Clock skew: 1.7249999999999999ns - Slack: 2.0364ns\n",
            "614. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6931_ - Clock skew: 1.7500000000000002ns - Slack: 2.0377ns\n",
            "615. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6727_ - Clock skew: 1.7101ns - Slack: 2.0405ns\n",
            "616. Path chip_core/housekeeping/_6603_ to chip_core/housekeeping/_6603_ - Clock skew: 0.5436000000000001ns - Slack: 2.0405ns\n",
            "617. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6959_ - Clock skew: 1.6693ns - Slack: 2.0409ns\n",
            "618. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6991_ - Clock skew: 1.7486ns - Slack: 2.0439ns\n",
            "619. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7059_ - Clock skew: 1.7495ns - Slack: 2.0454ns\n",
            "620. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6731_ - Clock skew: 1.7103ns - Slack: 2.0454ns\n",
            "621. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7124_ - Clock skew: 1.7094000000000003ns - Slack: 2.047ns\n",
            "622. Path chip_core/housekeeping/_6945_ to chip_core/housekeeping/_6945_ - Clock skew: 0.5449999999999999ns - Slack: 2.049ns\n",
            "623. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7118_ - Clock skew: 1.7098000000000002ns - Slack: 2.0507ns\n",
            "624. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7007_ - Clock skew: 1.6719000000000002ns - Slack: 2.0518ns\n",
            "625. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6728_ - Clock skew: 1.7103ns - Slack: 2.0538ns\n",
            "626. Path chip_core/housekeeping/_6863_ to chip_core/housekeeping/_6863_ - Clock skew: 0.5461ns - Slack: 2.0548ns\n",
            "627. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6964_ - Clock skew: 1.7169ns - Slack: 2.0554ns\n",
            "628. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7086_ - Clock skew: 1.7209999999999999ns - Slack: 2.0588ns\n",
            "629. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7058_ - Clock skew: 1.7137ns - Slack: 2.0608ns\n",
            "630. Path chip_core/housekeeping/_6730_ to chip_core/housekeeping/_6730_ - Clock skew: 0.5453000000000001ns - Slack: 2.0618ns\n",
            "631. Path chip_core/housekeeping/_7047_ to chip_core/housekeeping/_7047_ - Clock skew: 0.5406999999999997ns - Slack: 2.0642ns\n",
            "632. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7008_ - Clock skew: 1.6826ns - Slack: 2.0733ns\n",
            "633. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6908_ - Clock skew: 1.6752ns - Slack: 2.0742ns\n",
            "634. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7089_ - Clock skew: 1.6826999999999999ns - Slack: 2.0766ns\n",
            "635. Path chip_core/housekeeping/_6657_ to chip_core/housekeeping/_6691_ - Clock skew: 1.6788ns - Slack: 2.0779ns\n",
            "636. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6916_ - Clock skew: 1.7468000000000001ns - Slack: 2.0783ns\n",
            "637. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6994_ - Clock skew: 1.7186000000000001ns - Slack: 2.083ns\n",
            "638. Path chip_core/housekeeping/_6513_ to chip_core/housekeeping/_6497_ - Clock skew: 0.5396000000000001ns - Slack: 2.0913ns\n",
            "639. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6962_ - Clock skew: 1.7171ns - Slack: 2.109ns\n",
            "640. Path chip_core/housekeeping/_7046_ to chip_core/housekeeping/_7046_ - Clock skew: 0.5432000000000001ns - Slack: 2.1222ns\n",
            "641. Path chip_core/housekeeping/_6946_ to chip_core/housekeeping/_6946_ - Clock skew: 0.5425ns - Slack: 2.1304ns\n",
            "642. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6928_ - Clock skew: 1.7305ns - Slack: 2.1317ns\n",
            "643. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6867_ - Clock skew: 1.7500000000000002ns - Slack: 2.1572ns\n",
            "644. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_7048_ - Clock skew: 1.7167000000000001ns - Slack: 2.1596ns\n",
            "645. Path chip_core/housekeeping/_7052_ to chip_core/housekeeping/_7052_ - Clock skew: 0.5425ns - Slack: 2.167ns\n",
            "646. Path chip_core/housekeeping/_6943_ to chip_core/housekeeping/_6943_ - Clock skew: 0.5459ns - Slack: 2.1907ns\n",
            "647. Path chip_core/housekeeping/_6948_ to chip_core/housekeeping/_6948_ - Clock skew: 0.5434000000000001ns - Slack: 2.1969ns\n",
            "648. Path chip_core/housekeeping/_6951_ to chip_core/housekeeping/_6951_ - Clock skew: 0.544ns - Slack: 2.1993ns\n",
            "649. Path chip_core/housekeeping/_6510_ to chip_core/housekeeping/_6494_ - Clock skew: 0.5436000000000001ns - Slack: 2.2008ns\n",
            "650. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6944_ - Clock skew: 1.7190999999999999ns - Slack: 2.2483ns\n",
            "651. Path chip_core/housekeeping/_6463_ to chip_core/housekeeping/_6947_ - Clock skew: 1.7144000000000001ns - Slack: 2.2508ns\n",
            "652. Path chip_core/housekeeping/_6955_ to chip_core/housekeeping/_6955_ - Clock skew: 0.5434000000000001ns - Slack: 2.2983ns\n",
            "653. Path chip_core/housekeeping/_6522_ to chip_core/housekeeping/_6506_ - Clock skew: 0.5439000000000003ns - Slack: 2.315ns\n",
            "654. Path chip_core/housekeeping/_6509_ to chip_core/housekeeping/_6493_ - Clock skew: 0.5438999999999998ns - Slack: 2.3328ns\n",
            "655. Path chip_core/housekeeping/_6956_ to chip_core/housekeeping/_6956_ - Clock skew: 0.5434000000000001ns - Slack: 2.3347ns\n",
            "656. Path chip_core/housekeeping/_6952_ to chip_core/housekeeping/_6952_ - Clock skew: 0.5436000000000001ns - Slack: 2.3537ns\n",
            "657. Path chip_core/housekeeping/_6517_ to chip_core/housekeeping/_6501_ - Clock skew: 0.5445000000000002ns - Slack: 2.4136ns\n",
            "658. Path chip_core/housekeeping/_6518_ to chip_core/housekeeping/_6502_ - Clock skew: 0.5444999999999998ns - Slack: 2.4281ns\n",
            "659. Path chip_core/housekeeping/_6523_ to chip_core/housekeeping/_6507_ - Clock skew: 0.5438000000000001ns - Slack: 2.4298ns\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nbformat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgq5moAs08s8",
        "outputId": "c91521ec-8936-4c8a-c65a-e52e18dad305"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.27.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.15.0)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNYYEC9gOu4YY+4s8w95bUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002e26124ac54442a5d1f99379cf5fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002e895d943f4b84a4c7e9d94cb41932": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "003f34cc29f34a3cac3c1edceb6ba31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8002ccb179ba4bd7a90da6054343326c",
            "placeholder": "​",
            "style": "IPY_MODEL_0768bfe28cb542ba98f9c07e845ea348",
            "value": " 25.1k/? [00:00&lt;00:00, 2.30MB/s]"
          }
        },
        "006983e2283348df8decc3b245098a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_751a1b476d92462ba349eb90ab9c53e5",
            "placeholder": "​",
            "style": "IPY_MODEL_0385d6b82b2b4c1aac4a92b2a8834470",
            "value": "Downloading .gitattributes: "
          }
        },
        "0072536ff3fd4ecda7de0ff71349b8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00b4cf8b2b15482fbd606df261893e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0852d4d1958d473e8c9548ad973d0be5",
            "max": 23046789,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58cc52cf551541d1a88614b48432ae8c",
            "value": 23046789
          }
        },
        "00e57cda7d954cba9013ecb19821f991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e869838c304085a4623f3f741b0f09",
            "placeholder": "​",
            "style": "IPY_MODEL_76472b9a721140368a530273bf6c0dc9",
            "value": "Downloading data_config.json: "
          }
        },
        "00e5fdeec82b4b99963329f0899ae511": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0116f19ff33f43a28b1a52556fcc0574": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a300e51e94b4190a944854cc3fe0dde",
            "max": 90265744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3df110d821d245a4b8674cf7fbebb310",
            "value": 90265744
          }
        },
        "01466d495dfd444d9706a86429cb8b45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d5853bde6343579d878baed31869c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9da3a46b747406a9e91f127048b5f7f",
              "IPY_MODEL_8f766e1c1b9f4c558bb3320f4401ce35",
              "IPY_MODEL_1a728dc0f25c4511a2afeff1cd46b580"
            ],
            "layout": "IPY_MODEL_d1203b7cf74a4fc7a06be100424cc85e"
          }
        },
        "0264a2477a844750b3e24a4079046840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0289266acd9644c5b372443d25685121": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029a42a215fe405796154508c1e59dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_617ec32f75eb48cbbd3abf21bca37364",
            "placeholder": "​",
            "style": "IPY_MODEL_3340fc0094214e7d873e51746b35eff4",
            "value": "Downloading model_O1.onnx: 100%"
          }
        },
        "02d83a14e1974a02933b6fb84b8fee10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02fa33e476d84680acdbd932b4332aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "030d91d7bfbb471e9247d3c4d63516c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a3f4e3c75674e8c844ad84638752cd9",
              "IPY_MODEL_ee2936eb2c494bc1843aaeca475d4fef",
              "IPY_MODEL_6a68408321e04315a3693f3849563fad"
            ],
            "layout": "IPY_MODEL_5f8ef43fc4484ec1b7e76e3ad838344f"
          }
        },
        "032e3682bfe9460d86e7cf6809529176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0350a9ed8f5944d1bc1a83288d2ecaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0385d6b82b2b4c1aac4a92b2a8834470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03a251947a3f4262b8df2d00e4a9bb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03c39b0bc0f844f9af35ae8fb9711483": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03e347bcf70e45c3adf783ffd241684f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d0d1ba150d941e39407ec3c40fb8947",
              "IPY_MODEL_723a7558456f44fdb00ea74d265567d3",
              "IPY_MODEL_e528d567434e4b3e91b31419d26bcee7"
            ],
            "layout": "IPY_MODEL_abd76b7b03584a628469aaa052e93adf"
          }
        },
        "03efaf509a814ea6b634676272a4fddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9549580fc33f4444b07c708ce8821625",
            "placeholder": "​",
            "style": "IPY_MODEL_224dff89a22745dcbcaecadddd2a4347",
            "value": "Downloading model_O3.onnx: 100%"
          }
        },
        "03fd23b543574db59244e3e01d5dfb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "041255dc0b4e4ea78f937dbab0f0072c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7abb3c1c74ef4f0eb9447fcca47d5078",
              "IPY_MODEL_510ef88b22de435e8c85d902994b8ae2",
              "IPY_MODEL_2e03480b9b2841dd9aa1c2c747a10f00"
            ],
            "layout": "IPY_MODEL_f80638e09b3a4e41b1c5bf558c6b84be"
          }
        },
        "0425a8a6bcb547529502608c95c27060": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0473f6921b124d278367031b4e6cccc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d08c4ab70a94ddeaad6e541ea07d696",
              "IPY_MODEL_1eca1f63b6774c709dcb9c086753100a",
              "IPY_MODEL_2d26e686c23443c7902d933724cbd1fd"
            ],
            "layout": "IPY_MODEL_4b663baf84c7423c8fa80355c7a432d3"
          }
        },
        "047b47e9c6b442ec821b6efbacc2b4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0484abe01641433a9a37feaf38411d06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04900d40e885491e8e3444a1df83b71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04d0669fc63644029b19f42796773a58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "052b04b5535a4115aaf828ffdf048080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f27ad9ae80b6471383524788bf0e8eef",
            "placeholder": "​",
            "style": "IPY_MODEL_2e47d74ea4bc429984e78c3f25b975c4",
            "value": "Downloading (…)ce_transformers.json: 100%"
          }
        },
        "05629090422f41d0a5dd075dec2e6215": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "05b1d21677de42548ad430d2e5e956ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05d0627afc6c418fb2394e9a1b6955ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d83b5420acb84b3388abd7a825582ea2",
            "max": 500058,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d66ea4558a848abac380f878f9f166d",
            "value": 500058
          }
        },
        "05edf76d9a424e0f9d6abcc368dae91f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0604455104ba4e97a816f0c2f0324229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "061698bfe5c143399227c68e1ea78bad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063dd3c9b7154c2b86095266a52c94ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06471650c03440e7bb8701cde0971a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b10637086547ef8df4a085e227c004",
            "placeholder": "​",
            "style": "IPY_MODEL_03fd23b543574db59244e3e01d5dfb30",
            "value": " 116/116 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "066e6598660645378c3939d3d2841f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "069c3f345da6404b9b89a58c7ebef338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48bd0028bff84db6997ba523ea31f98f",
            "max": 23046789,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d22f23e2f874440ebd266a28202a945a",
            "value": 23046789
          }
        },
        "06a89b3989094cc492caeddbcd8d6bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06b75cd6798543f9b9ae91fa881c6111": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c467a050af439eb75c22dfd050fcd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d930e8a1a54df4b826ce1826dfde28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06ef8a823951486fbfab571c64ad8a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0768bfe28cb542ba98f9c07e845ea348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07da8bb58adf4b45bb8272fa49ac5fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07dfea43f10145e0b44cc0dd9c8cb422": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0852d4d1958d473e8c9548ad973d0be5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b3aabd306443208f392f34142f5100": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08d01c0af065491784c56692df28636c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ec5ea1fa0d414ab4ac46ac5d5a5de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89bb26f685044d6ba6ab09369c2d915a",
            "placeholder": "​",
            "style": "IPY_MODEL_c8a97cf4fd0949f0bdc8c5f99bc1a814",
            "value": " 112/112 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "0912053bf7154e6f96b6e65aca1a1f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "096af96cd077434f989f069152e41f64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d4b368f26845f28772f0c1407f4f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_259642531cb94b51872b17364ecba85a",
              "IPY_MODEL_b546d194321743b9b118833a9f2e3f25",
              "IPY_MODEL_f505098deaf5434dba68eaa808166c61"
            ],
            "layout": "IPY_MODEL_f37d63649186471986697434d2d3472b"
          }
        },
        "0a291b8e2e1245119542d93090b0023b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a30e530d8d04ff592d4d6aa63d69ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07dfea43f10145e0b44cc0dd9c8cb422",
            "placeholder": "​",
            "style": "IPY_MODEL_d5888a15e0a549c39235a4a271ecfaf9",
            "value": " 612/612 [00:00&lt;00:00, 75.0kB/s]"
          }
        },
        "0a6f1cbcb4ff41908ee1b9558e5fabe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0aa66b87e90d44369075f3016ced2301": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aeb175563f14d4a8dbcefa61ca9f907": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9924518b6c643408a9159985440101e",
            "placeholder": "​",
            "style": "IPY_MODEL_04900d40e885491e8e3444a1df83b71f",
            "value": "Downloading model_O1.onnx: 100%"
          }
        },
        "0b69456c949446008576495a6e5a50ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b9bb890b3d741369b4ca6890c289a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bba852c316b48e4b754f115badf88f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bc24b20a2264709967772a4d5ce0690": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c0fc3712d7b48848253cb48d48c87f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca4fbed1bec44b4991401cb94be3ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dd03a7932e84f1eaf45c9e95d77bc51",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2606f97087240dab23f994a553daafc",
            "value": 2
          }
        },
        "0cd01c76aeef4e2b9b9a201eadac2f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0d1ba150d941e39407ec3c40fb8947": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f64032a2af4837b7f1b1aca98ab3c8",
            "placeholder": "​",
            "style": "IPY_MODEL_ad7aa71e881b4cd8bc07301ead088a35",
            "value": "Downloading .gitattributes: "
          }
        },
        "0d25b83472a848e0904a1797698a0b1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d452a26332f41a7b66b82d3c85c0821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d66ea4558a848abac380f878f9f166d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d744344f71f4cb6868bf77a6d68d546": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89443b41d5db4be18d9e8850c65ba8ac",
            "placeholder": "​",
            "style": "IPY_MODEL_53bd848993b84529862f194e2dc8a3f3",
            "value": " 90.4M/90.4M [00:00&lt;00:00, 298MB/s]"
          }
        },
        "0da947241d4b48e9b87d7bc6bf1d6451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5500a073bdd64810b725ae1ea420bde3",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67b40389042849758ce4451d1d54e9d6",
            "value": 349
          }
        },
        "0e562cea7c6f418f8516de67232492c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dac9a6d8f43643a9a57ae0408f9a9b24",
              "IPY_MODEL_a1d8ff2b389b4a1f81625b679d4a6b4d",
              "IPY_MODEL_9b4bb652ce13426184eb69a00f4e8787"
            ],
            "layout": "IPY_MODEL_7cd89697a0234c4cbe1119b78a827517"
          }
        },
        "0e6d461c66a54869915bd23e6910ab4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e79192245444dcbafa8eef76329613d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e94ce04526c4da38051b66bee51634c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e9f9f10a8f74d7a8189db04779f3252": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ec4879f78ad4030ad355052698133db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee279a8b0ff469da74a9f3ab3f51a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f1caa4f54f44f40b4b3033718629a05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f78ca3482264d97a075e7273f908242": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa3a7b26bc342a78dc1c6a211a98f25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1038f092afe74b6caee07ff39dda54ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1b969e780c47d2b263aec4479da1a9",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_359f0f86786d4c66961924a25772a28e",
            "value": 112
          }
        },
        "104b02932c134da783c82aff99b9b908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10964dce0fc141f1b27b582fdab2c9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111448fcca994e6c965e79de5c86f191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "113f01d7ad9a4ff79aeec8bbf68176d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1175e59d19cc42ab84f1f649d5b407e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00e57cda7d954cba9013ecb19821f991",
              "IPY_MODEL_29e5c4cc583a49fe926a5351431c56d0",
              "IPY_MODEL_6d180428907442e095a1654b7d27b4b0"
            ],
            "layout": "IPY_MODEL_2e8a802dc1ff4440aade769460aed8ca"
          }
        },
        "11bd65590b784e6283d4520b63e2bd30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11c1568b03a74bb88779f2f9a783a5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11c4378530b94cbb9371cc17df5b1249": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_627baeeed64b42c4addb3601d38fece5",
              "IPY_MODEL_8cc30dcb96004b0eb49a7b0eb7254a14",
              "IPY_MODEL_003f34cc29f34a3cac3c1edceb6ba31a"
            ],
            "layout": "IPY_MODEL_1a3bc4e601a6411ab2f7c3988372f935"
          }
        },
        "11f465108f3345a7b9665df5a8665b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1284189b4a724e6792ad0b456d7e4fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a0c8ca12a84e6995c247429d92cfb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12c7ae7fce274d63a2121fbf40685c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12fbaae50e1948f2b3f384498cfa7f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137662b6ab434085936faae1eae803bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6c6d351dfc547fab33a66ba75a5dfd1",
              "IPY_MODEL_2d486a82021c48a6a252a462a769793a",
              "IPY_MODEL_4643035d28d947eea75c869e1a01a0e4"
            ],
            "layout": "IPY_MODEL_47a9340723aa4898b45e4caf5a5dfa2a"
          }
        },
        "14005756676843ac8405d38e078b169f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14051861f2964cac90b6e14652858364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b867043fbae34d4da23ab9c35453b559",
              "IPY_MODEL_d9c8dfec2ce448cabcfff69a393e3b92",
              "IPY_MODEL_1a9653731d094d0e8ebc29f389756dd1"
            ],
            "layout": "IPY_MODEL_b994063c34354e1991314c955c5ea499"
          }
        },
        "14109c03ea904a83abd66208234faecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c20bf4c0d22d4efdb52db1effe57f19f",
              "IPY_MODEL_850d9511decb4716a414782063937d77",
              "IPY_MODEL_f6491464b46f4f9f97b3dd5288854ae6"
            ],
            "layout": "IPY_MODEL_5b736b5404714877bcca15e17a5edeec"
          }
        },
        "1490d6000483413f9660a88a3bb7d6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42868fad64824cd595cc5ee1383e38fd",
            "placeholder": "​",
            "style": "IPY_MODEL_d92bedbe2e4c48f489d4f1e021bd719a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "149e1e8208f1482e9d5acafbe1d37288": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a75f7756544876b26a226ba5022380": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_878c42bfaae64315b1f04b10691073d4",
              "IPY_MODEL_61da6987ccec43938a5fbbb94b2a8ef1",
              "IPY_MODEL_23b33c0769274ba19c26b882366d19b2"
            ],
            "layout": "IPY_MODEL_c6a129e3dfd6454f9cad29dba89ce3e8"
          }
        },
        "1577df45e53e4f9fb55ad515fef3ddd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "168c22fcfcfc4cf984d95263553aa3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1722feda370a4afab8a081786b26a889": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1774b3b2a43a4e70a1472a6f982df625": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "178eea154f394ef992eea375ce053ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179aeeaa25ab4b07848fa99b5634f20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa899a4f5fc947ddbdf94ec1d16dcff2",
            "max": 646,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_605b0f90d6ca4f56967a2f9f628b1502",
            "value": 646
          }
        },
        "17a48ac52f8f4e02b7ea9ba90923f1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b92e71d7053438fa8025d536dcbe9bc",
            "placeholder": "​",
            "style": "IPY_MODEL_9c1d8ea4db6746d49ecbb38289c6926c",
            "value": " 646/646 [00:00&lt;00:00, 63.7kB/s]"
          }
        },
        "17b8e034b05c4d7c8fbb6ab935bbb990": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e66a9ffb7faf4c1a8d8e51b2e73a8b26",
            "placeholder": "​",
            "style": "IPY_MODEL_5e1aa87179a045f39644877ee0d5b8e2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "17db3b8f5db9446684bf2cc5d65f0fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e3167dc0e54b60bf49d8da3a91afbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ec9fba5f5548378f3f7bf1277a970b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18b792e3313744389effe6f0abfb8a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b8f88154a14b8e8e8001fe3861a123": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c3385e47624b65a6ac5b84f9b3b38f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d40c303db54b4581293bcaff35271e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18eb640ba3614cf6b50a64162f984e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a10e9c9989c4299bd6ab8e1ada121f2",
              "IPY_MODEL_26ee7303465b48ab9ed988f7fb9154ea",
              "IPY_MODEL_1d0b1ef3317b4ce6b033f1264ce4eaa9"
            ],
            "layout": "IPY_MODEL_65f1c762bf004a24a5190a8f927a08b9"
          }
        },
        "18ef89f0f21b454fa59eda04def352fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18efd71d5a7d4f4eae357a41cc1b6812": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "192a5bbe114b409f90d957da37eb66ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "195f14728bfe4bde98df406ebd58c2a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "196429f9ea73463cb22321b827fef7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19c13990e4e94a5e811d33d23083bec8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d6845ed2e143c3b66c0706b52d3cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5076ca236d164978a3da150637eba20d",
              "IPY_MODEL_7ab465a6dc3b453c8fe2a6c7a37e16f8",
              "IPY_MODEL_57cc26dc0b884f16af085d88df442984"
            ],
            "layout": "IPY_MODEL_0425a8a6bcb547529502608c95c27060"
          }
        },
        "19e3410076f74098bf8e012eab7b4297": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a10e9c9989c4299bd6ab8e1ada121f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7529a697abaf47a1a051d16fff23c43f",
            "placeholder": "​",
            "style": "IPY_MODEL_f2a5c5dc07474abcbdac1d451f27ef85",
            "value": "Downloading model_O4.onnx: 100%"
          }
        },
        "1a1fd67bad054dbdad82d1a2719dc873": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a687862b7d694b9982b037b377be6a41",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a08543921ba6465b96f5bf2e9c5be06f",
            "value": 116
          }
        },
        "1a3bc4e601a6411ab2f7c3988372f935": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a48c5bc740a4c4bbe795deb33484e37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6e96b498a9469fbfff24aff4be7210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e781ba326a4cc2ac7ab90a760b5781",
            "placeholder": "​",
            "style": "IPY_MODEL_7ff4a524f9394f799877985188686c0d",
            "value": " 45.2M/45.2M [00:00&lt;00:00, 253MB/s]"
          }
        },
        "1a728dc0f25c4511a2afeff1cd46b580": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01466d495dfd444d9706a86429cb8b45",
            "placeholder": "​",
            "style": "IPY_MODEL_2376d77a8e754d188e18421e36c403b2",
            "value": " 612/612 [00:00&lt;00:00, 76.1kB/s]"
          }
        },
        "1a9653731d094d0e8ebc29f389756dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd8545261a93447d855d6c8dde545dad",
            "placeholder": "​",
            "style": "IPY_MODEL_11c1568b03a74bb88779f2f9a783a5bb",
            "value": " 1.59k/? [00:00&lt;00:00, 125kB/s]"
          }
        },
        "1a992e81e2b54a729b637fb68ea26493": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af21745f03048d69505addc2fe343a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb3d29e8735e477b943de9e85de59843",
            "placeholder": "​",
            "style": "IPY_MODEL_b72d45f7bf6a4a27a43982156255c912",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "1b4a92f0da954c00b736be771e93e4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bde08b27f184040b3de094ebb3e7f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c5cf2f8a2e94fafb8a4e06d12187311": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d01c0af065491784c56692df28636c",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f6ef1f7df314bc1b7a5c004b6d9d334",
            "value": 23026053
          }
        },
        "1cc3383096594b54bfa180a8f499b274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cc67fb9698d4082b503b46525650f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421f2f1b64b84aefadbc3c68d072f600",
            "max": 3500425616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37cc571e9e504f059fe50d5c2396a4b2",
            "value": 3500425616
          }
        },
        "1cc95ce9969b4a5b9d26578410342c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb756bfcd778451a885d7decd0712c97",
            "placeholder": "​",
            "style": "IPY_MODEL_c4c0408926174b9ab668e8104dcf2c1b",
            "value": " 9.98G/9.98G [00:57&lt;00:00, 257MB/s]"
          }
        },
        "1cd10969f46b47309a70809d20b9aeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdadd988c345471b9328e946052c7050",
            "placeholder": "​",
            "style": "IPY_MODEL_5078f8e91520424dbc088c9a21281dd3",
            "value": "Downloading (…)_qint8_quantized.bin: 100%"
          }
        },
        "1d002b747ec2483d996597cae36d1133": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d07ccacbe554f88b21a41804c912c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a1143956f74e038fa4998be28a337e",
            "placeholder": "​",
            "style": "IPY_MODEL_91cb931cf6444caea93b732391e470b6",
            "value": "Downloading (…)nce_bert_config.json: 100%"
          }
        },
        "1d0b1ef3317b4ce6b033f1264ce4eaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f69e6f06ff1c4bbcb4909b33b7558a11",
            "placeholder": "​",
            "style": "IPY_MODEL_3304bbfcb2054ea0bee2f98cc4ede818",
            "value": " 45.2M/45.2M [00:00&lt;00:00, 274MB/s]"
          }
        },
        "1d513ed6fc454ad4954314f1ca43541b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0aeb175563f14d4a8dbcefa61ca9f907",
              "IPY_MODEL_4a91c572d4764158a2310617cf754117",
              "IPY_MODEL_291f9367670e4567b770e5274cdd64e6"
            ],
            "layout": "IPY_MODEL_a940e7d641354a1d95547634156ba97a"
          }
        },
        "1d54cd329f85444ea5d07af27e3bdb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc2f962e5ff4cedb2f594221a8a01b3",
            "placeholder": "​",
            "style": "IPY_MODEL_f6550dd8d904418ab042151090738a6c",
            "value": "Downloading data_config.json: "
          }
        },
        "1d82f01287ef407d9e5ffad183dd4c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdb2831ffedb4e10bdedc76e8ba790fd",
              "IPY_MODEL_f93f7ba8f13c45ea86aaaa612af608c7",
              "IPY_MODEL_c389fa85327b46ec90be8e750a9299df"
            ],
            "layout": "IPY_MODEL_b9b6c6422b8d4fe684276a1c795241da"
          }
        },
        "1de6ca23a8e7419e99c8d058e44d6fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0b23b3c21d4950a0e8df9ac6731d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_41d761ed5d454d7ab913df8be5c3c882",
            "value": "Downloading vocab.txt: "
          }
        },
        "1df031ca9457426c947dcd28c64a4632": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dfd570945fc48b8b85d9ca720d5d20e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1e15f984cdd443d8bd7f64e23b7de14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e1c2210876045f9a157535f430e77a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e20b9f3b0584a16a803e9be32fba740": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e52ac27563c40dcb43700d28b14210d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e63608ad9624f8e8fe9a4fc2d519a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce96546c950a491eb8be7c3bf0309f2c",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1150fffe081471783c7e103e1fc2031",
            "value": 411
          }
        },
        "1e69309b0bf14057a8674f92f3257500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57512a7d4ba7491ba869eff58c40fef8",
            "placeholder": "​",
            "style": "IPY_MODEL_6f6805b4575a4c85b43bc8ee093bb64c",
            "value": " 2/2 [01:03&lt;00:00, 29.19s/it]"
          }
        },
        "1e732b94e8354f94b7b9ed5b0e3f5ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9a447b6137474089e934a2fa8b8c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1eca1f63b6774c709dcb9c086753100a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b641a653ff4a05931049e62eac9ff2",
            "max": 90265744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f9f6ed6063242a58cdfff65eda11f4d",
            "value": 90265744
          }
        },
        "1edfac6eec2d4992b90134163f444dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f14d3de34c94d16876a493a7fd4954f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f7e8db5838d4ae3acbdecf6b11b73dc",
            "placeholder": "​",
            "style": "IPY_MODEL_c22c4f099ac74ac69bf008afd04a79fc",
            "value": " 10.5k/? [00:00&lt;00:00, 1.11MB/s]"
          }
        },
        "1f27d1d078bd45418ddc4b2f2061cf6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed4bfa6a255246b295e81d71948603d4",
              "IPY_MODEL_2c21f36468c344bc9ddc091783014c6e",
              "IPY_MODEL_294e2c8f1cdc4c319becefab92110181"
            ],
            "layout": "IPY_MODEL_f8c11d9d21d44ac19dfe03b1752648c1"
          }
        },
        "1f67677176da4de49517f82137f2ca09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ff0d42557a443498f1f65ecfc31697c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20978600309b476ea6b765a4e33799c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_523c8942435f4fd18956b71bf7740a0f",
              "IPY_MODEL_b9801b6340234966a72feb10c92c870d",
              "IPY_MODEL_0a30e530d8d04ff592d4d6aa63d69ab9"
            ],
            "layout": "IPY_MODEL_c514798d2df14f35bb06fe4666152883"
          }
        },
        "20d67a27ae2145b89b311190e25122ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218c14ff046b4f158d95bc74db198b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e1197b4df64475a8d0d40c0943f5430",
              "IPY_MODEL_54ac3a0b746c4e7ca030569ae4e876a9",
              "IPY_MODEL_9e226eeb21d44f6783df0bf237fe2ad0"
            ],
            "layout": "IPY_MODEL_2c00abccd45d448582cf54e121d18468"
          }
        },
        "21a5744f19ec4930ae437cfff54ee607": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d2d52c79ab47deb0feb79c7bbf212b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67556a4e4c6d4d879a826fd7a7ea3776",
            "placeholder": "​",
            "style": "IPY_MODEL_65fc61c20c5649d6ae94f9d0b50fb2fa",
            "value": "Downloading (…)el_qint8_avx512.onnx: 100%"
          }
        },
        "21e0c252a0cd4918a3a24326b9e58418": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2218a1ab3d4746f1aee860dc28736e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7297a2a112c4669a4e6c0b4c09eadd5",
            "max": 45212349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b69456c949446008576495a6e5a50ab",
            "value": 45212349
          }
        },
        "224dff89a22745dcbcaecadddd2a4347": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "224e3ef13e004f20b28e8b8067c97a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d6124651d574631969bfa4ed2475fc4",
              "IPY_MODEL_a41d777292a04015a59ba3688a49ed1c",
              "IPY_MODEL_842f7ad81b4b4d34a468ec2c7bc593af"
            ],
            "layout": "IPY_MODEL_b71eed38b31d42c1b79ff91be5038218"
          }
        },
        "225e96f289754ff4bc6e40b794401060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "226efa4f5e014c73932d30403ddf3280": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22729dea76084b1a8e4081a53f72df91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a1143956f74e038fa4998be28a337e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2302721590ad430db61287b394c99d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f828856d2f184015b2c122a481a3a052",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29ca52c7a48f4616961e4a2c6ce659b9",
            "value": 1
          }
        },
        "2340343870bb4f0da76a76e29b67fbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71bc66c81de34f1f920d1eab33c69f26",
              "IPY_MODEL_9afe8bec4a2348868a64ab35a0406964",
              "IPY_MODEL_70669f0858dc4608a04065ef73929dcd"
            ],
            "layout": "IPY_MODEL_1b4a92f0da954c00b736be771e93e4c1"
          }
        },
        "2376d77a8e754d188e18421e36c403b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23b33c0769274ba19c26b882366d19b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b972f97cb962438fad4e19065ec88b62",
            "placeholder": "​",
            "style": "IPY_MODEL_1d002b747ec2483d996597cae36d1133",
            "value": " 45.2M/45.2M [00:00&lt;00:00, 305MB/s]"
          }
        },
        "23b547017c6342a38c95b2f305521ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d8173c7650442890db6e84c810777d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24daf4fe0ee24a86bcf2bbe0bcd2b11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc458d5904fc419eb7e95c8cee17f455",
            "max": 500058,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd5ef7e1149e4276a5c835bb99f55859",
            "value": 500058
          }
        },
        "2506f7ff62f34694945d0d044033007a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "253d80ccde82413abee06a8b90297089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25513fe619af42ecab8f45badf3050c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25593c1670284e09bc8dad7cc33ed3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259642531cb94b51872b17364ecba85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2aaa5cbcd494af3af90bb4b5c87acac",
            "placeholder": "​",
            "style": "IPY_MODEL_b0b50c76c34b49b48f938fbafe4ae6e2",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "25b37c6a428042e7afc440ef347da339": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "25ef83e4e1674cca8c3ca32753936c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d9b1a309c94ce19378890710ded038",
            "placeholder": "​",
            "style": "IPY_MODEL_279bd9d2a5394730b0ebd3a51d7bf5d4",
            "value": " 612/612 [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "263331e29a024113bb53ffb9d6237368": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26692debeb9c45d3899ab463f3054eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "269a6fb8fefa4520a13d8690d42779e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26adbb7f9f024c7aae2edf69f5d65501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26e318fd50a9459f8c84136659e991b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ee7303465b48ab9ed988f7fb9154ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c403e92163824be797b2f48fef526a56",
            "max": 45212349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_808d5aab68054d74945a08abe54048ca",
            "value": 45212349
          }
        },
        "26f48dc181774720b3bcc7ecaf60a6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "274860a62ea742999b445a24adf37be4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2791beeace374a439ab95451b76a5c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98826e88b1a5420e87db574ee849fa68",
            "placeholder": "​",
            "style": "IPY_MODEL_2b617db277f54bca86220c2e642d12f0",
            "value": " 2/2 [00:54&lt;00:00, 54.12s/it]"
          }
        },
        "279bd9d2a5394730b0ebd3a51d7bf5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27ca669e00cd490d96938b1448013b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27f7a761766a45bf88e5a4b5112fa4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e677ce983d624825907556fec239aeac",
            "placeholder": "​",
            "style": "IPY_MODEL_3c1fb029bb8245cea2f95b9acb34bf88",
            "value": " 646/646 [00:00&lt;00:00, 45.3kB/s]"
          }
        },
        "27fe06d3b83e4652abc4826521150498": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283a54a4e1634b5ead12e07d527bf858": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2869177037834e518078a39793148059": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2888991785d84433950702ad287ee691": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1722feda370a4afab8a081786b26a889",
            "placeholder": "​",
            "style": "IPY_MODEL_d307bfcb2e6e4fce8cbaeaa688c84840",
            "value": "Downloading (…)fetensors.index.json: "
          }
        },
        "28ea88de83bc4973ba23fb0c1c3c3ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "291d9eba2f3b459ca7cf583b91092d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "291f9367670e4567b770e5274cdd64e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11f465108f3345a7b9665df5a8665b3c",
            "placeholder": "​",
            "style": "IPY_MODEL_5d25bb0fe02540aaba0df239b52828a2",
            "value": " 90.4M/90.4M [00:03&lt;00:00, 18.2MB/s]"
          }
        },
        "29350e14c64d41a48d978f7ca7029c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1af21745f03048d69505addc2fe343a7",
              "IPY_MODEL_d355d433873d41c8bf25207f3de2f8fd",
              "IPY_MODEL_501fedf74d1f4f15a028ccdfecb3c195"
            ],
            "layout": "IPY_MODEL_7af50139dee3421b94826d4d9c2a2a03"
          }
        },
        "294e2c8f1cdc4c319becefab92110181": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97b865cd42284ff2a11a93e9ad2acfb3",
            "placeholder": "​",
            "style": "IPY_MODEL_70409302db19422faa5656683cf7a800",
            "value": " 90.3M/90.3M [00:00&lt;00:00, 275MB/s]"
          }
        },
        "2953e4dbffcf4c359a301f0c20b7c9bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2965d4e4269944c081e4612aec0f129f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2997826ac37b4f77b80f20c40f2c7fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ea7dfd8bbd4b4299d0d806c9e1059e",
            "placeholder": "​",
            "style": "IPY_MODEL_95f4b9e67e3c4f7cb65b4497fd328e5e",
            "value": " 2/2 [00:58&lt;00:00, 26.67s/it]"
          }
        },
        "29a527cf27ef483ea81ddf7aee7092a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97eb4648fae04213ab41d97a5fd97d1f",
              "IPY_MODEL_d5f2ac09302a4cf4b9f8c1b8a27ff553",
              "IPY_MODEL_ab00268816b040d5b17b2f7727317f33"
            ],
            "layout": "IPY_MODEL_111448fcca994e6c965e79de5c86f191"
          }
        },
        "29ca52c7a48f4616961e4a2c6ce659b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29e5c4cc583a49fe926a5351431c56d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6beea24e3ec9466b9c4a7a6f3f672900",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a611633fb50d4a5cbc3bed1e2277cbd4",
            "value": 1
          }
        },
        "2a502de44af741df966ae3c4cc7a976d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a5b3c403f344fb1b33609ee093a9963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b8f88154a14b8e8e8001fe3861a123",
            "placeholder": "​",
            "style": "IPY_MODEL_8bb8cb42f69e43d19b7597139e16f945",
            "value": "Downloading shards: 100%"
          }
        },
        "2af06338b725458085a6e077b51f5aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b617db277f54bca86220c2e642d12f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ba57ddb56f04301bfc45b73f70f1335": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5177550e5f944d1a9de83364cba894a0",
            "placeholder": "​",
            "style": "IPY_MODEL_1cc3383096594b54bfa180a8f499b274",
            "value": "Downloading tokenizer.model: 100%"
          }
        },
        "2bfd8a5a43dc449a892717c256c6a688": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e5d127819d41e8919640569b6e65f9",
            "placeholder": "​",
            "style": "IPY_MODEL_f9ff5711fcc147e497231ab3fbaaff05",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 280MB/s]"
          }
        },
        "2c00abccd45d448582cf54e121d18468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c15ee18da4f46129a5831d7780273e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21a5744f19ec4930ae437cfff54ee607",
            "placeholder": "​",
            "style": "IPY_MODEL_3593ecc1b0164833a6ef558459153a3b",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "2c21f36468c344bc9ddc091783014c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c8838ba4f0403ab9955f616961b23c",
            "max": 90265744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_808ee969da34465b8d6107547e4ed7ab",
            "value": 90265744
          }
        },
        "2cab78e64c294f3b99946d9cd380d9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a5b9499eee4e1aaf7619ccc369dfa7",
            "placeholder": "​",
            "style": "IPY_MODEL_53f133fa47c948d1b0741de6db5429c4",
            "value": "Downloading train_script.py: "
          }
        },
        "2cf0cc7e92e04fe49d13d36a323621f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_962d8adef08244d8a7c2f8af9b111c39",
            "placeholder": "​",
            "style": "IPY_MODEL_80860bf6bd6045109e03dbd3e329213a",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "2d26e686c23443c7902d933724cbd1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26cc6e079ee402194a659075b5b44ca",
            "placeholder": "​",
            "style": "IPY_MODEL_68480c61aed4496e8e0e047cae92a41e",
            "value": " 90.3M/90.3M [00:00&lt;00:00, 208MB/s]"
          }
        },
        "2d486a82021c48a6a252a462a769793a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ff2084abbc4cac8344ecc4a1baac68",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65f486ffda8f4f829e2918b125d27f58",
            "value": 1
          }
        },
        "2d504c24293f4db3a239cf6fa4b06d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_365c751ecfb94b67847d1dcc4a3ad582",
            "placeholder": "​",
            "style": "IPY_MODEL_0604455104ba4e97a816f0c2f0324229",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.44kB/s]"
          }
        },
        "2da999512828443b9acd1dcfa4119c84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dc4498e482f4e8fab1f860df6e89bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e03480b9b2841dd9aa1c2c747a10f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62986736155646c98fd12512da90c59e",
            "placeholder": "​",
            "style": "IPY_MODEL_f71de2b3646f430387d83ad4acd926fb",
            "value": " 10.5k/? [00:00&lt;00:00, 952kB/s]"
          }
        },
        "2e0cacb16f694aa19661d93c3c793c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c487976920ca48738e42459703e004b1",
            "placeholder": "​",
            "style": "IPY_MODEL_c23683c2240940928d5eb7f79cd6331e",
            "value": " 3.50G/3.50G [00:22&lt;00:00, 201MB/s]"
          }
        },
        "2e1197b4df64475a8d0d40c0943f5430": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb4b3045806446cd94141b5336d62bda",
            "placeholder": "​",
            "style": "IPY_MODEL_225e96f289754ff4bc6e40b794401060",
            "value": "Downloading (…)ce_transformers.json: 100%"
          }
        },
        "2e22f01099944fa69c1c304051b7d74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64928ad5908466db07d26da10b1eb0b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4440074eaece43c68755c34646df860d",
            "value": 2
          }
        },
        "2e2f278bdb2d49cb9cc7f9d45b8f38c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e306f6e1a4d4564945f276c7a850f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d03ebc36f32540538770715e7edc0828",
            "placeholder": "​",
            "style": "IPY_MODEL_06a89b3989094cc492caeddbcd8d6bf6",
            "value": " 411/411 [00:00&lt;00:00, 26.6kB/s]"
          }
        },
        "2e47d74ea4bc429984e78c3f25b975c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e487339d6be445cb0c698473ced7153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e91a22164c9849fda3a5c801f87ed172",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90c6c4a43903460db8d8309b84945f1a",
            "value": 53
          }
        },
        "2e8a802dc1ff4440aade769460aed8ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec0479b85164b7faee6cf201593ba6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ed2f0de1e644e97bddd2b7db30b18bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_963744ca2e244e6ba4a6f753e6e35848",
            "placeholder": "​",
            "style": "IPY_MODEL_3b44909b5ac1411395bc8d8832af5822",
            "value": "Downloading tokenizer.model: 100%"
          }
        },
        "2ed4500812064ea2b2b15347ce40f8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c330b41a854c4df6a90787e24a2c65bd",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70726e64583e49c9bb03fc2d089cee75",
            "value": 90888945
          }
        },
        "2fa77fbc9ba9417882562ee5941d87f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ff191213a1b490aaaf013ade48a38a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301e9194750b4bd99f25083e87e51da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68167a4f370646adb0a11ecfaf0a5c6a",
            "placeholder": "​",
            "style": "IPY_MODEL_2af06338b725458085a6e077b51f5aee",
            "value": "Downloading config.json: 100%"
          }
        },
        "30220cb4d8a1429e8d92976b825e3d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb69bdf1234648aba639e442b0e97f98",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e2118042c734316877dcc65ab0608cd",
            "value": 1
          }
        },
        "3046ddbe60724c8384c7da1d54134ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308dfd6c4af54bc99dbdf7b21b7b2a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30e781ba326a4cc2ac7ab90a760b5781": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "312faa5d21274016b6661c8eec9e3ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "314c193307024550b7fed8f34351e2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31521fee37034c8ab79c297d766b154c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "317b1c13bb4049b6ad9cb6d43e4f5dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31f2a77ace8b4b2c9e4172e5553b1963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3200a71728314547a5abebfac664d358": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "324518d0142b439db303e7390345422e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "327eff2159a3461fbe519c4894b70ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2fc9d5d2a4e44c9b49d424992bab00a",
              "IPY_MODEL_80a39524b9204b91ab800861a4200d55",
              "IPY_MODEL_939f1df069354a649a152e43f455e496"
            ],
            "layout": "IPY_MODEL_af41f782078f4bb39ec6c237fc4d5032"
          }
        },
        "329ac193ee214fcca82fa936f0693b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32d590a30b584e2daaf35aa41415c652": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3304bbfcb2054ea0bee2f98cc4ede818": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3340fc0094214e7d873e51746b35eff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "335d74b3e67a4fa0839423332d9a3e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_149e1e8208f1482e9d5acafbe1d37288",
            "placeholder": "​",
            "style": "IPY_MODEL_8847c23d1bc442e1a06d6dd55de758c9",
            "value": "Downloading generation_config.json: 100%"
          }
        },
        "33d9b1a309c94ce19378890710ded038": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34069299114d471d95ec180b2844fd9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343c252921964b04a7a4c5d526e8f738": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3bbd5fdaf134ff2b927638250d380f9",
            "placeholder": "​",
            "style": "IPY_MODEL_192a5bbe114b409f90d957da37eb66ba",
            "value": "Downloading data_config.json: "
          }
        },
        "347a6e13bdf34635ab382a60a2f6b576": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63bc2f90b24f4e519c46a6af86ae3337",
            "placeholder": "​",
            "style": "IPY_MODEL_f2c83afc96c040b5a06e32172fa5c619",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 227MB/s]"
          }
        },
        "3544eb4f2e244bb2976adb26694d9544": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3593ecc1b0164833a6ef558459153a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "359f0f86786d4c66961924a25772a28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "365c751ecfb94b67847d1dcc4a3ad582": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36777f8923884efb8215d9eb3d985f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f842684899af42a887557e16f9fe1869",
            "placeholder": "​",
            "style": "IPY_MODEL_308dfd6c4af54bc99dbdf7b21b7b2a85",
            "value": "Downloading (…)nt8_avx512_vnni.onnx: 100%"
          }
        },
        "36c5226338df4ffab441b3272c85cbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d464130f7041c4ba782827c5b2824b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e2e7f982e94087953e68244df6ca91",
            "placeholder": "​",
            "style": "IPY_MODEL_407ed72b494348b59d344756ca13c364",
            "value": " 2/2 [01:11&lt;00:00, 32.79s/it]"
          }
        },
        "3740c36c90124fe4a5a6d1e1fffc55ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7fea2b9f789438abf0cba04637af9ca",
              "IPY_MODEL_179aeeaa25ab4b07848fa99b5634f20e",
              "IPY_MODEL_e22c18f263a448ef8f281273e350b50c"
            ],
            "layout": "IPY_MODEL_b42efad6f7384945b9f9d98bfbe9fb94"
          }
        },
        "3773be4816d6405f804bc35449a7fb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37ac8ef87bf74917bf3ab47023020c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a5b3c403f344fb1b33609ee093a9963",
              "IPY_MODEL_95387ea88a41433b91f919e37a2beeb8",
              "IPY_MODEL_c4b391e1e04e403ca092d7878eef200d"
            ],
            "layout": "IPY_MODEL_c9b53c6c32494869bf41178640564d25"
          }
        },
        "37cc571e9e504f059fe50d5c2396a4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "380edf7f24fa4de29a2f25d37d809aad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38412e3383a34014a9c4fdf2862fc58d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d8119e862d4642823b84553fc8ac67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e55d9d9c27d47a7930b996473fc6e2d",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3c3b666e4d42e0826aeaecbf604197",
            "value": "Downloading tokenizer.json: "
          }
        },
        "390db3d08ceb49fdb0ae2084f6ca8ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "392a7daa6776422aac143550f01422f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397966192433469181a6d41159a04c99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399513d2399143958f03a1f9628c0e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e732b94e8354f94b7b9ed5b0e3f5ba0",
            "placeholder": "​",
            "style": "IPY_MODEL_c677ac8c37cc4b16840063accfb8a1bc",
            "value": "Downloading .gitattributes: "
          }
        },
        "399d5f1435d44853bcc8dcde38aa0da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a0c0dc86aa14b4eb07586f6fa6c3b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7153d871d7584e8abab2e7fd3e9c818b",
            "placeholder": "​",
            "style": "IPY_MODEL_11bd65590b784e6283d4520b63e2bd30",
            "value": "Downloading (…)_qint8_quantized.xml: "
          }
        },
        "3a26af61f2914c19ba4e9b39b94520b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2869177037834e518078a39793148059",
            "placeholder": "​",
            "style": "IPY_MODEL_4ce80f79104d412694fbd53bae4bf2ba",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 128MB/s]"
          }
        },
        "3a3087d770354696985569b8c6fcb3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8d77cc90ae14019a41746fa75dd4d17",
              "IPY_MODEL_60bb4daed0ee4e90b741c43619429087",
              "IPY_MODEL_9d40cb1b2664451d8a6d00035918381e"
            ],
            "layout": "IPY_MODEL_9a1b17557b5d49bb9f029fd598a404ce"
          }
        },
        "3a6d2c86797b4144aa1d69451b4d1c35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a91b1b5b45e412eb57439eddce5b6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a93149b9fc045aead269b10f96b6b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a980969bc974a688ac906590d2748c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b1234e1dc9e43068d9a2225c678f233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7c122c227e74d14b5df8905181a49a9",
              "IPY_MODEL_de7514463b55423ca43a02f372efbf53",
              "IPY_MODEL_8503c829903b4fb49939a62f1882f997"
            ],
            "layout": "IPY_MODEL_3e42b7b2b71d4531aa256ebb5b448ba4"
          }
        },
        "3b1fdc1ddfad4f7c98eeb409171ccafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b44909b5ac1411395bc8d8832af5822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b7c506254cf4055871f9c05e64a049e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b92e71d7053438fa8025d536dcbe9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1fb029bb8245cea2f95b9acb34bf88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c6c26093b0749d3b70f67680871fe91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c759dccaa1048f38ba7560418ee2f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91f97d687244e13b1c7021ef9ff0cc3",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb303fa79834a93ad65227011bc688f",
            "value": " 411/411 [00:00&lt;00:00, 35.5kB/s]"
          }
        },
        "3d5ff2dde3ea47c4b0048cb5c12f0747": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dad8eb5f7784207a9c371b7252cc820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3df110d821d245a4b8674cf7fbebb310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e0a786891f949ae9162ae04944ec79e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3e42b7b2b71d4531aa256ebb5b448ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e518e2430e842e98a3c54d5960eefe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee8296a86f74949bd667ab4657d8b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f3b71aa26574b0389b972013f2d9bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05b1d21677de42548ad430d2e5e956ca",
            "placeholder": "​",
            "style": "IPY_MODEL_b36dcdd6783f465baeff85801392e250",
            "value": " 22.9M/22.9M [00:00&lt;00:00, 246MB/s]"
          }
        },
        "3f4f42efe424496a904f3206a266e82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66efae71b5f8457883b4a06d6b6f9b7c",
              "IPY_MODEL_0ca4fbed1bec44b4991401cb94be3ad1",
              "IPY_MODEL_9af6b6d434af4e51a684b9431b085c07"
            ],
            "layout": "IPY_MODEL_096af96cd077434f989f069152e41f64"
          }
        },
        "3f6aaacb9961458ba6e3a12cd35c659c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21d2d52c79ab47deb0feb79c7bbf212b",
              "IPY_MODEL_4869195465f2442699d4919afb741487",
              "IPY_MODEL_347a6e13bdf34635ab382a60a2f6b576"
            ],
            "layout": "IPY_MODEL_b2c92180be0f439bb602f279b27f9fe2"
          }
        },
        "3f7e107e2b1e474480989bdbde7e431b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fb431ed4a10403c9300bbce14ed9e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40416307e5004aecae064b6ac9af2a37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407ed72b494348b59d344756ca13c364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "408d5f76046846ab8cc8a597000544bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40df0f841c374dc6af8494de498facb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40e3ab9e0351401e980691bfb49176bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "411fc75d76cb43948cd667afc23c2122": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4185b71614e945dc8bf524b160bd10fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d67a27ae2145b89b311190e25122ef",
            "placeholder": "​",
            "style": "IPY_MODEL_6cc0cfbf8d4841cea3d39d7c5ab3c93a",
            "value": "Downloading config.json: 100%"
          }
        },
        "41d761ed5d454d7ab913df8be5c3c882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41e5f287e49b48259e281aaf763b87e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42151894c52c416dae00e8f1f8cecf5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421f2f1b64b84aefadbc3c68d072f600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4258ac6b45c546ee9ef2c6ccc7429f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3afcaeed1874a54be7275b0e7d18806",
              "IPY_MODEL_cd1d41870d304e4c86904bcc27fd736d",
              "IPY_MODEL_ecc1c2eff0164a7fa60afc1825e871f7"
            ],
            "layout": "IPY_MODEL_89de784100844ec7a74f5c43efad4d4c"
          }
        },
        "425f901db1e643efafc71dbba2b5f4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42868fad64824cd595cc5ee1383e38fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a5b9499eee4e1aaf7619ccc369dfa7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ae91e5fc8742598ee4e87f31eb78ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c3385e47624b65a6ac5b84f9b3b38f",
            "placeholder": "​",
            "style": "IPY_MODEL_d050f8b75269494ab05df3641733eace",
            "value": " 466k/? [00:00&lt;00:00, 20.9MB/s]"
          }
        },
        "42d9e893c83c436fb645002a2e8f7b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4329b9c9355143de9aefda5ff3442339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4372a4e66f73433b9907b21becbedcd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437df8da1c0e4fb692a94fb4451fe8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4440074eaece43c68755c34646df860d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44ada1b1e8184ebc8a3c8db91536ff06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_892effe1e0c3478e8dff05214991b4d9",
              "IPY_MODEL_8dfe9997b94d4ebdbdc859e12f65bb86",
              "IPY_MODEL_94ba8ad711814a0c826ff2de25cc3d47"
            ],
            "layout": "IPY_MODEL_26f48dc181774720b3bcc7ecaf60a6bf"
          }
        },
        "44c8838ba4f0403ab9955f616961b23c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d5b962a04148b88f7713caf23155dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4502ca6ea067426ea288506ee093532e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45709e3fa69e4eff8dc4b4ce328eb0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45875b031b044710a0f7e9532033dc40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "45d99908b9cf4297a3b49d3a623fae17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45e9950e3ac4418795a2b748a957c517": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5287de44b8b54af8a56fecc63687ec63",
              "IPY_MODEL_a218a6064fc84c7e85fd72a4ec1d0f9b",
              "IPY_MODEL_66b11835308947b8a5f80e44fb4c62ad"
            ],
            "layout": "IPY_MODEL_ea029b5137e84350ba46446599c515f2"
          }
        },
        "45ea6401b49f481aad71b5eaa7edfe73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fde3235287d542ccaf3088af8bf78950",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12a0c8ca12a84e6995c247429d92cfb3",
            "value": 116
          }
        },
        "460c31822a4f4818bc08e263d0cc3a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0c3b18d932648488b9c741067de403d",
              "IPY_MODEL_30220cb4d8a1429e8d92976b825e3d83",
              "IPY_MODEL_5f0ad748e4374da1b9f0e13307716a15"
            ],
            "layout": "IPY_MODEL_c02c6e94284a485db756cd5e8c27b03d"
          }
        },
        "4643035d28d947eea75c869e1a01a0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e3167dc0e54b60bf49d8da3a91afbd",
            "placeholder": "​",
            "style": "IPY_MODEL_9a0a865a646f4acaada044d13e3625a4",
            "value": " 13.2k/? [00:00&lt;00:00, 1.18MB/s]"
          }
        },
        "464b32269e0c4a40a56ea223c6c18e53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46e51e03792d4b7cbb6300bbb3ab83f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "470bdb34970940d89bc06aba6e8b5f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef0ced69039b4a22b6c7293b40f4abe0",
              "IPY_MODEL_8f356c5f092e4882b67fa217ed8c7e0b",
              "IPY_MODEL_c6a2e62e55464d109ab15b59739945f4"
            ],
            "layout": "IPY_MODEL_b2c66b1721a44b82ac642d0484cb5b1d"
          }
        },
        "474b6ed46e2b477497257702c1ca3801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "475b6d0583f541348b390af739467fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4372a4e66f73433b9907b21becbedcd8",
            "placeholder": "​",
            "style": "IPY_MODEL_b74166f3dd3c44b3bc8be1961d97956a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "475bd4a079a84878a0b43accedf931e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a9340723aa4898b45e4caf5a5dfa2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47abc603bb49443181cbcade412d5e48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ae4f9641a449a8b7efb16a0a21fe2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9015fab762b543bd9a28e7435ae6e977",
            "max": 646,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbe5120d4dbf4b06987dc72e3be30536",
            "value": 646
          }
        },
        "4869195465f2442699d4919afb741487": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_933c26c05bec46d79833d49d2df75bcf",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3773be4816d6405f804bc35449a7fb51",
            "value": 23026053
          }
        },
        "48bd0028bff84db6997ba523ea31f98f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48fe890bb8a142ba881ac0cb302b7f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f507aebbc354dafb0a27465b8c28a25",
            "placeholder": "​",
            "style": "IPY_MODEL_5dec8406357a4c2296d4ac1ea29f5f1b",
            "value": " 90.3M/90.3M [00:00&lt;00:00, 241MB/s]"
          }
        },
        "49539475661e421cb73c7cf4e8e79c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "497d5ef5243940aab69644d2fbd8b90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8823ccf5e72a44fab7c915343767ff67",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f09e0153c3e4404a59b19d6163e4c78",
            "value": 2
          }
        },
        "49ad2dcf668a409ca6516bec6b5605ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec5ec4e6c8904fcbbafcdf9dcc46db77",
              "IPY_MODEL_1cc67fb9698d4082b503b46525650f02",
              "IPY_MODEL_566443bd974d499393f6f0515ec38f22"
            ],
            "layout": "IPY_MODEL_d3baa763413a4b6eb90b0299af7d2b59"
          }
        },
        "4a3f4e3c75674e8c844ad84638752cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ff4fa88d21544a0959b52eea3cdb1ca",
            "placeholder": "​",
            "style": "IPY_MODEL_99f915f64314496ca86ea825016c6fd9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4a769323f3284e1c8ed9911a95299dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0bd7e54d8d246c98d631f5921318056",
            "placeholder": "​",
            "style": "IPY_MODEL_cafc9336a8eb4f04a714ef3b36bf9939",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 306MB/s]"
          }
        },
        "4a91c572d4764158a2310617cf754117": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6fc803b91b64208b71a91acad0d12d6",
            "max": 90360328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e99d9f2d829f4777966be8355c5e8296",
            "value": 90360328
          }
        },
        "4aad7e2f72324820b71e06a431e446bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4abd00291eb9450dbddc550b4cf9879d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac27f54421d4730ab0c2f139eaacd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42151894c52c416dae00e8f1f8cecf5a",
            "max": 500058,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4f636e0348e4b4b87f4f454d994a8fd",
            "value": 500058
          }
        },
        "4ac93a96d1d649aa99c13ad6e2d3e230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c10a268b45d4312b50b4f6cda7e5e69",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_961858920d1c4468a92c06fddcd82654",
            "value": 1
          }
        },
        "4ad162fbbc4e4c1295aebe0b93eb75cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bdd167f55b54badad2c66a09aec83fd",
              "IPY_MODEL_601e2c5c5518412a87421cce4f7aba1d",
              "IPY_MODEL_2791beeace374a439ab95451b76a5c8c"
            ],
            "layout": "IPY_MODEL_b64530a7667148adb8c21f6c1b57135d"
          }
        },
        "4b2300a04b7049308ab1a4ec8e65ee6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b663baf84c7423c8fa80355c7a432d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b79614345144b40a73436f909f1e4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57f2adb727d84496a7fbc7e085243a56",
            "placeholder": "​",
            "style": "IPY_MODEL_9b4bf2eef3cf48d6ad89cb3c2ae44d3e",
            "value": "Downloading model.onnx: 100%"
          }
        },
        "4b9589fb650946b7bd5fb0820e7c81a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be0cd6ca99c4d7fa85b7f5a7916e56a",
            "placeholder": "​",
            "style": "IPY_MODEL_0264a2477a844750b3e24a4079046840",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 194MB/s]"
          }
        },
        "4b9b80df084f47dea44be7097d146273": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b9c8a6cef124f5a97f6d383b0b722ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e9d63f81b8a4be0ad0f735b6c74f5fa",
            "max": 90326497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65210dbaec354be19c1ea3665ece4428",
            "value": 90326497
          }
        },
        "4bc5b70a7bf8441fbcab42d464ce5113": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdb0bc3434643829cd63ca79b7f4bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93eaf5ec5e384428ad283fa2e5e2a7d3",
            "placeholder": "​",
            "style": "IPY_MODEL_269a6fb8fefa4520a13d8690d42779e5",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.42kB/s]"
          }
        },
        "4c6800f3a154486a928e40ee362353d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cc007c436c248debe965da1a2f84cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d592f659a3b94b688003f960f4ffe312",
            "placeholder": "​",
            "style": "IPY_MODEL_ced1d4ae254140b6a72f8daf74552443",
            "value": "Downloading config.json: 100%"
          }
        },
        "4ce80f79104d412694fbd53bae4bf2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf09d742e854971b283ec6b4cefc122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a22f76a484f42a594e33489c3417b06",
            "placeholder": "​",
            "style": "IPY_MODEL_c91fff0b12e941f59d69e7aa036ec410",
            "value": " 411/411 [00:00&lt;00:00, 48.0kB/s]"
          }
        },
        "4d921725438f4c7fa30fd6974145aa40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e0980ff295942b9bbed8a2405f0ac4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e281b1dff5e4afc86717302642dbf31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e3ecd49555d4440893b44fe5f4eb7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e461638844c4a6a8fa8d24d8b084afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d07ccacbe554f88b21a41804c912c46",
              "IPY_MODEL_2e487339d6be445cb0c698473ced7153",
              "IPY_MODEL_4e86e5407f9444f09c728c3de6daf5c4"
            ],
            "layout": "IPY_MODEL_19e3410076f74098bf8e012eab7b4297"
          }
        },
        "4e4eda429d2643fd97d6f403efbc66a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bdcc9e737be44a4ac5a5c412f5009bb",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c6800f3a154486a928e40ee362353d2",
            "value": 411
          }
        },
        "4e5024d0809c40b2a6069413911db6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1490d6000483413f9660a88a3bb7d6e5",
              "IPY_MODEL_ec6e53843fa3422f9174982083d53783",
              "IPY_MODEL_2997826ac37b4f77b80f20c40f2c7fa4"
            ],
            "layout": "IPY_MODEL_b8f0cfa283ff41ee97677a8f803247aa"
          }
        },
        "4e5e1a83f0164a86895b0bd45f974103": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_052b04b5535a4115aaf828ffdf048080",
              "IPY_MODEL_45ea6401b49f481aad71b5eaa7edfe73",
              "IPY_MODEL_eb6a8b7f7ea2414a9702698b5d952757"
            ],
            "layout": "IPY_MODEL_7f3bcfda0c9846df868fcd2eee7b756d"
          }
        },
        "4e86e5407f9444f09c728c3de6daf5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_061698bfe5c143399227c68e1ea78bad",
            "placeholder": "​",
            "style": "IPY_MODEL_89ba5b0e3dc64efb84e74d5031963c9b",
            "value": " 53.0/53.0 [00:00&lt;00:00, 6.52kB/s]"
          }
        },
        "4e8a17077f464ae890236a0985b17d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb8f3d5fb1b4c40be42dbe2bc676c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cefdd3039c4c4290843f7e00d1fb91b5",
            "max": 90326497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cebd3fdac18f4a548a21eff316080b29",
            "value": 90326497
          }
        },
        "4ef2704b02e24e75bc437e3bd14e42ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef56ac0025544a4aef80e3aac82aca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e70f60edda7f43c7adce2e16f9f46521",
            "placeholder": "​",
            "style": "IPY_MODEL_d4bdb1c3fa43458882821c2cc4b90fcb",
            "value": " 9.98G/9.98G [02:19&lt;00:00, 41.7MB/s]"
          }
        },
        "4efabe35061a4d31bb5b7bf6aa5acfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a1546d0afc4357a8aec090b5a9dd5b",
            "placeholder": "​",
            "style": "IPY_MODEL_ffc31f20dffd4fe184dff35cc1b93145",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 135MB/s]"
          }
        },
        "4f130b3ab9744cff92875c199639eb65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f495fcb342049f6a9cf3ddee0ca5f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f507aebbc354dafb0a27465b8c28a25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f8085040cf84857af29218cabc52eea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f8378019748425fa002d77f1d4fc9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e669c01427514e428e99cfcd8791d657",
              "IPY_MODEL_f949115e02674a5b9b2b42ba117bc00e",
              "IPY_MODEL_9a341371b2cc4686883010155592712b"
            ],
            "layout": "IPY_MODEL_8ec2f7993da54eb4a9e7391c1795f357"
          }
        },
        "4fb4f3b1aac94eb187dd0d8986b3205c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500efb5040ac44a8bc693d96b86bbf18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501fedf74d1f4f15a028ccdfecb3c195": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a376c445e3430ebbd05d7931c9b9ca",
            "placeholder": "​",
            "style": "IPY_MODEL_18ef89f0f21b454fa59eda04def352fd",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 223MB/s]"
          }
        },
        "505873e0410442b88ab57ef057922802": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5076ca236d164978a3da150637eba20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75baf60ac515444f8a491b51c46ef3ad",
            "placeholder": "​",
            "style": "IPY_MODEL_0072536ff3fd4ecda7de0ff71349b8e1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5078f8e91520424dbc088c9a21281dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50af68f3ea14412e96fbb59d9a565156": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "50efa3a93c474ce2b6d077f899b1bf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_960ed08742294f0c86b7cb4bdc84cac3",
            "max": 90326497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddb00c765dc2458bb8441f0076c2b6b9",
            "value": 90326497
          }
        },
        "510ef88b22de435e8c85d902994b8ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5509931c51f14f8ab5b523689f5c5363",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8798fa091b54836b21c699de2b94caa",
            "value": 1
          }
        },
        "511d824e50b64f1f947f0c8536487f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5177550e5f944d1a9de83364cba894a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517f0e8a313a461fbd5a95dbb63ad1d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51db87e88cba4a95a1bfe120d92c456a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "523c8942435f4fd18956b71bf7740a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd88aa6c3b124896a02624637ab35161",
            "placeholder": "​",
            "style": "IPY_MODEL_b66de9ddfb5442048432e976a8aba8d9",
            "value": "Downloading config.json: 100%"
          }
        },
        "527bffe660d94ed988c3641435a6a255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1de6ca23a8e7419e99c8d058e44d6fa4",
              "IPY_MODEL_9bd882b92f1a48988e733ee91d64f8c0",
              "IPY_MODEL_5999613a44e0411aa5d0f8645c4e0a73"
            ],
            "layout": "IPY_MODEL_656fed84483f4d9a8f2406df250a0a0e"
          }
        },
        "5287de44b8b54af8a56fecc63687ec63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_944c18536cc9460e992a663ca5a7fe0c",
            "placeholder": "​",
            "style": "IPY_MODEL_1f67677176da4de49517f82137f2ca09",
            "value": "Downloading model_quint8_avx2.onnx: 100%"
          }
        },
        "52a0b3b4fa38441296fc2552d6edce3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a376c445e3430ebbd05d7931c9b9ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b55f718b6d49a4b59b7ec10f31aa3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "538c1a40cf694fec90c8030d41b909c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53b1c2bf1de14e23b5e15daf2e8474c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "53bd848993b84529862f194e2dc8a3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f0b82f1eec484886c1236f1b56cb25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f133fa47c948d1b0741de6db5429c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "543469ef680f406497315759786b2be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59887a48564c465998655dc95ae4768b",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2494586f25e4d8f86258ee8345cd6e6",
            "value": 190
          }
        },
        "549bad16e2414e5393280820e9890f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e39c8fd1ba2848c3965d11e7b5716a56",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db2abfcec55f419ab058097ef6434bef",
            "value": 1
          }
        },
        "54ac3a0b746c4e7ca030569ae4e876a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a27f830e5e754451956fd907b2356114",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c6c26093b0749d3b70f67680871fe91",
            "value": 116
          }
        },
        "54fe6814eb7f48f591d3e1b2297a2365": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_505873e0410442b88ab57ef057922802",
            "placeholder": "​",
            "style": "IPY_MODEL_681df2ca6298455cb891ffc35bfc488c",
            "value": "Downloading vocab.txt: "
          }
        },
        "5500a073bdd64810b725ae1ea420bde3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5509931c51f14f8ab5b523689f5c5363": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5545aaeb70e5462baf4b5a28363eaf9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5564c6ebca1f401da44da628e3467f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55850c6dfd554b9b89cf7bd65663212d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "558dc661cdc842fca527b1b863c20946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55b4b7d46cf4e46a9d2acb6abf7173c",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d578ec8a8ae7489ba440c81ed0b29fe4",
            "value": 116
          }
        },
        "559288102d844e14bb5c5edace7955a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ed30864aff43249eb5f91861c4ec09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "563320bc9c174de48297b02321407d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9af9d703e0a4f40b18ddb32c8cb1e64",
            "placeholder": "​",
            "style": "IPY_MODEL_1ff0d42557a443498f1f65ecfc31697c",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 171MB/s]"
          }
        },
        "56447bf0c5ef4b228d47e5f36b3bf203": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "566213f1d5c544b7ad0413b56d70a5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b163ef7384eb4f95be00e7ec1a73b72f",
              "IPY_MODEL_a2893e31fe114666bf9d05489147cc57",
              "IPY_MODEL_ab6c1bb8c15441098750575fb3e9e37d"
            ],
            "layout": "IPY_MODEL_21e0c252a0cd4918a3a24326b9e58418"
          }
        },
        "566443bd974d499393f6f0515ec38f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83364bc38a694466bc5e03140cfaaf38",
            "placeholder": "​",
            "style": "IPY_MODEL_10964dce0fc141f1b27b582fdab2c9b6",
            "value": " 3.50G/3.50G [00:43&lt;00:00, 81.8MB/s]"
          }
        },
        "566840304c9b40c6a0ae43bbdcc563d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5686639b6e994b14bf6170a20e279c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "568bf7b486d447068a50c4f990d75249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569e08a7b6644cf19fb076b504ad56d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb431ed4a10403c9300bbce14ed9e7b",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d561285cb8a427988ceca99d932650e",
            "value": 411
          }
        },
        "56c444637c4e4adc9ce25f14ab356b97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572f2e53d97f4b5197b9ef44beda9d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828b34a3b82d4d8794241e76fe75d1fe",
            "placeholder": "​",
            "style": "IPY_MODEL_4b2300a04b7049308ab1a4ec8e65ee6b",
            "value": " 2/2 [00:58&lt;00:00, 26.59s/it]"
          }
        },
        "574c3a381e564e96bbe31bc802db9fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62c32a7f46dc4127a89884287f990973",
              "IPY_MODEL_9f01be8c1c754841a7ac8413ec33ca4d",
              "IPY_MODEL_908394de664a40fcb75ef67518af901e"
            ],
            "layout": "IPY_MODEL_9f02c626e14341bfae840dec5f606c7f"
          }
        },
        "57512a7d4ba7491ba869eff58c40fef8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "576d552a4dac4aa187c82a848318bfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a6277dd7972411aa5c005a6238d67a3",
            "placeholder": "​",
            "style": "IPY_MODEL_68d88b90a9cf490c91322fd13173a384",
            "value": " 2/2 [00:58&lt;00:00, 26.61s/it]"
          }
        },
        "57a5b104c446439ebd360f643a788c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d00172fa7bd240208a371488265339cb",
            "placeholder": "​",
            "style": "IPY_MODEL_31521fee37034c8ab79c297d766b154c",
            "value": "Downloading (…)of-00002.safetensors: 100%"
          }
        },
        "57cc26dc0b884f16af085d88df442984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ec4879f78ad4030ad355052698133db",
            "placeholder": "​",
            "style": "IPY_MODEL_9bf149682077465182b85fd87f23922d",
            "value": " 2/2 [00:54&lt;00:00, 54.47s/it]"
          }
        },
        "57e28c6d9cda4d62ae6c51bc6f31bb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57f2adb727d84496a7fbc7e085243a56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a290facd204df3b8cbb6d2d3fd6457": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b062987e1e340e8af1c3e7805bc68fc",
            "placeholder": "​",
            "style": "IPY_MODEL_7f35caf43b1f48f0a2c02ff7af6cbeba",
            "value": "Downloading config.json: 100%"
          }
        },
        "58c81480ec6649e2aa7bce960ae64c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3dfe8015634ee9a65e32fe9a18da12",
            "placeholder": "​",
            "style": "IPY_MODEL_c8e0ce97446a44eca1b6f7bb7804187a",
            "value": " 350/350 [00:00&lt;00:00, 33.0kB/s]"
          }
        },
        "58cc52cf551541d1a88614b48432ae8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58e94c3caf9f4f14b7d6d5838e033f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ce58e2d9e014944b6a280c9d696ded0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d73589d0a22243debbc3950e59a9867b",
            "value": 2
          }
        },
        "58ec4a45101c49e4b8080f5402c0e96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699e546383b349a3af744724c3ff89c7",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ba4622a8f20464dae44bb332e7c0c82",
            "value": 90868376
          }
        },
        "595ab24928984f4f874c55e9b382a7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_907998058c394d3a968da216b1b2cb5c",
              "IPY_MODEL_a82f857182724e48a22a7f5ac84ce5e0",
              "IPY_MODEL_1f14d3de34c94d16876a493a7fd4954f"
            ],
            "layout": "IPY_MODEL_e2ce4a6220ad49c1811d39cc281c6ef2"
          }
        },
        "59887a48564c465998655dc95ae4768b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5999613a44e0411aa5d0f8645c4e0a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23b547017c6342a38c95b2f305521ec7",
            "placeholder": "​",
            "style": "IPY_MODEL_8fd950ed089f499fa9238b2c8dbe3000",
            "value": " 232k/? [00:00&lt;00:00, 438kB/s]"
          }
        },
        "599eb83f9de840f38691794cf66b19f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59b9bf579011464199b811f70bbb4338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59be65899ba347dc9142115b4b67eb77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b736b5404714877bcca15e17a5edeec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba4622a8f20464dae44bb332e7c0c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5be0cd6ca99c4d7fa85b7f5a7916e56a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be65bf7257f482ba5c6452e81fbc5d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c0832fab25e45c6859ea0806d868295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56447bf0c5ef4b228d47e5f36b3bf203",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40e3ab9e0351401e980691bfb49176bd",
            "value": 1
          }
        },
        "5c2938c29bd94735a6a8c88afcdd9f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c2a547748654e08aa0b99d977516986": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66528f506156490790644ddac5b413fe",
            "placeholder": "​",
            "style": "IPY_MODEL_2ec0479b85164b7faee6cf201593ba6e",
            "value": "Downloading (…)of-00002.safetensors: 100%"
          }
        },
        "5c94a1a4a0254e38856ed973cce006ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbc78aa35724b9aabefc64674e93616": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cdf714ed91049f58f1ad4ea57608469": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d25bb0fe02540aaba0df239b52828a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc3119051b449339ad4cb9c41de746a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dec8406357a4c2296d4ac1ea29f5f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e103bd5ce7a4a01a0cae9f49a6a24af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5e1aa87179a045f39644877ee0d5b8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e2d4634930147939df1e200189823df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05edf76d9a424e0f9d6abcc368dae91f",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_731cf3819ec742a59d7eebb40e641429",
            "value": 53
          }
        },
        "5e33cc6b901b4890bc116cf98d9f12bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6189e2b3ee664bedb9a66a16ba3fb3db",
              "IPY_MODEL_558dc661cdc842fca527b1b863c20946",
              "IPY_MODEL_c261513358e142fab2aa9f320d1e0f88"
            ],
            "layout": "IPY_MODEL_e6c71f3337434e0180dd02ed0ffd3f66"
          }
        },
        "5e3ce944d0ec4d37baaa70149be71723": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ee58c81cce4063af823f0c60eb157b",
            "placeholder": "​",
            "style": "IPY_MODEL_40df0f841c374dc6af8494de498facb5",
            "value": "Downloading config.json: 100%"
          }
        },
        "5e4ceba4a07e4dafb7a2dc2acb778111": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c65ea55165de4adea3939adae385acca",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_032e3682bfe9460d86e7cf6809529176",
            "value": 350
          }
        },
        "5e9d63f81b8a4be0ad0f735b6c74f5fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f09e0153c3e4404a59b19d6163e4c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f0ad748e4374da1b9f0e13307716a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cd01c76aeef4e2b9b9a201eadac2f2f",
            "placeholder": "​",
            "style": "IPY_MODEL_a3b98694916e49b79496261ff134143f",
            "value": " 25.1k/? [00:00&lt;00:00, 1.36MB/s]"
          }
        },
        "5f8ef43fc4484ec1b7e76e3ad838344f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601e2c5c5518412a87421cce4f7aba1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df031ca9457426c947dcd28c64a4632",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8a88bdbbacf4095b91491ab4514af91",
            "value": 2
          }
        },
        "605b0f90d6ca4f56967a2f9f628b1502": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "605d41776906404ab6aa0c091786eb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "606337b912264bb7ba7cc2e822af74c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60bb4daed0ee4e90b741c43619429087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1577df45e53e4f9fb55ad515fef3ddd1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d69bba33938b4cd8b124f0cea77541b1",
            "value": 1
          }
        },
        "60d24e1fd47c450f9300e9a276c3b24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60ee58c81cce4063af823f0c60eb157b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f4cdaefc2d4f2eb469fa342953be7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_559288102d844e14bb5c5edace7955a2",
            "placeholder": "​",
            "style": "IPY_MODEL_02fa33e476d84680acdbd932b4332aeb",
            "value": " 2/2 [00:41&lt;00:00, 41.99s/it]"
          }
        },
        "615a33c7c711486e804b177b217a34aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61608a496a07479abeb5e4d0cbb37b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cd10969f46b47309a70809d20b9aeed",
              "IPY_MODEL_7c95503eaacb4822831de884d58e5d4f",
              "IPY_MODEL_3f3b71aa26574b0389b972013f2d9bff"
            ],
            "layout": "IPY_MODEL_ac757f21d8dd44bd9cdd3104ae5516ae"
          }
        },
        "617ec32f75eb48cbbd3abf21bca37364": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6189e2b3ee664bedb9a66a16ba3fb3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be65bf7257f482ba5c6452e81fbc5d0",
            "placeholder": "​",
            "style": "IPY_MODEL_f2fde1e327f643b3883769f744f2b80c",
            "value": "Downloading (…)ce_transformers.json: 100%"
          }
        },
        "61a7ef1dfa53425cabbbacdc40261ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61da6987ccec43938a5fbbb94b2a8ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a9f8aa5cfd04d09a789493a14508bab",
            "max": 45212349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57e28c6d9cda4d62ae6c51bc6f31bb14",
            "value": 45212349
          }
        },
        "620e046c29d74b9ea554b47072d75307": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6273874c5a024d7b9e56cb4963f12234": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_654746114040476294d4df8ef2f6405f",
              "IPY_MODEL_2ed4500812064ea2b2b15347ce40f8b1",
              "IPY_MODEL_563320bc9c174de48297b02321407d34"
            ],
            "layout": "IPY_MODEL_06c467a050af439eb75c22dfd050fcd7"
          }
        },
        "627baeeed64b42c4addb3601d38fece5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd8027cd897245818631e094e4ed8c80",
            "placeholder": "​",
            "style": "IPY_MODEL_08b3aabd306443208f392f34142f5100",
            "value": "Downloading (…)fetensors.index.json: "
          }
        },
        "62986736155646c98fd12512da90c59e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a92922ad8e4f1d838dbcf9599c9af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3a3bb0e97594c74b5e6955f5a733fda",
            "placeholder": "​",
            "style": "IPY_MODEL_b65a6cae7f924a9e9e49b76a62156472",
            "value": " 211k/? [00:00&lt;00:00, 12.8MB/s]"
          }
        },
        "62c32a7f46dc4127a89884287f990973": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195f14728bfe4bde98df406ebd58c2a8",
            "placeholder": "​",
            "style": "IPY_MODEL_312faa5d21274016b6661c8eec9e3ebc",
            "value": "Downloading model_qint8_arm64.onnx: 100%"
          }
        },
        "62e6758384644f00bc16a3f273a03caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d0669fc63644029b19f42796773a58",
            "placeholder": "​",
            "style": "IPY_MODEL_3a980969bc974a688ac906590d2748c0",
            "value": "Downloading model_quint8_avx2.onnx: 100%"
          }
        },
        "635da505b3784c0cbbb757b39e230189": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b0bced691b24eee8537bf2ceb00a838",
            "placeholder": "​",
            "style": "IPY_MODEL_c1b06077292041d38d22b0878a1aa0d5",
            "value": " 90.4M/90.4M [00:00&lt;00:00, 175MB/s]"
          }
        },
        "63bc2f90b24f4e519c46a6af86ae3337": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f64032a2af4837b7f1b1aca98ab3c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64301bcee191455eb109b4cc9fbe2aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64853c976d0345a5a66ec8a615ff7cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "650a6da4aa814adda0d20d64da66e7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c38d850a979b4697967517f24b2c117c",
              "IPY_MODEL_b1eb6b4938c84498814d5989141de7c3",
              "IPY_MODEL_67396f894c5541d89e938f640a24cc02"
            ],
            "layout": "IPY_MODEL_3544eb4f2e244bb2976adb26694d9544"
          }
        },
        "6512af48d90248aea0820c0fceacb80f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6515798838c442d0a9525f933549ed9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9258f1f32ed4d5a940950a6e697419d",
            "placeholder": "​",
            "style": "IPY_MODEL_4d921725438f4c7fa30fd6974145aa40",
            "value": " 232k/? [00:00&lt;00:00, 15.2MB/s]"
          }
        },
        "65210dbaec354be19c1ea3665ece4428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "654746114040476294d4df8ef2f6405f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9fb38eb00d8499693cbc0b172855704",
            "placeholder": "​",
            "style": "IPY_MODEL_f26c772aa920484c9183c7e8f844cdab",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "656fed84483f4d9a8f2406df250a0a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b17955bc594e73911afe8f4a50d62c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b73133de974967a3ca1a9d103a8eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99bbd82b8a3e40cfa63a36ba9ea7eed4",
              "IPY_MODEL_ecaae07d704c4ce6a65003c1908dd9b8",
              "IPY_MODEL_48fe890bb8a142ba881ac0cb302b7f17"
            ],
            "layout": "IPY_MODEL_517f0e8a313a461fbd5a95dbb63ad1d4"
          }
        },
        "65f1c762bf004a24a5190a8f927a08b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f486ffda8f4f829e2918b125d27f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65fc61c20c5649d6ae94f9d0b50fb2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "663a136650014618999dd0850ebce86f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663bf456c10240ec8f8a620a95a3f653": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b72645b813ec4583adb4ee27e99a64de",
              "IPY_MODEL_ee66aee457a94df09f79c82aad410448",
              "IPY_MODEL_4b9589fb650946b7bd5fb0820e7c81a5"
            ],
            "layout": "IPY_MODEL_81875e1af14347ecb19b8fd2a33bb885"
          }
        },
        "66528f506156490790644ddac5b413fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6664aca9bc8443ec8c7425541ba2c72a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666f64f345924c9faa4aff802f038fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98a013ed830a4243b2496cdfc263e016",
              "IPY_MODEL_1a1fd67bad054dbdad82d1a2719dc873",
              "IPY_MODEL_b594224d1eab4284b6ff0c13d6ee3b07"
            ],
            "layout": "IPY_MODEL_25513fe619af42ecab8f45badf3050c5"
          }
        },
        "66b11835308947b8a5f80e44fb4c62ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a82e3ac5189b450380ca453d179ae249",
            "placeholder": "​",
            "style": "IPY_MODEL_e5ce2131a15640ebbbebb59af50be5f7",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 204MB/s]"
          }
        },
        "66c475c2b5384bf7b573c65a2b58464f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002e26124ac54442a5d1f99379cf5fc8",
            "placeholder": "​",
            "style": "IPY_MODEL_fe10aa0808b74b2297d5c23606bf4676",
            "value": " 1.84M/? [00:00&lt;00:00, 57.5MB/s]"
          }
        },
        "66dbc1edfc2048d399462886420de59f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66efae71b5f8457883b4a06d6b6f9b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98fb0bb67754e71bd0c82f622cc33b1",
            "placeholder": "​",
            "style": "IPY_MODEL_dc139872f43647a0aa8cd5e6e38fdf3b",
            "value": "Downloading shards: 100%"
          }
        },
        "66f8ed40e3dd4891bda18ecd6c3d70bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66fae20cb5fe443bb3fc67f501b3a833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67396f894c5541d89e938f640a24cc02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5c96d0ecee24e9dbd5ee8214130496d",
            "placeholder": "​",
            "style": "IPY_MODEL_14005756676843ac8405d38e078b169f",
            "value": " 90.4M/90.4M [00:00&lt;00:00, 298MB/s]"
          }
        },
        "67556a4e4c6d4d879a826fd7a7ea3776": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b40389042849758ce4451d1d54e9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68167a4f370646adb0a11ecfaf0a5c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681df2ca6298455cb891ffc35bfc488c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "683e4d9a973c4c08b5f14f7ebafd5bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f09cbda5e64779b7058b09190c3840",
            "placeholder": "​",
            "style": "IPY_MODEL_605d41776906404ab6aa0c091786eb60",
            "value": "Downloading tokenizer.json: "
          }
        },
        "68480c61aed4496e8e0e047cae92a41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "685b1c66e7904c5aa35237270363ccec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b75cd6798543f9b9ae91fa881c6111",
            "placeholder": "​",
            "style": "IPY_MODEL_d6765c0c71754f139e6ab99bf4f779b3",
            "value": " 500k/500k [00:00&lt;00:00, 40.6MB/s]"
          }
        },
        "686545a18256476f97e73cf2f6f278c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688c9f0efae94ee29e57dd29e86cc1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c95f06cd834517b51e463735e70481",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d8539bacda0431a88034e1e321b6ecf",
            "value": 1
          }
        },
        "68b20dfc91b249579b6b1a9407cea6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68d88b90a9cf490c91322fd13173a384": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69041b87e25143e59711779525aca6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6998656c848b4e84b9a7c273e191c663": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "699e546383b349a3af744724c3ff89c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69d3c55274a24ada8ccc56b35b5e6c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69dc4490371d4b07bc46418a6df42559": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a033c92fcfc4ffda669b8d2835dfae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a0b2edf2e2840959b709f6c4d3497da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a300e51e94b4190a944854cc3fe0dde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a68408321e04315a3693f3849563fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fa3a7b26bc342a78dc1c6a211a98f25",
            "placeholder": "​",
            "style": "IPY_MODEL_bec2bd773e4044cab9bd91186674a61d",
            "value": " 2/2 [01:03&lt;00:00, 28.99s/it]"
          }
        },
        "6b062987e1e340e8af1c3e7805bc68fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0891462bab4cb3afbe36451372ea47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0afa6e524e499f958b5d34357df6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94ff97bd00954662b2a82bf1e989157d",
              "IPY_MODEL_ac01bfa5e00c4cfb9381a221eaa00700",
              "IPY_MODEL_efb76c551bb14347b81f5ec94c9b3ce1"
            ],
            "layout": "IPY_MODEL_5cbc78aa35724b9aabefc64674e93616"
          }
        },
        "6b9b0f9078df43529c0a21bf0c336f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ba9d6135a03467abe551fc7dcdffb46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17b8e034b05c4d7c8fbb6ab935bbb990",
              "IPY_MODEL_2e22f01099944fa69c1c304051b7d74e",
              "IPY_MODEL_cb9a4ebd8c9c4348b8ce6085e314441d"
            ],
            "layout": "IPY_MODEL_9cc6cba5aeec44f299173aac2954190f"
          }
        },
        "6bc37ed1cb53427dac681e7763fb9ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6beea24e3ec9466b9c4a7a6f3f672900": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6bf3f434fc244f6289eaa3c79ad7a491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaca4be07f1f40c3a8b60f82aec16d62",
            "placeholder": "​",
            "style": "IPY_MODEL_97c53cc6744c43beb509a434830088e4",
            "value": " 13.2k/? [00:00&lt;00:00, 720kB/s]"
          }
        },
        "6c7073bfe32f43678e2d4ea5e638567a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cc007c436c248debe965da1a2f84cde",
              "IPY_MODEL_543469ef680f406497315759786b2be1",
              "IPY_MODEL_b3d35c8a9dcd4d82a8f7be8913438d6c"
            ],
            "layout": "IPY_MODEL_e58aa02aba6e4cf593d24b09171a2507"
          }
        },
        "6c782cfaeb7441a8b82df67121dc0cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2bf393d922343f084f0d2f57da366e4",
            "placeholder": "​",
            "style": "IPY_MODEL_18efd71d5a7d4f4eae357a41cc1b6812",
            "value": " 190/190 [00:00&lt;00:00, 21.6kB/s]"
          }
        },
        "6c95d19381154dc98d15787b1c7c580a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fec9edad0dcc4d4d80ed16e51e514bab",
            "placeholder": "​",
            "style": "IPY_MODEL_d6da2ae12acd4c65b945db378c6f4930",
            "value": " 90.3M/90.3M [00:00&lt;00:00, 381MB/s]"
          }
        },
        "6cab9909670e4163a52a63b7b9275be1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6caf554a27e344048b1ba4eeb9e554cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34069299114d471d95ec180b2844fd9a",
            "placeholder": "​",
            "style": "IPY_MODEL_95c9d707b0374ba593461152e90d1660",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6cb4c935e02a45a886061e86524e19f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc0cfbf8d4841cea3d39d7c5ab3c93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ce58e2d9e014944b6a280c9d696ded0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cf11fc63374447ca783b50233eec628": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1190e3ab6e478985839d47a0f211a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d180428907442e095a1654b7d27b4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f78ca3482264d97a075e7273f908242",
            "placeholder": "​",
            "style": "IPY_MODEL_762969cd2c4646b89b7b05eae1e30cf6",
            "value": " 39.3k/? [00:00&lt;00:00, 3.83MB/s]"
          }
        },
        "6d63143c4c794bb1b3d9c03ffcf23296": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d84ceee84d9462699aa90d7d1a81eec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dee68e3e5fb4b8cbd5ebf8ee63e6d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e03a6a9147c143f3877c49a25c5f02a1",
              "IPY_MODEL_4e4eda429d2643fd97d6f403efbc66a0",
              "IPY_MODEL_4cf09d742e854971b283ec6b4cefc122"
            ],
            "layout": "IPY_MODEL_a1a51adc982042fe8ead05c085b6baee"
          }
        },
        "6e55d9d9c27d47a7930b996473fc6e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8a7c3db7da40a1be5dae34983d978a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eaa4a7fc562446a8e1490c91e71ad96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e8dcaa61f241f7953c12eb22f4a633",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0c95183354f406a937ec91baf47847c",
            "value": 2
          }
        },
        "6eb210f2c3dc43c89c89c959fd90038d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f2a93f8310b42a0953deac752327f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f449e8a08314ae5a98eca56bbc23e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edd3b6647ebd4f5f848e2dc037f8c3c6",
              "IPY_MODEL_6eaa4a7fc562446a8e1490c91e71ad96",
              "IPY_MODEL_89e33a2008554bf8acd8c6bdae2145b4"
            ],
            "layout": "IPY_MODEL_92961d3f66ef461a8e689a615034790a"
          }
        },
        "6f46030f8e2b4783abeca5f6be6cc69e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f52d48c620c4b4fa7632a76d59bd411": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6f5eb69733114c948a58a16ac56ebd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f6805b4575a4c85b43bc8ee093bb64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f71cb7ff318423c8e502ae4ce300d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b69cb2942b749bbafb27ea2fd2475c5",
              "IPY_MODEL_05d0627afc6c418fb2394e9a1b6955ba",
              "IPY_MODEL_b4ef449386334628b503f62c1d6004e2"
            ],
            "layout": "IPY_MODEL_a3ff196882fd428380198cfdba8a64d2"
          }
        },
        "7031ca0c7e0e42678d396db7122f91e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "703c3090a3174febbc3007a0d1ee8139": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b37c6a428042e7afc440ef347da339",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94238c0b77484bffb79c1f7827335cd0",
            "value": 1
          }
        },
        "70409302db19422faa5656683cf7a800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70669f0858dc4608a04065ef73929dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af13e5851d1d40a3a8d757fcb6558de8",
            "placeholder": "​",
            "style": "IPY_MODEL_d08cc25135004577b893153308d46b59",
            "value": " 22.9M/22.9M [00:00&lt;00:00, 204MB/s]"
          }
        },
        "70726e64583e49c9bb03fc2d089cee75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70899f30168944829be0a6b95ba3961c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70d6e987d8f847b794cd082e67c59937": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b1c2bf1de14e23b5e15daf2e8474c6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb157b8f41634e7cb2648b0e127ac1bd",
            "value": 1
          }
        },
        "70ffd8b2a7074d8ca285490054600a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7153d871d7584e8abab2e7fd3e9c818b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716ecfc982c14965bda6e8b91e15e668": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57a5b104c446439ebd360f643a788c9d",
              "IPY_MODEL_c91c7aace656455887bc8c056f49614d",
              "IPY_MODEL_2e0cacb16f694aa19661d93c3c793c63"
            ],
            "layout": "IPY_MODEL_1284189b4a724e6792ad0b456d7e4fc7"
          }
        },
        "71807425abee499aac63e56fb74e8b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7edf2f104b84e17bfdb5453e8e18373",
            "placeholder": "​",
            "style": "IPY_MODEL_70899f30168944829be0a6b95ba3961c",
            "value": "Downloading openvino_model.xml: "
          }
        },
        "71bc66c81de34f1f920d1eab33c69f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f210aafa99964807aac81d5c48834022",
            "placeholder": "​",
            "style": "IPY_MODEL_226efa4f5e014c73932d30403ddf3280",
            "value": "Downloading (…)_qint8_quantized.bin: 100%"
          }
        },
        "71d48b1031c340bb84e5aa14f183c4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71eb8ad9448d438eba902551fd8c69ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71f9dc0a6a9f4e418b81ea3a0826c8b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71fe8408fc814231b82624bba94337ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c34aa8a147bd49549ec4cf632d5f8999",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0350a9ed8f5944d1bc1a83288d2ecaa9",
            "value": 1
          }
        },
        "723a7558456f44fdb00ea74d265567d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dfd570945fc48b8b85d9ca720d5d20e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b9b80df084f47dea44be7097d146273",
            "value": 1
          }
        },
        "7247ffd7d7d740eaabca5d82df0eb122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "725d5238593f4566bbf69d07f722a16e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b0237db5444040a52b3fe259abe949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72de281e5da04fa68e3b7cf772a1cdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73160150383b4165bfce13bc1c273e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c5fef3fd8554ab99add17472ce7d7b0",
            "placeholder": "​",
            "style": "IPY_MODEL_b5361ebf7ac249c4b1842c0590550432",
            "value": " 232k/? [00:00&lt;00:00, 16.0MB/s]"
          }
        },
        "731cf3819ec742a59d7eebb40e641429": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "733083c1342549a19e60ee170c848063": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_006983e2283348df8decc3b245098a9e",
              "IPY_MODEL_d1c8aad90ab74af49d39c089c7499977",
              "IPY_MODEL_75e44fa8152b4cad85b3543db7f8f33d"
            ],
            "layout": "IPY_MODEL_45709e3fa69e4eff8dc4b4ce328eb0f5"
          }
        },
        "736e6b944baf485cbacc1b5bbfd9bbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36777f8923884efb8215d9eb3d985f14",
              "IPY_MODEL_ef0d5656fe2c4d08a228db5502e93af4",
              "IPY_MODEL_4a769323f3284e1c8ed9911a95299dd0"
            ],
            "layout": "IPY_MODEL_f89c633efea047e78e49031e6c55b694"
          }
        },
        "73853d4b10334969baad4b5e8c86fec7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b72bae7bcd45d19705a36d3ae0e50a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c3a185b51041898b14dad342b396ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74542d3c007648008320bd55e9dece00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a54ceeac73b2405683e2b141dd5d36ba",
              "IPY_MODEL_c9a08804863742ef897e7f995e22feed",
              "IPY_MODEL_7ce9a9f267ee4ee3a76f8f45b0201ab2"
            ],
            "layout": "IPY_MODEL_a4cc2a9d3f1c47d8bb9ac961ea25aaa4"
          }
        },
        "7478600a44b9414e96bda1390664a8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c94a1a4a0254e38856ed973cce006ef",
            "placeholder": "​",
            "style": "IPY_MODEL_a66ffd0b33ac4a86bdf7e854268ac420",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 192MB/s]"
          }
        },
        "751a1b476d92462ba349eb90ab9c53e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7529a697abaf47a1a051d16fff23c43f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75baf60ac515444f8a491b51c46ef3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75e44fa8152b4cad85b3543db7f8f33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500efb5040ac44a8bc693d96b86bbf18",
            "placeholder": "​",
            "style": "IPY_MODEL_825f7300f39645ae9625a7308b41cb2b",
            "value": " 1.23k/? [00:00&lt;00:00, 119kB/s]"
          }
        },
        "761e3c97bcca447496efd906754360e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "762969cd2c4646b89b7b05eae1e30cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76472b9a721140368a530273bf6c0dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76e8dcaa61f241f7953c12eb22f4a633": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7739707832fe445490158d5f77578b61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77adb0ec2a9841fe990d20d4e2ad9f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "783ae4f8af6a4ebc99d91febccf795d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_343c252921964b04a7a4c5d526e8f738",
              "IPY_MODEL_5c0832fab25e45c6859ea0806d868295",
              "IPY_MODEL_95beaed903974f8cabbce873782adc39"
            ],
            "layout": "IPY_MODEL_815a3d71498744398f5ca7e1449c0f23"
          }
        },
        "7844052c70894ab9927923f632829f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "787dde1d41714e559ef9e3788213347c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c0fc3712d7b48848253cb48d48c87f0",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59b9bf579011464199b811f70bbb4338",
            "value": 90888945
          }
        },
        "78d37f7e23e7487ea1dcee7182f16b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79085e7e53984825a78d6ae75ec59672": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792321100b9b417298c848279cfd45e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7959d64ee02843ae9f6a56daf8499c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "797ed7936a92434ab666e9769804c14d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79dd93f3e6824121a2996368413ce540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e9fb025e113438884f0edc4a8fac845",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_390db3d08ceb49fdb0ae2084f6ca8ec9",
            "value": 90888945
          }
        },
        "7a23e4409da84bf096cf64b7b7f62533": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3618cd87a74dc6b8b791b9b6f324ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a73287f752549caa8d3c100ae046786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f45c449f83c141d184163236ccb6c426",
              "IPY_MODEL_ffb0a8a71c3749b2abc3fbafeb67ac8d",
              "IPY_MODEL_572f2e53d97f4b5197b9ef44beda9d8a"
            ],
            "layout": "IPY_MODEL_bcd5db0f0cfc404a87bff2573e37c48d"
          }
        },
        "7ab465a6dc3b453c8fe2a6c7a37e16f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa44427116e4f789ef61f0aaeec76a7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db8fc5d08637491eb0a1862edc8cbc41",
            "value": 2
          }
        },
        "7abb3c1c74ef4f0eb9447fcca47d5078": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba09e40088314f3895ed5d987dab0fc0",
            "placeholder": "​",
            "style": "IPY_MODEL_17ec9fba5f5548378f3f7bf1277a970b",
            "value": "Downloading README.md: "
          }
        },
        "7abbed4cfd9047458cef4d4fe556675e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ae2eae1eb7e441fb55a54522b771a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7af50139dee3421b94826d4d9c2a2a03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b2c18055ca449bdbe55ecb6a6406f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bba393b34594e45987eb6e909b28cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bdcc9e737be44a4ac5a5c412f5009bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c27afb10e294551a87faf613482960d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b0066ab33a471d9019dfd2bf481006",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_566840304c9b40c6a0ae43bbdcc563d7",
            "value": 116
          }
        },
        "7c355b31995b47728b967637688d8ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c45555a7cf047e887dfb74321b3a00e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df3d02f826914a1ab61fc790de19a26c",
            "value": 1
          }
        },
        "7c95503eaacb4822831de884d58e5d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb4c935e02a45a886061e86524e19f6",
            "max": 22933664,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55850c6dfd554b9b89cf7bd65663212d",
            "value": 22933664
          }
        },
        "7c9992ed09774ed3a923d53447247c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e018aa9759c4a61a783480bfbfd553f",
            "placeholder": "​",
            "style": "IPY_MODEL_8e32b322c8f84a71857d71c62f745984",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7cb451f16a3243a2a6d4f57c0c7908df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d13f6764bf343bea7d6ff1d2e1b4dcf",
              "IPY_MODEL_5e2d4634930147939df1e200189823df",
              "IPY_MODEL_2d504c24293f4db3a239cf6fa4b06d52"
            ],
            "layout": "IPY_MODEL_3b7c506254cf4055871f9c05e64a049e"
          }
        },
        "7cd89697a0234c4cbe1119b78a827517": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce9a9f267ee4ee3a76f8f45b0201ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f46030f8e2b4783abeca5f6be6cc69e",
            "placeholder": "​",
            "style": "IPY_MODEL_3a91b1b5b45e412eb57439eddce5b6dc",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 256MB/s]"
          }
        },
        "7d08c4ab70a94ddeaad6e541ea07d696": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4abd00291eb9450dbddc550b4cf9879d",
            "placeholder": "​",
            "style": "IPY_MODEL_3b1fdc1ddfad4f7c98eeb409171ccafd",
            "value": "Downloading openvino_model.bin: 100%"
          }
        },
        "7d13f6764bf343bea7d6ff1d2e1b4dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fffd1b1b97564479a3600e524ed97e90",
            "placeholder": "​",
            "style": "IPY_MODEL_5c2938c29bd94735a6a8c88afcdd9f6c",
            "value": "Downloading (…)nce_bert_config.json: 100%"
          }
        },
        "7d3c3b666e4d42e0826aeaecbf604197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d4939a31c62489bb2e8f4111c101ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d561285cb8a427988ceca99d932650e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dd03a7932e84f1eaf45c9e95d77bc51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ddd082677ce42dd86ba5787af78c0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d194a55ba688467da7a0db045be7305f",
            "placeholder": "​",
            "style": "IPY_MODEL_9a2d0142f19349c9ae215f136cec5277",
            "value": "Downloading generation_config.json: 100%"
          }
        },
        "7e12a0bb9b8d494597b5edfe8a197524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e4eae7672864ffa8752daa1d8bb2b03",
              "IPY_MODEL_94a3a90a469048f7a2519f6dc5a03339",
              "IPY_MODEL_d9af2c59e2cd4132be70c579cb4eb87c"
            ],
            "layout": "IPY_MODEL_2ff191213a1b490aaaf013ade48a38a1"
          }
        },
        "7e1b969e780c47d2b263aec4479da1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e390a4a7e9f444e80ce7f7bd8bfa7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7e45b7d0619b4d72ae23d4fa875c59f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4eae7672864ffa8752daa1d8bb2b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3046ddbe60724c8384c7da1d54134ce7",
            "placeholder": "​",
            "style": "IPY_MODEL_329ac193ee214fcca82fa936f0693b80",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7e5943b15ac045599351aef1f1a1a47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e7b7fba04384ba491431b73fe4ad578": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95536468b3f0493bb41add69fbfce20c",
              "IPY_MODEL_2218a1ab3d4746f1aee860dc28736e40",
              "IPY_MODEL_1a6e96b498a9469fbfff24aff4be7210"
            ],
            "layout": "IPY_MODEL_bbef7a3eba2f4b9da001ba9ed20d3fd2"
          }
        },
        "7e9fb025e113438884f0edc4a8fac845": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef8e967a56d41b0bed16f6be231d62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f0e7307cd354628b87d029757125741": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f35caf43b1f48f0a2c02ff7af6cbeba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f3bcfda0c9846df868fcd2eee7b756d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f745822f8364a789f747e2918a9dca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d93a4635e0054cac8488f9b1dad79add",
              "IPY_MODEL_f44f5689aa6443b7baf7592c7654e3df",
              "IPY_MODEL_73160150383b4165bfce13bc1c273e83"
            ],
            "layout": "IPY_MODEL_d69185aff09d4f9aa1130547755a891f"
          }
        },
        "7f8447f023fd4da1afdcca72f590bc0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb59f7d333f4ec88d444021b3534fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_464b32269e0c4a40a56ea223c6c18e53",
            "max": 9976701592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e69ee0ea123143f18a60ab620703ffea",
            "value": 9976701592
          }
        },
        "7fd11956c43d483480e9e4716470d295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fef97d46d614d868575b068f4419191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff4a524f9394f799877985188686c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8002ccb179ba4bd7a90da6054343326c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800abf389bd042c9bd37272f0580b858": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c61b12340974cd780ec35c9d6376370",
            "placeholder": "​",
            "style": "IPY_MODEL_2506f7ff62f34694945d0d044033007a",
            "value": "Downloading (…)nce_bert_config.json: 100%"
          }
        },
        "80336a35e8b34d5ca43005314b7f8f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "807409b68b3a4350947653b9b5c9ed71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6664aca9bc8443ec8c7425541ba2c72a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3ced9cf432d4e6cb76863a7b78b645f",
            "value": 2
          }
        },
        "80860bf6bd6045109e03dbd3e329213a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "808d5aab68054d74945a08abe54048ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "808ee969da34465b8d6107547e4ed7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80a39524b9204b91ab800861a4200d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f61a87ef87475b9cdbf54d915f03af",
            "max": 90326566,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e95e6163de9d4bd2af02f6e14140a648",
            "value": 90326566
          }
        },
        "81549c298b9f4ba8944adb13d80eb0b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "815a3d71498744398f5ca7e1449c0f23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816be69662324de78e47781ffef30821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81875e1af14347ecb19b8fd2a33bb885": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8194e30d81ec4cf6bd0de360a72ec9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba243a5e6b54abab0ac3d164cd81ab1",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2158488626d4208ac7ad75aa1e32287",
            "value": 612
          }
        },
        "8211fd05644d4b16af73b5a175570f64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82243f048b364fd883616c1f5382ba6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "825f7300f39645ae9625a7308b41cb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "828b34a3b82d4d8794241e76fe75d1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83364bc38a694466bc5e03140cfaaf38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8345f09d1ca641f5b79ce585ee7e82ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834809a1a8934fb0a4a3480329f96099": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836e9cadc9134dcb984085cf6f2aad89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65b17955bc594e73911afe8f4a50d62c",
            "placeholder": "​",
            "style": "IPY_MODEL_6d1190e3ab6e478985839d47a0f211a7",
            "value": " 90.3M/90.3M [00:02&lt;00:00, 32.9MB/s]"
          }
        },
        "83c95f06cd834517b51e463735e70481": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "83cafcac35354ee7be49f86e9e8fbf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9708519f08334dd2b3aba1a51df69ece",
              "IPY_MODEL_1e63608ad9624f8e8fe9a4fc2d519a7a",
              "IPY_MODEL_3c759dccaa1048f38ba7560418ee2f00"
            ],
            "layout": "IPY_MODEL_e33bb200e8b142f0855e5dbd0c64a803"
          }
        },
        "842f7ad81b4b4d34a468ec2c7bc593af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa1b85075c1842b0ad5242383b6f6304",
            "placeholder": "​",
            "style": "IPY_MODEL_5686639b6e994b14bf6170a20e279c89",
            "value": " 350/350 [00:00&lt;00:00, 37.1kB/s]"
          }
        },
        "843e055eb2dd497387801623a769eaaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2888991785d84433950702ad287ee691",
              "IPY_MODEL_db01ae3488b74fbf9e6b4abca0d3d59c",
              "IPY_MODEL_c3a89fdea1374ca689e9edb88026ed48"
            ],
            "layout": "IPY_MODEL_606337b912264bb7ba7cc2e822af74c3"
          }
        },
        "84d8a2accea04fa28b53d94f103cbcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48635a6a24240e3a431653250119583",
            "placeholder": "​",
            "style": "IPY_MODEL_d79d1c155aca49448eb59ca6f870a7fc",
            "value": " 2/2 [00:42&lt;00:00, 42.44s/it]"
          }
        },
        "84ddfd7f0a89497c9ffea2dcd75f30f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f61bc3cfb940f78ef7dffbb068f3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761e3c97bcca447496efd906754360e9",
            "placeholder": "​",
            "style": "IPY_MODEL_b8dd59450c77480b917c0c886182f5dc",
            "value": "Downloading modules.json: 100%"
          }
        },
        "8503c829903b4fb49939a62f1882f997": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b6f08c755fc4d8aaeed30107abf1a74",
            "placeholder": "​",
            "style": "IPY_MODEL_1e15f984cdd443d8bd7f64e23b7de14f",
            "value": " 2/2 [00:52&lt;00:00, 52.20s/it]"
          }
        },
        "850d9511decb4716a414782063937d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac7cd1df41174ad799eeccef1429d6cb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a725cae7f2e44f5f90d525ddc791d39f",
            "value": 2
          }
        },
        "8523de1b618a4361ac5572df545f3c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8533caf3523a42f3bdcf434882fb8977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "85704f23d84b4d658a7979c87c7f168f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "860ddec7a510474d99552521faa297cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cab78e64c294f3b99946d9cd380d9df",
              "IPY_MODEL_afdc7c5dc95b4b1a9b2135154ea9f9db",
              "IPY_MODEL_6bf3f434fc244f6289eaa3c79ad7a491"
            ],
            "layout": "IPY_MODEL_92e7960c3fc44fc98c31cdb2a7dbf857"
          }
        },
        "86131aa6e8ce430194a859c8eeadfeb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8614c733d1084fb5a9930834f7aa2ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b10c735ee44eb1b74ff39c9f5937ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "87323ba357e3416aa83b710fc972f236": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7844052c70894ab9927923f632829f1e",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3293a821ec94b0f8650455b324aa3cb",
            "value": 116
          }
        },
        "878c42bfaae64315b1f04b10691073d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d63143c4c794bb1b3d9c03ffcf23296",
            "placeholder": "​",
            "style": "IPY_MODEL_cc9e5a059c4f4333b9045117d2aa586a",
            "value": "Downloading model_O4.onnx: 100%"
          }
        },
        "87b405bd85094656aa2509c03f4f5d19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d943c837c2412cbdef9d39625411e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58a290facd204df3b8cbb6d2d3fd6457",
              "IPY_MODEL_af82c5fc79ad40e6972d33aa75f4d54a",
              "IPY_MODEL_e902067b2be445ebab16abbad4732a92"
            ],
            "layout": "IPY_MODEL_59be65899ba347dc9142115b4b67eb77"
          }
        },
        "88051db9debc47c7be8240ad62f9adc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8823ccf5e72a44fab7c915343767ff67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8847c23d1bc442e1a06d6dd55de758c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "886b5e318b224e8f900aef060cb2933c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee4609a9e8f24d37b05613ffecbe81af",
              "IPY_MODEL_e96f864d01cb4157b0ed9839be66df8d",
              "IPY_MODEL_42ae91e5fc8742598ee4e87f31eb78ba"
            ],
            "layout": "IPY_MODEL_c204dd2a307a4f14b83f78b566db76b4"
          }
        },
        "889ce5cd1d814240ae2b0ce6c0a52b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c2a547748654e08aa0b99d977516986",
              "IPY_MODEL_9623e48730cd4f22b534ec278440ea66",
              "IPY_MODEL_1cc95ce9969b4a5b9d26578410342c7a"
            ],
            "layout": "IPY_MODEL_71f9dc0a6a9f4e418b81ea3a0826c8b0"
          }
        },
        "890af1b470284e3bab45e041978a86e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6cdc9172f80400dab1d7074738caeb5",
            "placeholder": "​",
            "style": "IPY_MODEL_2fa77fbc9ba9417882562ee5941d87f7",
            "value": " 39.3k/? [00:00&lt;00:00, 712kB/s]"
          }
        },
        "890ef333e80140568fbaf6ddaf30f50d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8916cab077c940cab463ce2584d2af2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "892effe1e0c3478e8dff05214991b4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54114fd45444bc28167e2b653113fcc",
            "placeholder": "​",
            "style": "IPY_MODEL_86131aa6e8ce430194a859c8eeadfeb2",
            "value": "Downloading tokenizer_config.json: "
          }
        },
        "89443b41d5db4be18d9e8850c65ba8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89808fb12ce64361aad08870c7fb076b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89a1446c35ae422b8fcb095307d1145d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b792e3313744389effe6f0abfb8a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_8916cab077c940cab463ce2584d2af2d",
            "value": "Downloading model_O3.onnx: 100%"
          }
        },
        "89ba5b0e3dc64efb84e74d5031963c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89bb26f685044d6ba6ab09369c2d915a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d745d00ff84f3fa59a24a2f0a424d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89de784100844ec7a74f5c43efad4d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89e33a2008554bf8acd8c6bdae2145b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e318fd50a9459f8c84136659e991b4",
            "placeholder": "​",
            "style": "IPY_MODEL_113f01d7ad9a4ff79aeec8bbf68176d2",
            "value": " 2/2 [01:06&lt;00:00, 29.90s/it]"
          }
        },
        "8a0385004be349ed950da812260f5f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a41fa3c7f2d47b78a55f27bc28e9b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ebdf6c5a99e4638a2da4026bf82c275",
            "placeholder": "​",
            "style": "IPY_MODEL_cf432bb484cc4615bcfa631fb6cd373d",
            "value": "Downloading tokenizer.json: "
          }
        },
        "8a435c6552424d4cb418dc20ffc6a60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71807425abee499aac63e56fb74e8b4a",
              "IPY_MODEL_925692e4a0f8448f891d7e76e4bd4d19",
              "IPY_MODEL_62a92922ad8e4f1d838dbcf9599c9af7"
            ],
            "layout": "IPY_MODEL_d75b71fc416d4b14bf881ec2ea2f6625"
          }
        },
        "8a4be78da4e3413bbcd0e4645f9b4213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6caf554a27e344048b1ba4eeb9e554cb",
              "IPY_MODEL_af551d32608b494885650d16479ec4bf",
              "IPY_MODEL_576d552a4dac4aa187c82a848318bfa5"
            ],
            "layout": "IPY_MODEL_437df8da1c0e4fb692a94fb4451fe8b3"
          }
        },
        "8a62588975df42c9978eb92d9100ac1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8aa68c701e2e497e8f4ddc005bbc02dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aade0326d344d029813b5fe6f4fca3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac91f09e4754e83848a8e2040b3798d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4dc0bb1a1d44787813c62a579ef8245",
              "IPY_MODEL_807409b68b3a4350947653b9b5c9ed71",
              "IPY_MODEL_36d464130f7041c4ba782827c5b2824b"
            ],
            "layout": "IPY_MODEL_1a48c5bc740a4c4bbe795deb33484e37"
          }
        },
        "8b0b6e16f8dc495baf746059b062b936": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0bced691b24eee8537bf2ceb00a838": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b6f08c755fc4d8aaeed30107abf1a74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b96ad475f15422989be6b1af92974ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bb8cb42f69e43d19b7597139e16f945": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bdd167f55b54badad2c66a09aec83fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e589f888e00d4b08b19ae0af71da25c4",
            "placeholder": "​",
            "style": "IPY_MODEL_69041b87e25143e59711779525aca6d0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8bdebcdf79b5416ab353b4c7f66a21e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c3dfe8015634ee9a65e32fe9a18da12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c4fe33b3d394774b95cacad4fafc474": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da999512828443b9acd1dcfa4119c84",
            "placeholder": "​",
            "style": "IPY_MODEL_975b339d5f5b4949bcaf04325baadb8f",
            "value": "Downloading (…)of-00002.safetensors: 100%"
          }
        },
        "8c5fef3fd8554ab99add17472ce7d7b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c61b12340974cd780ec35c9d6376370": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9d86afca934fd298a224b812747f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cc30dcb96004b0eb49a7b0eb7254a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b10c735ee44eb1b74ff39c9f5937ed",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45d99908b9cf4297a3b49d3a623fae17",
            "value": 1
          }
        },
        "8d383b22fae14e08b5a3dff84ab987ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_683e4d9a973c4c08b5f14f7ebafd5bbb",
              "IPY_MODEL_71fe8408fc814231b82624bba94337ef",
              "IPY_MODEL_e5361e90811b4f94b498ca3ddc4a4614"
            ],
            "layout": "IPY_MODEL_4e3ecd49555d4440893b44fe5f4eb7ca"
          }
        },
        "8d6124651d574631969bfa4ed2475fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6512af48d90248aea0820c0fceacb80f",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c42cc8c8c54039ba0c0db575ba2ba7",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "8d8b709b6cb847f7817ecdd3db63cae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_663a136650014618999dd0850ebce86f",
            "placeholder": "​",
            "style": "IPY_MODEL_07da8bb58adf4b45bb8272fa49ac5fa1",
            "value": " 90.3M/90.3M [00:00&lt;00:00, 233MB/s]"
          }
        },
        "8d92e6bd9ab04c549b59851fab2d9920": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da366a6e93d492985fd79ccf56a4bec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8dc7025e871c4c1f85424896e6054015": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dfe9997b94d4ebdbdc859e12f65bb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80afb8ae6ec4e4391d2e4858353494f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bba852c316b48e4b754f115badf88f6",
            "value": 1
          }
        },
        "8e32b322c8f84a71857d71c62f745984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e74a7d3fc8340d787d18341c7a0f6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_816be69662324de78e47781ffef30821",
            "placeholder": "​",
            "style": "IPY_MODEL_fa3d4b8ebdef4d38aad4807306fb0d6a",
            "value": "Downloading model_quint8_avx2.onnx: 100%"
          }
        },
        "8ebdf6c5a99e4638a2da4026bf82c275": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec2f7993da54eb4a9e7391c1795f357": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec98a177e27463f92e013a923ebd4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f16d510c2544051bdc807ad850d3e85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f356c5f092e4882b67fa217ed8c7e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22729dea76084b1a8e4081a53f72df91",
            "max": 90405214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49539475661e421cb73c7cf4e8e79c6a",
            "value": 90405214
          }
        },
        "8f5949efdf56409c8b0fab5da676ffb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f65f914e8334809b66008d8bf28724a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f766e1c1b9f4c558bb3320f4401ce35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686545a18256476f97e73cf2f6f278c9",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab07433386d54fe2a740aac852347aab",
            "value": 612
          }
        },
        "8f9f6ed6063242a58cdfff65eda11f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fb303fa79834a93ad65227011bc688f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fb4f62bffc941af8c2fe4bf44b03379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d073040d10694ed49276313135ab9d7a",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ee8296a86f74949bd667ab4657d8b72",
            "value": 349
          }
        },
        "8fd950ed089f499fa9238b2c8dbe3000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9015fab762b543bd9a28e7435ae6e977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "902f5996ab184423975c6617e939f68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae0f5fec869148cdafe90f2c221562c6",
              "IPY_MODEL_b3723a12e6554ec6ae9d3cfea1b79a83",
              "IPY_MODEL_df817a5f7c8f45d2929eebec6bcf26fe"
            ],
            "layout": "IPY_MODEL_0289266acd9644c5b372443d25685121"
          }
        },
        "9075b3075fe8428f9a5c89336c291127": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "907998058c394d3a968da216b1b2cb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a4d0c7c2c54b74be80002d81590e48",
            "placeholder": "​",
            "style": "IPY_MODEL_dec0127e01e54096b2c0b8395e990c02",
            "value": "Downloading README.md: "
          }
        },
        "908394de664a40fcb75ef67518af901e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb210f2c3dc43c89c89c959fd90038d",
            "placeholder": "​",
            "style": "IPY_MODEL_0e79192245444dcbafa8eef76329613d",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 220MB/s]"
          }
        },
        "909c3d22969b4f30bd55a7091f01a602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87b405bd85094656aa2509c03f4f5d19",
            "placeholder": "​",
            "style": "IPY_MODEL_53f0b82f1eec484886c1236f1b56cb25",
            "value": " 112/112 [00:00&lt;00:00, 13.8kB/s]"
          }
        },
        "90c6c4a43903460db8d8309b84945f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90eee82806684434ab5afbe3f57388bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91577fcae4184dfe9ac578ebfe164316": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91cb931cf6444caea93b732391e470b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "925692e4a0f8448f891d7e76e4bd4d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0d6105c31d495a8920f17ae56140fd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e8a7c3db7da40a1be5dae34983d978a",
            "value": 1
          }
        },
        "92961d3f66ef461a8e689a615034790a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e7960c3fc44fc98c31cdb2a7dbf857": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930ae74d94ff4aa99652fed0ece2db5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9338023e38b54b1f93acfda71b922ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3cb55c1cfde4a06ba1b5bb3c0d8d1c4",
              "IPY_MODEL_1c5cf2f8a2e94fafb8a4e06d12187311",
              "IPY_MODEL_b7f2df11c1414ef0b3584f2d204db68d"
            ],
            "layout": "IPY_MODEL_380edf7f24fa4de29a2f25d37d809aad"
          }
        },
        "933c26c05bec46d79833d49d2df75bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "939f1df069354a649a152e43f455e496": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc3119051b449339ad4cb9c41de746a",
            "placeholder": "​",
            "style": "IPY_MODEL_26adbb7f9f024c7aae2edf69f5d65501",
            "value": " 90.3M/90.3M [00:00&lt;00:00, 282MB/s]"
          }
        },
        "93eaf5ec5e384428ad283fa2e5e2a7d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94146c327cce471b867c01e6607528a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94238c0b77484bffb79c1f7827335cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "944c18536cc9460e992a663ca5a7fe0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9488384bf67948c2a9670ec586787b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_399513d2399143958f03a1f9628c0e0f",
              "IPY_MODEL_688c9f0efae94ee29e57dd29e86cc1d6",
              "IPY_MODEL_c4fc6d88e77c4a35b58e1f75629aee30"
            ],
            "layout": "IPY_MODEL_7f8447f023fd4da1afdcca72f590bc0a"
          }
        },
        "94a3a90a469048f7a2519f6dc5a03339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6fbf61661f44b9087a15a8f7db47135",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e42864f0fe9f418e86c1b1e4ab804912",
            "value": 2
          }
        },
        "94ba8ad711814a0c826ff2de25cc3d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bde08b27f184040b3de094ebb3e7f0b",
            "placeholder": "​",
            "style": "IPY_MODEL_7fd11956c43d483480e9e4716470d295",
            "value": " 1.59k/? [00:00&lt;00:00, 145kB/s]"
          }
        },
        "94ff2084abbc4cac8344ecc4a1baac68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "94ff97bd00954662b2a82bf1e989157d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d452a26332f41a7b66b82d3c85c0821",
            "placeholder": "​",
            "style": "IPY_MODEL_0912053bf7154e6f96b6e65aca1a1f65",
            "value": "Downloading modules.json: 100%"
          }
        },
        "95387ea88a41433b91f919e37a2beeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_063dd3c9b7154c2b86095266a52c94ac",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e5943b15ac045599351aef1f1a1a47e",
            "value": 2
          }
        },
        "9543f9fbdcc34a64b177a601021d9299": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9549580fc33f4444b07c708ce8821625": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95536468b3f0493bb41add69fbfce20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fef97d46d614d868575b068f4419191",
            "placeholder": "​",
            "style": "IPY_MODEL_7e45b7d0619b4d72ae23d4fa875c59f5",
            "value": "Downloading model_O4.onnx: 100%"
          }
        },
        "9562d2e0fa054e75ab9bdc654e5a98fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95beaed903974f8cabbce873782adc39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_475bd4a079a84878a0b43accedf931e9",
            "placeholder": "​",
            "style": "IPY_MODEL_e6fb8361ff5d401bb49d449872742502",
            "value": " 39.3k/? [00:00&lt;00:00, 3.55MB/s]"
          }
        },
        "95c9d707b0374ba593461152e90d1660": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95f4b9e67e3c4f7cb65b4497fd328e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95f61a87ef87475b9cdbf54d915f03af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "960be35de43b46e7a3dd4b564d404515": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a0c0dc86aa14b4eb07586f6fa6c3b7c",
              "IPY_MODEL_7c355b31995b47728b967637688d8ae6",
              "IPY_MODEL_e9fb77a2f2364045b89c39d25314210a"
            ],
            "layout": "IPY_MODEL_b7661b91ca9c4bdebf3e162d8ff82056"
          }
        },
        "960ed08742294f0c86b7cb4bdc84cac3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9614fb1eb86644269802498db026a191": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e8a17077f464ae890236a0985b17d0a",
            "max": 90326566,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28ea88de83bc4973ba23fb0c1c3c3ded",
            "value": 90326566
          }
        },
        "961858920d1c4468a92c06fddcd82654": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9623e48730cd4f22b534ec278440ea66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa66b87e90d44369075f3016ced2301",
            "max": 9976701592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03c39b0bc0f844f9af35ae8fb9711483",
            "value": 9976701592
          }
        },
        "962d8adef08244d8a7c2f8af9b111c39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963744ca2e244e6ba4a6f753e6e35848": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96488210acde43e6a30928e94897e627": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e518e2430e842e98a3c54d5960eefe1",
            "placeholder": "​",
            "style": "IPY_MODEL_e1b4036b291a4a3b9ad9f110ebf03946",
            "value": " 2/2 [03:02&lt;00:00, 82.89s/it]"
          }
        },
        "9708519f08334dd2b3aba1a51df69ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e954bf7c16e043cfb611531b47a4cdd3",
            "placeholder": "​",
            "style": "IPY_MODEL_72de281e5da04fa68e3b7cf772a1cdbf",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "9721d6dfab9d42b8bff850e36961f22b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "974f2422758f40749fdf082c77ab8a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "975b339d5f5b4949bcaf04325baadb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97b865cd42284ff2a11a93e9ad2acfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c53cc6744c43beb509a434830088e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97d5efa75ab9412e90387c7fa2e2a03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ba57ddb56f04301bfc45b73f70f1335",
              "IPY_MODEL_4ac27f54421d4730ab0c2f139eaacd5c",
              "IPY_MODEL_685b1c66e7904c5aa35237270363ccec"
            ],
            "layout": "IPY_MODEL_db38d6004098448d94f6a02e3b59a670"
          }
        },
        "97e5d127819d41e8919640569b6e65f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97eb4648fae04213ab41d97a5fd97d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c444637c4e4adc9ce25f14ab356b97",
            "placeholder": "​",
            "style": "IPY_MODEL_6f2a93f8310b42a0953deac752327f76",
            "value": "Downloading openvino_model.xml: "
          }
        },
        "9879bb312a8f473db6a2c3d0f7b7d591": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e92ae0b68b1f4793abe203769cbd212b",
              "IPY_MODEL_1038f092afe74b6caee07ff39dda54ed",
              "IPY_MODEL_909c3d22969b4f30bd55a7091f01a602"
            ],
            "layout": "IPY_MODEL_84ddfd7f0a89497c9ffea2dcd75f30f7"
          }
        },
        "98826e88b1a5420e87db574ee849fa68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9898a9ca5e6c4b74a304a5d5a9ee27b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c5226338df4ffab441b3272c85cbeb",
            "placeholder": "​",
            "style": "IPY_MODEL_d398bdcf5b624bceb3aa0c54ad0060f9",
            "value": "Downloading (…)_qint8_quantized.xml: "
          }
        },
        "98a013ed830a4243b2496cdfc263e016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7abbed4cfd9047458cef4d4fe556675e",
            "placeholder": "​",
            "style": "IPY_MODEL_dcc1adfd3f2d4947ac7c16a67fc28048",
            "value": "Downloading generation_config.json: 100%"
          }
        },
        "999c34534fb84a34b038fb3ed5b164fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5efdac5590c4c038ca3c3e124d26244",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c010c51d57fa4c51982171c86c0dce6e",
            "value": 112
          }
        },
        "99bbd82b8a3e40cfa63a36ba9ea7eed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5d0710b08744963b30911b07fede59f",
            "placeholder": "​",
            "style": "IPY_MODEL_a254cf227f0943c29ac18aa3db8ed644",
            "value": "Downloading model_O2.onnx: 100%"
          }
        },
        "99c3f6923d9343fca47e09071a81ba20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99d0d6d99a1d4a1196ee947a858b98b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99f915f64314496ca86ea825016c6fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a0a865a646f4acaada044d13e3625a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a1b17557b5d49bb9f029fd598a404ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a22f76a484f42a594e33489c3417b06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2d0142f19349c9ae215f136cec5277": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a341371b2cc4686883010155592712b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf35f3e76f7a4e7ebb41836a58839a1e",
            "placeholder": "​",
            "style": "IPY_MODEL_da39fc9483cd4005b7645a43c1f601f6",
            "value": " 13.2k/? [00:00&lt;00:00, 1.54MB/s]"
          }
        },
        "9a60254eca3248b5ac66ef9869c93431": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84f61bc3cfb940f78ef7dffbb068f3d4",
              "IPY_MODEL_8fb4f62bffc941af8c2fe4bf44b03379",
              "IPY_MODEL_9f6964a7796f41abbd299e66207faef8"
            ],
            "layout": "IPY_MODEL_40416307e5004aecae064b6ac9af2a37"
          }
        },
        "9a6277dd7972411aa5c005a6238d67a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a66f1e36cb44883918363d338c73a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a9f8aa5cfd04d09a789493a14508bab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aae2bc1cd4540a69460ce54bb2fa63c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af6b6d434af4e51a684b9431b085c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12fbaae50e1948f2b3f384498cfa7f1d",
            "placeholder": "​",
            "style": "IPY_MODEL_72b0237db5444040a52b3fe259abe949",
            "value": " 2/2 [01:20&lt;00:00, 37.25s/it]"
          }
        },
        "9afe8bec4a2348868a64ab35a0406964": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b562496342a242dba17bd5466500db01",
            "max": 22933664,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4394b606971409c8b7776feb3a3d311",
            "value": 22933664
          }
        },
        "9b4bb652ce13426184eb69a00f4e8787": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7eb58fce57f48d1baee600b80b64f3b",
            "placeholder": "​",
            "style": "IPY_MODEL_7f0e7307cd354628b87d029757125741",
            "value": " 3.50G/3.50G [00:43&lt;00:00, 79.6MB/s]"
          }
        },
        "9b4bf2eef3cf48d6ad89cb3c2ae44d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b69cb2942b749bbafb27ea2fd2475c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be2cac4b1b4e4343ad0ee0fe88fd7fe8",
            "placeholder": "​",
            "style": "IPY_MODEL_317b1c13bb4049b6ad9cb6d43e4f5dd3",
            "value": "Downloading tokenizer.model: 100%"
          }
        },
        "9bd882b92f1a48988e733ee91d64f8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8533caf3523a42f3bdcf434882fb8977",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474b6ed46e2b477497257702c1ca3801",
            "value": 1
          }
        },
        "9bf149682077465182b85fd87f23922d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bf58fb4838148ef841e617234487182": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c10a268b45d4312b50b4f6cda7e5e69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9c1d8ea4db6746d49ecbb38289c6926c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c2a4a5f52b54c1ca758090684f27af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ef2704b02e24e75bc437e3bd14e42ec",
            "placeholder": "​",
            "style": "IPY_MODEL_d2b3bf36a32b4d30bf7b077e28c9a974",
            "value": "Downloading (…)el_qint8_avx512.onnx: 100%"
          }
        },
        "9c45555a7cf047e887dfb74321b3a00e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9c6156e0af9f4309b116281761e2ea5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b79614345144b40a73436f909f1e4ef",
              "IPY_MODEL_fa5c95af95434f689ab197e9948822da",
              "IPY_MODEL_a894fe12b637441cbc5c55a030e820a1"
            ],
            "layout": "IPY_MODEL_e65787c746d444a3bd83a76161cd4231"
          }
        },
        "9cb139db06744566ab0117c203410779": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8da366a6e93d492985fd79ccf56a4bec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe41ec0ba2c744cda207131bff468694",
            "value": 1
          }
        },
        "9cc6cba5aeec44f299173aac2954190f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cca97c6ff0b4972beb76ac1e3ded196": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d0788d7fdba4feaa23a2535ba1ff584": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4098470dc04fe08c00bcbb057ee3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1007687649a4dd5936de6da9ef79ec2",
            "placeholder": "​",
            "style": "IPY_MODEL_ed37bfc8a4e64ea296ba8801ae0a2265",
            "value": "Downloading (…)el_qint8_avx512.onnx: 100%"
          }
        },
        "9d40cb1b2664451d8a6d00035918381e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2cde23aa6134265a0986cebde88c68a",
            "placeholder": "​",
            "style": "IPY_MODEL_0e94ce04526c4da38051b66bee51634c",
            "value": " 466k/? [00:00&lt;00:00, 20.8MB/s]"
          }
        },
        "9d8539bacda0431a88034e1e321b6ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d9c2bc1c0b24981ae21b26a7a27f14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a7ef1dfa53425cabbbacdc40261ae7",
            "placeholder": "​",
            "style": "IPY_MODEL_314c193307024550b7fed8f34351e2f1",
            "value": " 500k/500k [00:00&lt;00:00, 43.2MB/s]"
          }
        },
        "9daaba1833cf481c87f7f2fac4e96b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e018aa9759c4a61a783480bfbfd553f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e2118042c734316877dcc65ab0608cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e226eeb21d44f6783df0bf237fe2ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa68c701e2e497e8f4ddc005bbc02dc",
            "placeholder": "​",
            "style": "IPY_MODEL_cd36f89ac1964d2faacacbcb4c46a1cf",
            "value": " 116/116 [00:00&lt;00:00, 13.8kB/s]"
          }
        },
        "9e83d80b293a410f85fc6ce6a6c265c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea11c066c454c3f9e3dc145cd1db969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ec23ac822dd40bbbc87aba60d0765db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eda247c525341e09534c201b76480a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f01be8c1c754841a7ac8413ec33ca4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef02eccba38b44d291b6aaddb154c31c",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a66f1e36cb44883918363d338c73a38",
            "value": 23026053
          }
        },
        "9f02c626e14341bfae840dec5f606c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0d6105c31d495a8920f17ae56140fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9f6964a7796f41abbd299e66207faef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f16d510c2544051bdc807ad850d3e85",
            "placeholder": "​",
            "style": "IPY_MODEL_df1b98b2ce36481a82ee632e05d1ba87",
            "value": " 349/349 [00:00&lt;00:00, 42.9kB/s]"
          }
        },
        "9f6ef1f7df314bc1b7a5c004b6d9d334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f79bc6b949340f5b9a3a7d497613640": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f7e8db5838d4ae3acbdecf6b11b73dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff4fa88d21544a0959b52eea3cdb1ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a08543921ba6465b96f5bf2e9c5be06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0c42cc8c8c54039ba0c0db575ba2ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0f261d9d7dc4696a3797b8f64450019": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8211fd05644d4b16af73b5a175570f64",
            "placeholder": "​",
            "style": "IPY_MODEL_c35647a002cf45609356d7114f20034f",
            "value": " 90.3M/90.3M [00:00&lt;00:00, 298MB/s]"
          }
        },
        "a1007687649a4dd5936de6da9ef79ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17976ebcf2e492c9d8346549c0d78a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a1a51adc982042fe8ead05c085b6baee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d082ef4b8446809ad2235500d2bc64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d8ff2b389b4a1f81625b679d4a6b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a23e4409da84bf096cf64b7b7f62533",
            "max": 3500425616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_104b02932c134da783c82aff99b9b908",
            "value": 3500425616
          }
        },
        "a20276f34e05456fb077e47900d9e327": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a21702b8b0f14f6fa8aed65580d4b19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_411fc75d76cb43948cd667afc23c2122",
            "placeholder": "​",
            "style": "IPY_MODEL_aa6d829bb45043ed80c88f1f435caa99",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "a218a6064fc84c7e85fd72a4ec1d0f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0715facc91d46d4bd8425cb5e85f180",
            "max": 23046789,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73c3a185b51041898b14dad342b396ca",
            "value": 23046789
          }
        },
        "a24ca1cd569c4c11a98e138ce756ebb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7e88840efb94b38a51ebbfe9a8c9df8",
              "IPY_MODEL_f51d94fe01ba47a08b9df8b64c3f0639",
              "IPY_MODEL_08ec5ea1fa0d414ab4ac46ac5d5a5de4"
            ],
            "layout": "IPY_MODEL_91577fcae4184dfe9ac578ebfe164316"
          }
        },
        "a254cf227f0943c29ac18aa3db8ed644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a269825541dc4c198a420cdef61f30f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9562d2e0fa054e75ab9bdc654e5a98fa",
            "placeholder": "​",
            "style": "IPY_MODEL_8f65f914e8334809b66008d8bf28724a",
            "value": " 368k/? [00:00&lt;00:00, 29.2MB/s]"
          }
        },
        "a27f830e5e754451956fd907b2356114": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2893e31fe114666bf9d05489147cc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc806811f7f46a3a5e7d5fd63aaad82",
            "max": 22933664,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aec5135b6af04f1cbd2d3d629967d279",
            "value": 22933664
          }
        },
        "a2dafb59428e4e83868b98e8a5f2889a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0996c9bfc8c4ff8aee1731e4d8df14c",
              "IPY_MODEL_9cb139db06744566ab0117c203410779",
              "IPY_MODEL_a269825541dc4c198a420cdef61f30f7"
            ],
            "layout": "IPY_MODEL_ee6126e14e474bd0811f46fd7ba20ac8"
          }
        },
        "a2fc9d5d2a4e44c9b49d424992bab00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b48e4e0514d847be8118837ad4986b23",
            "placeholder": "​",
            "style": "IPY_MODEL_0bc24b20a2264709967772a4d5ce0690",
            "value": "Downloading model_O2.onnx: 100%"
          }
        },
        "a3a52d5fe3324b24b41984a39eda9981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca11caa2866c4498a183378a6d0e0b27",
            "placeholder": "​",
            "style": "IPY_MODEL_b427eb8ab5d04b46878ced6f9177f3c7",
            "value": "Downloading openvino_model.bin: 100%"
          }
        },
        "a3b98694916e49b79496261ff134143f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3cb55c1cfde4a06ba1b5bb3c0d8d1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac476d2812b64cff99e3d76ac5fc6af2",
            "placeholder": "​",
            "style": "IPY_MODEL_9f79bc6b949340f5b9a3a7d497613640",
            "value": "Downloading model_qint8_arm64.onnx: 100%"
          }
        },
        "a3ff196882fd428380198cfdba8a64d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41d777292a04015a59ba3688a49ed1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f495fcb342049f6a9cf3ddee0ca5f1e",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e9a447b6137474089e934a2fa8b8c4e",
            "value": 350
          }
        },
        "a46d13462af54b2fbbc7b6430e217f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_800abf389bd042c9bd37272f0580b858",
              "IPY_MODEL_bbee8de5f57b47cb82ed24d8ad29b97b",
              "IPY_MODEL_4bdb0bc3434643829cd63ca79b7f4bae"
            ],
            "layout": "IPY_MODEL_9d0788d7fdba4feaa23a2535ba1ff584"
          }
        },
        "a495ee526539484ebb2b85633617732a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed8219c9458b4cd6af50fbc3c4215385",
              "IPY_MODEL_47ae4f9641a449a8b7efb16a0a21fe2c",
              "IPY_MODEL_17a48ac52f8f4e02b7ea9ba90923f1b1"
            ],
            "layout": "IPY_MODEL_e105f9523c7c4e3eab8fae7b01d3fd83"
          }
        },
        "a4cc2a9d3f1c47d8bb9ac961ea25aaa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d48093f53244898b12f1790a268041": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f636e0348e4b4b87f4f454d994a8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a54ceeac73b2405683e2b141dd5d36ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eda247c525341e09534c201b76480a9",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c4f06774f94b038da571d3305e923c",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "a58eae67a18c418db1593eb933234681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c96d0ecee24e9dbd5ee8214130496d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a611633fb50d4a5cbc3bed1e2277cbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a62ecd41698f45d6bda57b260c3618e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7f004063c69475286230dd3b6b98553",
            "placeholder": "​",
            "style": "IPY_MODEL_89808fb12ce64361aad08870c7fb076b",
            "value": " 349/349 [00:00&lt;00:00, 33.6kB/s]"
          }
        },
        "a66ffd0b33ac4a86bdf7e854268ac420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a687862b7d694b9982b037b377be6a41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6fc099e97af4420abaecea8b7997c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6fc803b91b64208b71a91acad0d12d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a725cae7f2e44f5f90d525ddc791d39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a73edc477d4b47b7995b3afac43fcd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cab9909670e4163a52a63b7b9275be1",
            "placeholder": "​",
            "style": "IPY_MODEL_d6df8f42799e438a9fb18a29d5862a9a",
            "value": "Downloading shards: 100%"
          }
        },
        "a7d4fcb35ab6447685bc73f6ef67b66a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80afb8ae6ec4e4391d2e4858353494f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a82e3ac5189b450380ca453d179ae249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a82f857182724e48a22a7f5ac84ce5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0dce412e798474c9ea469ee08020ec5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06d930e8a1a54df4b826ce1826dfde28",
            "value": 1
          }
        },
        "a83c3f6fa11d460ca3d1352edcca5741": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e773cb0be4d7481b99f4bc1d806c2190",
              "IPY_MODEL_569e08a7b6644cf19fb076b504ad56d2",
              "IPY_MODEL_2e306f6e1a4d4564945f276c7a850f55"
            ],
            "layout": "IPY_MODEL_8d92e6bd9ab04c549b59851fab2d9920"
          }
        },
        "a846c2e7b4894fc28513117fc9fb5fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a87f5c4a298b4ae99616906459bcc1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66f8ed40e3dd4891bda18ecd6c3d70bf",
            "placeholder": "​",
            "style": "IPY_MODEL_4e0980ff295942b9bbed8a2405f0ac4c",
            "value": "Downloading tokenizer_config.json: "
          }
        },
        "a894fe12b637441cbc5c55a030e820a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aad7e2f72324820b71e06a431e446bf",
            "placeholder": "​",
            "style": "IPY_MODEL_6f5eb69733114c948a58a16ac56ebd1d",
            "value": " 90.4M/90.4M [00:00&lt;00:00, 184MB/s]"
          }
        },
        "a8d77cc90ae14019a41746fa75dd4d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aade0326d344d029813b5fe6f4fca3b",
            "placeholder": "​",
            "style": "IPY_MODEL_fbe093f574044ca5a9bb0d8bd9ac0351",
            "value": "Downloading tokenizer.json: "
          }
        },
        "a9258f1f32ed4d5a940950a6e697419d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92ef27afbdd4d2c88f8c68f7c1756e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73edc477d4b47b7995b3afac43fcd6c",
              "IPY_MODEL_58e94c3caf9f4f14b7d6d5838e033f96",
              "IPY_MODEL_96488210acde43e6a30928e94897e627"
            ],
            "layout": "IPY_MODEL_9e83d80b293a410f85fc6ce6a6c265c8"
          }
        },
        "a940e7d641354a1d95547634156ba97a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9466d9f27734435918899f945dc1658": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa1b85075c1842b0ad5242383b6f6304": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa5ecb2245ca478db0e04feeeed9adfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa6d829bb45043ed80c88f1f435caa99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa6eab96f8834474a25d2ae00f72423e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa899a4f5fc947ddbdf94ec1d16dcff2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab00268816b040d5b17b2f7727317f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80336a35e8b34d5ca43005314b7f8f0a",
            "placeholder": "​",
            "style": "IPY_MODEL_f0a93c75544841df8a44bbbb65308f09",
            "value": " 211k/? [00:00&lt;00:00, 15.9MB/s]"
          }
        },
        "ab07433386d54fe2a740aac852347aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab11a24aaa8d436eaae776d48ddb54c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_301e9194750b4bd99f25083e87e51da5",
              "IPY_MODEL_8194e30d81ec4cf6bd0de360a72ec9d5",
              "IPY_MODEL_25ef83e4e1674cca8c3ca32753936c25"
            ],
            "layout": "IPY_MODEL_47abc603bb49443181cbcade412d5e48"
          }
        },
        "ab6c1bb8c15441098750575fb3e9e37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42d9e893c83c436fb645002a2e8f7b03",
            "placeholder": "​",
            "style": "IPY_MODEL_8c9d86afca934fd298a224b812747f10",
            "value": " 22.9M/22.9M [00:00&lt;00:00, 250MB/s]"
          }
        },
        "abd76b7b03584a628469aaa052e93adf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac01bfa5e00c4cfb9381a221eaa00700": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6d2c86797b4144aa1d69451b4d1c35",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99d0d6d99a1d4a1196ee947a858b98b2",
            "value": 349
          }
        },
        "ac1efbae7d4d49799e363b49cf72828c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b96ad475f15422989be6b1af92974ef",
            "placeholder": "​",
            "style": "IPY_MODEL_9ec23ac822dd40bbbc87aba60d0765db",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "ac3d44713ac14ceeb9e5d85963f167df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eabc9dbc04304d3f8bc76ea7772fbfb9",
            "placeholder": "​",
            "style": "IPY_MODEL_f71064670bbb43d3b5307da8c9fcb556",
            "value": " 116/116 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "ac476d2812b64cff99e3d76ac5fc6af2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac757f21d8dd44bd9cdd3104ae5516ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac7cd1df41174ad799eeccef1429d6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac94e748b4104222a5ec37b37c3ae1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c2a4a5f52b54c1ca758090684f27af4",
              "IPY_MODEL_f2c0073c07254195841a5a54817b1711",
              "IPY_MODEL_2bfd8a5a43dc449a892717c256c6a688"
            ],
            "layout": "IPY_MODEL_e36b6fe3dea64db2bf4d6a1d457fea87"
          }
        },
        "acafcbf3322c4e9089b409168db06f57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb16da33e37436aa0558edd1773dc89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acb8d65a4e17487392e300d160ac2f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac1efbae7d4d49799e363b49cf72828c",
              "IPY_MODEL_79dd93f3e6824121a2996368413ce540",
              "IPY_MODEL_f9046efb742444a994c5085da40e9e82"
            ],
            "layout": "IPY_MODEL_fb0d14ec849441c6adef6bd20a9a0116"
          }
        },
        "acd91cc98a7c430eb0f700234cb6c6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a87f5c4a298b4ae99616906459bcc1dc",
              "IPY_MODEL_be075c3c2ac74e39b0067c1b1e420eaa",
              "IPY_MODEL_fea8133c8e5e4ebf8663b6cb8fd97c1e"
            ],
            "layout": "IPY_MODEL_e961068556c1445caaf44b31e997b5b8"
          }
        },
        "ad6f385ca6dc4c5a89036099202a43ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad7aa71e881b4cd8bc07301ead088a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adab5bd60804478789c48e6354155064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adc806811f7f46a3a5e7d5fd63aaad82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adfcf69075bd405f8ad95e2d6a3efb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae0f5fec869148cdafe90f2c221562c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae4cedd5a6e443158289ce796083d3ad",
            "placeholder": "​",
            "style": "IPY_MODEL_1edfac6eec2d4992b90134163f444dad",
            "value": "Downloading (…)of-00002.safetensors: 100%"
          }
        },
        "ae4cedd5a6e443158289ce796083d3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec5135b6af04f1cbd2d3d629967d279": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af13e5851d1d40a3a8d757fcb6558de8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3c4068fb5645199925ff390dd2921a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af41f782078f4bb39ec6c237fc4d5032": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af551d32608b494885650d16479ec4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c546d23e4e8248d2b7fae7063bb43c38",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90eee82806684434ab5afbe3f57388bd",
            "value": 2
          }
        },
        "af82c5fc79ad40e6972d33aa75f4d54a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283a54a4e1634b5ead12e07d527bf858",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dca7b3b217d04a33901475132fdd62c8",
            "value": 190
          }
        },
        "af99b92440a444b98319f553c0e3664c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc30b224e3744378b975796174a98c98",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc74fda7740d4c56a305da69b0814f72",
            "value": 2
          }
        },
        "afa02c3f82ad487d956662b9c9ac2094": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afc61d4881ae490ca23e43ad96cc984c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afdc7c5dc95b4b1a9b2135154ea9f9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7544e40cdbc487fa30047c35bc3cfbb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6998656c848b4e84b9a7c273e191c663",
            "value": 1
          }
        },
        "b0715facc91d46d4bd8425cb5e85f180": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0b50c76c34b49b48f938fbafe4ae6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0bd7e54d8d246c98d631f5921318056": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c3b18d932648488b9c741067de403d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c69a6eebe7664bc6b9ca484430258771",
            "placeholder": "​",
            "style": "IPY_MODEL_6b9b0f9078df43529c0a21bf0c336f9d",
            "value": "Downloading (…)fetensors.index.json: "
          }
        },
        "b0fc237cf73d41649aaad595caa77afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f606184b714e4637bdb7c2be84a99540",
            "placeholder": "​",
            "style": "IPY_MODEL_64853c976d0345a5a66ec8a615ff7cb6",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 207MB/s]"
          }
        },
        "b163ef7384eb4f95be00e7ec1a73b72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b0891462bab4cb3afbe36451372ea47",
            "placeholder": "​",
            "style": "IPY_MODEL_69d3c55274a24ada8ccc56b35b5e6c56",
            "value": "Downloading (…)_qint8_quantized.bin: 100%"
          }
        },
        "b1eb6b4938c84498814d5989141de7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5282d896f8247bdaeadc39b049387bb",
            "max": 90360328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adab5bd60804478789c48e6354155064",
            "value": 90360328
          }
        },
        "b24ccff458944c769f3068df383802f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d4098470dc04fe08c00bcbb057ee3bb",
              "IPY_MODEL_e20bfe354e8c44578ddeb47bd7437b15",
              "IPY_MODEL_7478600a44b9414e96bda1390664a8e1"
            ],
            "layout": "IPY_MODEL_52a0b3b4fa38441296fc2552d6edce3b"
          }
        },
        "b259069439724a43a22052563e503534": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c66b1721a44b82ac642d0484cb5b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c92180be0f439bb602f279b27f9fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e2e7f982e94087953e68244df6ca91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32709ad61b546ea973c61f877eec282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b36dcdd6783f465baeff85801392e250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3723a12e6554ec6ae9d3cfea1b79a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d4fcb35ab6447685bc73f6ef67b66a",
            "max": 9976701592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77adb0ec2a9841fe990d20d4e2ad9f69",
            "value": 9976701592
          }
        },
        "b3c4f06774f94b038da571d3305e923c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3d35c8a9dcd4d82a8f7be8913438d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274860a62ea742999b445a24adf37be4",
            "placeholder": "​",
            "style": "IPY_MODEL_60d24e1fd47c450f9300e9a276c3b24a",
            "value": " 190/190 [00:00&lt;00:00, 5.11kB/s]"
          }
        },
        "b427eb8ab5d04b46878ced6f9177f3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b42efad6f7384945b9f9d98bfbe9fb94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b48e4e0514d847be8118837ad4986b23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ef449386334628b503f62c1d6004e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0484abe01641433a9a37feaf38411d06",
            "placeholder": "​",
            "style": "IPY_MODEL_a58eae67a18c418db1593eb933234681",
            "value": " 500k/500k [00:00&lt;00:00, 45.8MB/s]"
          }
        },
        "b5361ebf7ac249c4b1842c0590550432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b546d194321743b9b118833a9f2e3f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b524a0dda74af4a3d03f93ecf28f55",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2965d4e4269944c081e4612aec0f129f",
            "value": 350
          }
        },
        "b562496342a242dba17bd5466500db01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b594224d1eab4284b6ff0c13d6ee3b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27fe06d3b83e4652abc4826521150498",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb5e265ef0f4304aa74be5da0cff5ab",
            "value": " 116/116 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "b5c4cf63366f42598e081be20a62bf4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b64530a7667148adb8c21f6c1b57135d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65a6cae7f924a9e9e49b76a62156472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b66de9ddfb5442048432e976a8aba8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6fbf4cb4b974065a1b89595e80e2593": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71eed38b31d42c1b79ff91be5038218": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72645b813ec4583adb4ee27e99a64de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f0f1ae6e4b4d4d94e91051b1c0ff3a",
            "placeholder": "​",
            "style": "IPY_MODEL_b5c4cf63366f42598e081be20a62bf4f",
            "value": "Downloading (…)nt8_avx512_vnni.onnx: 100%"
          }
        },
        "b72d45f7bf6a4a27a43982156255c912": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b74166f3dd3c44b3bc8be1961d97956a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7661b91ca9c4bdebf3e162d8ff82056": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e88840efb94b38a51ebbfe9a8c9df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_615a33c7c711486e804b177b217a34aa",
            "placeholder": "​",
            "style": "IPY_MODEL_e024a851ebf24c3e9d148e61172db385",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "b7eb58fce57f48d1baee600b80b64f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f004063c69475286230dd3b6b98553": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f2df11c1414ef0b3584f2d204db68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_408d5f76046846ab8cc8a597000544bd",
            "placeholder": "​",
            "style": "IPY_MODEL_adfcf69075bd405f8ad95e2d6a3efb93",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 308MB/s]"
          }
        },
        "b83a74572a58445f9c815e0894a82490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7959d64ee02843ae9f6a56daf8499c2b",
            "max": 90405214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_047b47e9c6b442ec821b6efbacc2b4b0",
            "value": 90405214
          }
        },
        "b867043fbae34d4da23ab9c35453b559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff395e16d9114575ab36ae6302f2b8d2",
            "placeholder": "​",
            "style": "IPY_MODEL_00e5fdeec82b4b99963329f0899ae511",
            "value": "Downloading tokenizer_config.json: "
          }
        },
        "b8b0066ab33a471d9019dfd2bf481006": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8dd59450c77480b917c0c886182f5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8f0cfa283ff41ee97677a8f803247aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9187c69f7034061bc034f475751349a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b91f97d687244e13b1c7021ef9ff0cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b972f97cb962438fad4e19065ec88b62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9801b6340234966a72feb10c92c870d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5b7bafe241b4cf281c2c503745462de",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89d745d00ff84f3fa59a24a2f0a424d1",
            "value": 612
          }
        },
        "b9819afe1b0246169b69dad9079b1323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9898a9ca5e6c4b74a304a5d5a9ee27b0",
              "IPY_MODEL_70d6e987d8f847b794cd082e67c59937",
              "IPY_MODEL_d577fb2eff974dc99b83199f1f6d27dd"
            ],
            "layout": "IPY_MODEL_af3c4068fb5645199925ff390dd2921a"
          }
        },
        "b994063c34354e1991314c955c5ea499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b6c6422b8d4fe684276a1c795241da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9da3a46b747406a9e91f127048b5f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a0b2edf2e2840959b709f6c4d3497da",
            "placeholder": "​",
            "style": "IPY_MODEL_78d37f7e23e7487ea1dcee7182f16b1e",
            "value": "Downloading config.json: 100%"
          }
        },
        "b9f09cbda5e64779b7058b09190c3840": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fc753799c541f2b36b8a3ca199d8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba09e40088314f3895ed5d987dab0fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba8a15a0fc11491bbaf03b9db11cfb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa44427116e4f789ef61f0aaeec76a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab05e9155c044e89de49aaf110dafd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_475b6d0583f541348b390af739467fc6",
              "IPY_MODEL_bd13367d418e4309b0e780557805de99",
              "IPY_MODEL_60f4cdaefc2d4f2eb469fa342953be7d"
            ],
            "layout": "IPY_MODEL_e8f7501307f846c58cfa9d81e9160319"
          }
        },
        "bb69bdf1234648aba639e442b0e97f98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bba243a5e6b54abab0ac3d164cd81ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbee8de5f57b47cb82ed24d8ad29b97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a992e81e2b54a729b637fb68ea26493",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68b20dfc91b249579b6b1a9407cea6d3",
            "value": 53
          }
        },
        "bbef7a3eba2f4b9da001ba9ed20d3fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc74fda7740d4c56a305da69b0814f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcd5db0f0cfc404a87bff2573e37c48d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd13367d418e4309b0e780557805de99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_392a7daa6776422aac143550f01422f6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfd20d3d06474742aa0bad6a2a5f22cd",
            "value": 2
          }
        },
        "bd8545261a93447d855d6c8dde545dad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be075c3c2ac74e39b0067c1b1e420eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81549c298b9f4ba8944adb13d80eb0b0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7706284d0064f6e92790faf75024309",
            "value": 1
          }
        },
        "be2cac4b1b4e4343ad0ee0fe88fd7fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec2bd773e4044cab9bd91186674a61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf26e383bfce47cb83724b91c1e4d515": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3a52d5fe3324b24b41984a39eda9981",
              "IPY_MODEL_0116f19ff33f43a28b1a52556fcc0574",
              "IPY_MODEL_836e9cadc9134dcb984085cf6f2aad89"
            ],
            "layout": "IPY_MODEL_69dc4490371d4b07bc46418a6df42559"
          }
        },
        "bf7d7fe25a2c455d89c4c9e3ac0409c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2f2d0b6ce86439294dfef13956577bc",
              "IPY_MODEL_5e4ceba4a07e4dafb7a2dc2acb778111",
              "IPY_MODEL_58c81480ec6649e2aa7bce960ae64c51"
            ],
            "layout": "IPY_MODEL_db8e8f5ac9cd4a1c81b0f72943ad2961"
          }
        },
        "bfd8ac804a0e4497b288e9f7d8d88b87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c010c51d57fa4c51982171c86c0dce6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c02c6e94284a485db756cd5e8c27b03d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b524a0dda74af4a3d03f93ecf28f55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b641a653ff4a05931049e62eac9ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c180f1d76ab44f5489282f878aea8551": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_335d74b3e67a4fa0839423332d9a3e00",
              "IPY_MODEL_87323ba357e3416aa83b710fc972f236",
              "IPY_MODEL_06471650c03440e7bb8701cde0971a6f"
            ],
            "layout": "IPY_MODEL_620e046c29d74b9ea554b47072d75307"
          }
        },
        "c1b06077292041d38d22b0878a1aa0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d7d150fde1478b9ad79256fed54874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c204dd2a307a4f14b83f78b566db76b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20bf4c0d22d4efdb52db1effe57f19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7739707832fe445490158d5f77578b61",
            "placeholder": "​",
            "style": "IPY_MODEL_fda702e3812240b59ccf56099fb4a91a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c22c4f099ac74ac69bf008afd04a79fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c233330728fa47fa85dd46c662a85da3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23683c2240940928d5eb7f79cd6331e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c261513358e142fab2aa9f320d1e0f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc61d4881ae490ca23e43ad96cc984c",
            "placeholder": "​",
            "style": "IPY_MODEL_ce65ecb03d2f46319d3701e179f4a8a4",
            "value": " 116/116 [00:00&lt;00:00, 3.58kB/s]"
          }
        },
        "c2bf393d922343f084f0d2f57da366e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f2d0b6ce86439294dfef13956577bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71d15a2a16d4db5b933ab2b3c49435b",
            "placeholder": "​",
            "style": "IPY_MODEL_263331e29a024113bb53ffb9d6237368",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "c316d87f5d3745489b4b52887f695a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89a1446c35ae422b8fcb095307d1145d",
              "IPY_MODEL_50efa3a93c474ce2b6d077f899b1bf2b",
              "IPY_MODEL_8d8b709b6cb847f7817ecdd3db63cae1"
            ],
            "layout": "IPY_MODEL_a4d48093f53244898b12f1790a268041"
          }
        },
        "c3293a821ec94b0f8650455b324aa3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c330b41a854c4df6a90787e24a2c65bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34aa8a147bd49549ec4cf632d5f8999": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c35647a002cf45609356d7114f20034f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c389fa85327b46ec90be8e750a9299df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f639c230d94740fc8ee1d6f3d08622c0",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f84880e2bf4501bea6e5f85a9f81cd",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 251MB/s]"
          }
        },
        "c38d850a979b4697967517f24b2c117c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9e7765331864ab1bfca3052b49ce653",
            "placeholder": "​",
            "style": "IPY_MODEL_e8c249f3c1e547ac97cc070dc8ba7090",
            "value": "Downloading model_O1.onnx: 100%"
          }
        },
        "c3a89fdea1374ca689e9edb88026ed48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dc4498e482f4e8fab1f860df6e89bbc",
            "placeholder": "​",
            "style": "IPY_MODEL_27ca669e00cd490d96938b1448013b17",
            "value": " 25.1k/? [00:00&lt;00:00, 1.73MB/s]"
          }
        },
        "c3ced9cf432d4e6cb76863a7b78b645f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c403e92163824be797b2f48fef526a56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46c7aee4e22458795a875cc4f55da3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c48635a6a24240e3a431653250119583": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c487976920ca48738e42459703e004b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b391e1e04e403ca092d7878eef200d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ae2eae1eb7e441fb55a54522b771a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_d64463f94bff419a95472d801b816e1f",
            "value": " 2/2 [03:14&lt;00:00, 88.00s/it]"
          }
        },
        "c4c0408926174b9ab668e8104dcf2c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4dc0bb1a1d44787813c62a579ef8245": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b0b6e16f8dc495baf746059b062b936",
            "placeholder": "​",
            "style": "IPY_MODEL_03a251947a3f4262b8df2d00e4a9bb36",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c4fc6d88e77c4a35b58e1f75629aee30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a846c2e7b4894fc28513117fc9fb5fe2",
            "placeholder": "​",
            "style": "IPY_MODEL_7ef8e967a56d41b0bed16f6be231d62e",
            "value": " 1.23k/? [00:00&lt;00:00, 139kB/s]"
          }
        },
        "c514798d2df14f35bb06fe4666152883": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54114fd45444bc28167e2b653113fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c546d23e4e8248d2b7fae7063bb43c38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c64928ad5908466db07d26da10b1eb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c65ea55165de4adea3939adae385acca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c677ac8c37cc4b16840063accfb8a1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c69a6eebe7664bc6b9ca484430258771": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a129e3dfd6454f9cad29dba89ce3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a2e62e55464d109ab15b59739945f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc01ba8433b94bc7ae9253c53976061d",
            "placeholder": "​",
            "style": "IPY_MODEL_3dad8eb5f7784207a9c371b7252cc820",
            "value": " 90.4M/90.4M [00:00&lt;00:00, 283MB/s]"
          }
        },
        "c7297a2a112c4669a4e6c0b4c09eadd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7706284d0064f6e92790faf75024309": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7a2cb6f2a9d4dda8f671720c86fa351": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b10637086547ef8df4a085e227c004": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c122c227e74d14b5df8905181a49a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf58af6ecd1f4b9fb2e1c16ef02f98dd",
            "placeholder": "​",
            "style": "IPY_MODEL_2a502de44af741df966ae3c4cc7a976d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c80eb443ffe84fdf956cf7fa5a79f426": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c822ced2a2da47c185e1608029b29837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a41fa3c7f2d47b78a55f27bc28e9b77",
              "IPY_MODEL_2302721590ad430db61287b394c99d34",
              "IPY_MODEL_f8002cd60614482aaf5262c3b5bfd2ae"
            ],
            "layout": "IPY_MODEL_aa5ecb2245ca478db0e04feeeed9adfc"
          }
        },
        "c87e04b1fab34a5da4dce96ac8595c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c8a97cf4fd0949f0bdc8c5f99bc1a814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8e0ce97446a44eca1b6f7bb7804187a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c91c7aace656455887bc8c056f49614d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd1a4b33dbab422a9a6cd5a5e4c7e50b",
            "max": 3500425616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70ffd8b2a7074d8ca285490054600a01",
            "value": 3500425616
          }
        },
        "c91fff0b12e941f59d69e7aa036ec410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9a08804863742ef897e7f995e22feed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdaf4f84ad1a410eb9810e6fd2ec0c2d",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7d59dd85f764e6aa69efb449e840448",
            "value": 90868376
          }
        },
        "c9b53c6c32494869bf41178640564d25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca11caa2866c4498a183378a6d0e0b27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8a5ab32fd94d6aba83ff7030986432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cadff53568fd416a8192f5fec395a154": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cafc9336a8eb4f04a714ef3b36bf9939": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb12941792314e729e8473a8d1242760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cf0cc7e92e04fe49d13d36a323621f1",
              "IPY_MODEL_787dde1d41714e559ef9e3788213347c",
              "IPY_MODEL_3a26af61f2914c19ba4e9b39b94520b4"
            ],
            "layout": "IPY_MODEL_73853d4b10334969baad4b5e8c86fec7"
          }
        },
        "cb157b8f41634e7cb2648b0e127ac1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb69c9024085477aa05b1235d991033f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425f901db1e643efafc71dbba2b5f4d3",
            "placeholder": "​",
            "style": "IPY_MODEL_7bba393b34594e45987eb6e909b28cc2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cb9a4ebd8c9c4348b8ce6085e314441d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e6d461c66a54869915bd23e6910ab4f",
            "placeholder": "​",
            "style": "IPY_MODEL_1e52ac27563c40dcb43700d28b14210d",
            "value": " 2/2 [00:49&lt;00:00, 49.37s/it]"
          }
        },
        "cbd68b865b9c45b0be066ec544d4609b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3e78e5639641ac924f6a914bb06c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a21702b8b0f14f6fa8aed65580d4b19e",
              "IPY_MODEL_999c34534fb84a34b038fb3ed5b164fd",
              "IPY_MODEL_d190374c6a334c57b9106b08ccbfbeb9"
            ],
            "layout": "IPY_MODEL_82243f048b364fd883616c1f5382ba6c"
          }
        },
        "cc40753724b644bebaefa73b4d8ed2c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc59958e762340638ed6dd165abacbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f622bbb32d324712b55f5ff913edc68e",
              "IPY_MODEL_9614fb1eb86644269802498db026a191",
              "IPY_MODEL_a0f261d9d7dc4696a3797b8f64450019"
            ],
            "layout": "IPY_MODEL_f909ddad8f204206ad830ebcb1b4cf3f"
          }
        },
        "cc9e5a059c4f4333b9045117d2aa586a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd1729fc4c1d43de83c1333dcb05c19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd1d41870d304e4c86904bcc27fd736d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e0a786891f949ae9162ae04944ec79e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb7d40b1f9ca44de9dcab34c916a688e",
            "value": 1
          }
        },
        "cd36f89ac1964d2faacacbcb4c46a1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd5ef7e1149e4276a5c835bb99f55859": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdaf4f84ad1a410eb9810e6fd2ec0c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdb2831ffedb4e10bdedc76e8ba790fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_725d5238593f4566bbf69d07f722a16e",
            "placeholder": "​",
            "style": "IPY_MODEL_acb16da33e37436aa0558edd1773dc89",
            "value": "Downloading model_qint8_arm64.onnx: 100%"
          }
        },
        "cdc2f962e5ff4cedb2f594221a8a01b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd34f895bc94b37b50e7869a0db0e21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0680c2d90f4d16bd652b877a0011f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2e3494632fe4516a68c03018765c4d1",
              "IPY_MODEL_497d5ef5243940aab69644d2fbd8b90e",
              "IPY_MODEL_84d8a2accea04fa28b53d94f103cbcca"
            ],
            "layout": "IPY_MODEL_88051db9debc47c7be8240ad62f9adc1"
          }
        },
        "ce2db56f31914f2ca3665deef27691a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7c0867cbe774034b864ca03ea36db43",
              "IPY_MODEL_df588496885341f99b8c6ef5d34d3615",
              "IPY_MODEL_b0fc237cf73d41649aaad595caa77afc"
            ],
            "layout": "IPY_MODEL_dfe165554d37431fb905c422795b0e7b"
          }
        },
        "ce65ecb03d2f46319d3701e179f4a8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce96546c950a491eb8be7c3bf0309f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb9821d6a3f4311991478dc34a65d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cebd3fdac18f4a548a21eff316080b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ced1d4ae254140b6a72f8daf74552443": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cefdd3039c4c4290843f7e00d1fb91b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf35f3e76f7a4e7ebb41836a58839a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf432bb484cc4615bcfa631fb6cd373d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf58af6ecd1f4b9fb2e1c16ef02f98dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb38ae65a0b4812941886d70ec0f7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0b4ac5597534572922a387927e9013f",
              "IPY_MODEL_ffd2c837561443868a86d81432f9390f",
              "IPY_MODEL_f6a1bd4ce3bf476cb136470450790323"
            ],
            "layout": "IPY_MODEL_792321100b9b417298c848279cfd45e4"
          }
        },
        "cfb9264dfd054211974c0b5990f59c62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd20d3d06474742aa0bad6a2a5f22cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d00172fa7bd240208a371488265339cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0247626449946978fba8feb81052ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45875b031b044710a0f7e9532033dc40",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bc37ed1cb53427dac681e7763fb9ffd",
            "value": 1
          }
        },
        "d03ebc36f32540538770715e7edc0828": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d050f8b75269494ab05df3641733eace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d073040d10694ed49276313135ab9d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08cc25135004577b893153308d46b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0b4ac5597534572922a387927e9013f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d5ff2dde3ea47c4b0048cb5c12f0747",
            "placeholder": "​",
            "style": "IPY_MODEL_e8a7af47229d41f685887d9f52ff18cb",
            "value": "Downloading tokenizer.json: "
          }
        },
        "d1203b7cf74a4fc7a06be100424cc85e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d126d69e537e42d08855da886c15fbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8523de1b618a4361ac5572df545f3c4b",
            "placeholder": "​",
            "style": "IPY_MODEL_ad6f385ca6dc4c5a89036099202a43ed",
            "value": " 90.3M/90.3M [00:00&lt;00:00, 278MB/s]"
          }
        },
        "d18ffd1a9cc74d25b07ecc02912c5bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d40c303db54b4581293bcaff35271e",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afa02c3f82ad487d956662b9c9ac2094",
            "value": 190
          }
        },
        "d190374c6a334c57b9106b08ccbfbeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a2cb6f2a9d4dda8f671720c86fa351",
            "placeholder": "​",
            "style": "IPY_MODEL_7b2c18055ca449bdbe55ecb6a6406f5b",
            "value": " 112/112 [00:00&lt;00:00, 9.09kB/s]"
          }
        },
        "d194a55ba688467da7a0db045be7305f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c8aad90ab74af49d39c089c7499977": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f52d48c620c4b4fa7632a76d59bd411",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12c7ae7fce274d63a2121fbf40685c37",
            "value": 1
          }
        },
        "d22f23e2f874440ebd266a28202a945a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2b3bf36a32b4d30bf7b077e28c9a974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d307bfcb2e6e4fce8cbaeaa688c84840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d355d433873d41c8bf25207f3de2f8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44d5b962a04148b88f7713caf23155dd",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41e5f287e49b48259e281aaf763b87e5",
            "value": 90868376
          }
        },
        "d398bdcf5b624bceb3aa0c54ad0060f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3baa763413a4b6eb90b0299af7d2b59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4394b606971409c8b7776feb3a3d311": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d481955f95a44e608caea9be11110255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb1728c560894de48f9825c6e014c0d8",
              "IPY_MODEL_b83a74572a58445f9c815e0894a82490",
              "IPY_MODEL_0d744344f71f4cb6868bf77a6d68d546"
            ],
            "layout": "IPY_MODEL_8345f09d1ca641f5b79ce585ee7e82ea"
          }
        },
        "d49fc935142b4bcaa849fa9836ce74c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4bdb1c3fa43458882821c2cc4b90fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d54fab8a2609469590715024d1fe7b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4185b71614e945dc8bf524b160bd10fa",
              "IPY_MODEL_e8bd356bdd604c40b98bbf420ab26264",
              "IPY_MODEL_27f7a761766a45bf88e5a4b5112fa4ae"
            ],
            "layout": "IPY_MODEL_1774b3b2a43a4e70a1472a6f982df625"
          }
        },
        "d55b4b7d46cf4e46a9d2acb6abf7173c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d577fb2eff974dc99b83199f1f6d27dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ad40b0874149de9170a31171bcfcc3",
            "placeholder": "​",
            "style": "IPY_MODEL_6a033c92fcfc4ffda669b8d2835dfae9",
            "value": " 368k/? [00:00&lt;00:00, 30.3MB/s]"
          }
        },
        "d578ec8a8ae7489ba440c81ed0b29fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5888a15e0a549c39235a4a271ecfaf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d592f659a3b94b688003f960f4ffe312": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b7bafe241b4cf281c2c503745462de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5efdac5590c4c038ca3c3e124d26244": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f2ac09302a4cf4b9f8c1b8a27ff553": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e390a4a7e9f444e80ce7f7bd8bfa7c5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a6f1cbcb4ff41908ee1b9558e5fabe8",
            "value": 1
          }
        },
        "d64463f94bff419a95472d801b816e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6765c0c71754f139e6ab99bf4f779b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d69185aff09d4f9aa1130547755a891f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69bba33938b4cd8b124f0cea77541b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6c6d351dfc547fab33a66ba75a5dfd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d25b83472a848e0904a1797698a0b1a",
            "placeholder": "​",
            "style": "IPY_MODEL_9daaba1833cf481c87f7f2fac4e96b13",
            "value": "Downloading train_script.py: "
          }
        },
        "d6da2ae12acd4c65b945db378c6f4930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6df8f42799e438a9fb18a29d5862a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6f45dacc2244384a12751f0e2615949": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6fbf61661f44b9087a15a8f7db47135": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71d15a2a16d4db5b933ab2b3c49435b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73589d0a22243debbc3950e59a9867b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d740506359ce402cabb61eb8a715bfac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7544e40cdbc487fa30047c35bc3cfbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d75b71fc416d4b14bf881ec2ea2f6625": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79d1c155aca49448eb59ca6f870a7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7b7a81ce3794c82b71f4a798c0ae94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7c0867cbe774034b864ca03ea36db43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc11e6e2d7ca45e89acf110a5e8b2b51",
            "placeholder": "​",
            "style": "IPY_MODEL_ea5dc8d06be042d99123fe29135cc458",
            "value": "Downloading (…)nt8_avx512_vnni.onnx: 100%"
          }
        },
        "d7edf2f104b84e17bfdb5453e8e18373": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d83b5420acb84b3388abd7a825582ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a1546d0afc4357a8aec090b5a9dd5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92bedbe2e4c48f489d4f1e021bd719a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d933a7a8163b405d91d1da63072034e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03efaf509a814ea6b634676272a4fddb",
              "IPY_MODEL_4eb8f3d5fb1b4c40be42dbe2bc676c34",
              "IPY_MODEL_6c95d19381154dc98d15787b1c7c580a"
            ],
            "layout": "IPY_MODEL_397966192433469181a6d41159a04c99"
          }
        },
        "d93a4635e0054cac8488f9b1dad79add": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ec98a177e27463f92e013a923ebd4b6",
            "placeholder": "​",
            "style": "IPY_MODEL_e19efdbd9fcf45dda16591f249650500",
            "value": "Downloading vocab.txt: "
          }
        },
        "d98fb0bb67754e71bd0c82f622cc33b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9af2c59e2cd4132be70c579cb4eb87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aae2bc1cd4540a69460ce54bb2fa63c",
            "placeholder": "​",
            "style": "IPY_MODEL_52b55f718b6d49a4b59b7ec10f31aa3e",
            "value": " 2/2 [01:07&lt;00:00, 30.93s/it]"
          }
        },
        "d9c8dfec2ce448cabcfff69a393e3b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e103bd5ce7a4a01a0cae9f49a6a24af",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a3618cd87a74dc6b8b791b9b6f324ba",
            "value": 1
          }
        },
        "da39fc9483cd4005b7645a43c1f601f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dac9a6d8f43643a9a57ae0408f9a9b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1296780d5e1438fbe28afdbfddf7a79",
            "placeholder": "​",
            "style": "IPY_MODEL_974f2422758f40749fdf082c77ab8a75",
            "value": "Downloading (…)of-00002.safetensors: 100%"
          }
        },
        "dafb046befc2424a9c6b3d18b002099c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db01ae3488b74fbf9e6b4abca0d3d59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87e04b1fab34a5da4dce96ac8595c1c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_291d9eba2f3b459ca7cf583b91092d0d",
            "value": 1
          }
        },
        "db2abfcec55f419ab058097ef6434bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db38d6004098448d94f6a02e3b59a670": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8e8f5ac9cd4a1c81b0f72943ad2961": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8fc5d08637491eb0a1862edc8cbc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc11e6e2d7ca45e89acf110a5e8b2b51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc139872f43647a0aa8cd5e6e38fdf3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc30b224e3744378b975796174a98c98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc4d8c42f42a4eeea9c870af30e34f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc853598552445ca8e4c19ad8ea1c3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c9992ed09774ed3a923d53447247c91",
              "IPY_MODEL_af99b92440a444b98319f553c0e3664c",
              "IPY_MODEL_e01a8f30104b4de391e3afe833ca812a"
            ],
            "layout": "IPY_MODEL_d740506359ce402cabb61eb8a715bfac"
          }
        },
        "dca7b3b217d04a33901475132fdd62c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcc1adfd3f2d4947ac7c16a67fc28048": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd1a4b33dbab422a9a6cd5a5e4c7e50b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd3d50a45047459cb65302a8d04887fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd8027cd897245818631e094e4ed8c80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb00c765dc2458bb8441f0076c2b6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de2f9f2cc0d149caa7063f4764ecf41d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de7514463b55423ca43a02f372efbf53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85704f23d84b4d658a7979c87c7f168f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faf5a994a28048468fca714783669e22",
            "value": 2
          }
        },
        "dec0127e01e54096b2c0b8395e990c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df1115454fbb4ba3a74a0960623d7e15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1b98b2ce36481a82ee632e05d1ba87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df3d02f826914a1ab61fc790de19a26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df588496885341f99b8c6ef5d34d3615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cadff53568fd416a8192f5fec395a154",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_066e6598660645378c3939d3d2841f18",
            "value": 23026053
          }
        },
        "df817a5f7c8f45d2929eebec6bcf26fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6b011f235b1414fae497d027989dde1",
            "placeholder": "​",
            "style": "IPY_MODEL_f2f0e483c1544876a9f96cf65f6382c2",
            "value": " 9.98G/9.98G [02:30&lt;00:00, 56.3MB/s]"
          }
        },
        "dfb2f9c743f14d368a67ca5784f53a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa6eab96f8834474a25d2ae00f72423e",
            "max": 90360328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51db87e88cba4a95a1bfe120d92c456a",
            "value": 90360328
          }
        },
        "dfe165554d37431fb905c422795b0e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01a8f30104b4de391e3afe833ca812a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfb9264dfd054211974c0b5990f59c62",
            "placeholder": "​",
            "style": "IPY_MODEL_99c3f6923d9343fca47e09071a81ba20",
            "value": " 2/2 [00:43&lt;00:00, 43.53s/it]"
          }
        },
        "e024a851ebf24c3e9d148e61172db385": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e03a6a9147c143f3877c49a25c5f02a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_599eb83f9de840f38691794cf66b19f5",
            "placeholder": "​",
            "style": "IPY_MODEL_7031ca0c7e0e42678d396db7122f91e8",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "e03ef2f0c4ee4ea58225df77c9773065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e3ce944d0ec4d37baaa70149be71723",
              "IPY_MODEL_d18ffd1a9cc74d25b07ecc02912c5bcf",
              "IPY_MODEL_6c782cfaeb7441a8b82df67121dc0cab"
            ],
            "layout": "IPY_MODEL_a9466d9f27734435918899f945dc1658"
          }
        },
        "e105f9523c7c4e3eab8fae7b01d3fd83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1150fffe081471783c7e103e1fc2031": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1296780d5e1438fbe28afdbfddf7a79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e19efdbd9fcf45dda16591f249650500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1b4036b291a4a3b9ad9f110ebf03946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1d02549eb704476b389b010b7dd082d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e20bfe354e8c44578ddeb47bd7437b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d4939a31c62489bb2e8f4111c101ae0",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e20b9f3b0584a16a803e9be32fba740",
            "value": 23026053
          }
        },
        "e22c18f263a448ef8f281273e350b50c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80eb443ffe84fdf956cf7fa5a79f426",
            "placeholder": "​",
            "style": "IPY_MODEL_26692debeb9c45d3899ab463f3054eff",
            "value": " 646/646 [00:00&lt;00:00, 76.7kB/s]"
          }
        },
        "e2494586f25e4d8f86258ee8345cd6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e26cc6e079ee402194a659075b5b44ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2aaa5cbcd494af3af90bb4b5c87acac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2cde23aa6134265a0986cebde88c68a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ce4a6220ad49c1811d39cc281c6ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e3494632fe4516a68c03018765c4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3200a71728314547a5abebfac664d358",
            "placeholder": "​",
            "style": "IPY_MODEL_5545aaeb70e5462baf4b5a28363eaf9a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e33bb200e8b142f0855e5dbd0c64a803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e36b6fe3dea64db2bf4d6a1d457fea87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37484d541a9469baba662016dbebb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c15ee18da4f46129a5831d7780273e2",
              "IPY_MODEL_58ec4a45101c49e4b8080f5402c0e96d",
              "IPY_MODEL_f3ae4f551c6a4d0db867741ce9974a5e"
            ],
            "layout": "IPY_MODEL_002e895d943f4b84a4c7e9d94cb41932"
          }
        },
        "e39c8fd1ba2848c3965d11e7b5716a56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e3c3fcfa2dd4426f9083a8e4060cd6ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f84880e2bf4501bea6e5f85a9f81cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e42864f0fe9f418e86c1b1e4ab804912": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e528d567434e4b3e91b31419d26bcee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f900545332374c6dbf6ed32d20804b99",
            "placeholder": "​",
            "style": "IPY_MODEL_168c22fcfcfc4cf984d95263553aa3a6",
            "value": " 1.23k/? [00:00&lt;00:00, 25.8kB/s]"
          }
        },
        "e5361e90811b4f94b498ca3ddc4a4614": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25593c1670284e09bc8dad7cc33ed3d1",
            "placeholder": "​",
            "style": "IPY_MODEL_2e2f278bdb2d49cb9cc7f9d45b8f38c9",
            "value": " 1.84M/? [00:00&lt;00:00, 59.0MB/s]"
          }
        },
        "e589f888e00d4b08b19ae0af71da25c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58aa02aba6e4cf593d24b09171a2507": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ce2131a15640ebbbebb59af50be5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5d0710b08744963b30911b07fede59f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e61cb74837d346339a3dac48c6b6ee33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5564c6ebca1f401da44da628e3467f6b",
            "placeholder": "​",
            "style": "IPY_MODEL_b9187c69f7034061bc034f475751349a",
            "value": " 10.5k/? [00:00&lt;00:00, 252kB/s]"
          }
        },
        "e65787c746d444a3bd83a76161cd4231": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e669c01427514e428e99cfcd8791d657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f1caa4f54f44f40b4b3033718629a05",
            "placeholder": "​",
            "style": "IPY_MODEL_9bf58fb4838148ef841e617234487182",
            "value": "Downloading train_script.py: "
          }
        },
        "e66a9ffb7faf4c1a8d8e51b2e73a8b26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e677ce983d624825907556fec239aeac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69ee0ea123143f18a60ab620703ffea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6a4d0c7c2c54b74be80002d81590e48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c71f3337434e0180dd02ed0ffd3f66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6fb8361ff5d401bb49d449872742502": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e70ee7e52dbd4e08b89a9c940e524906": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb69c9024085477aa05b1235d991033f",
              "IPY_MODEL_ea45b3e9d8ed403a849a23003686202b",
              "IPY_MODEL_1e69309b0bf14057a8674f92f3257500"
            ],
            "layout": "IPY_MODEL_df1115454fbb4ba3a74a0960623d7e15"
          }
        },
        "e70f60edda7f43c7adce2e16f9f46521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e747b944c0714a3ca8395e15dc9aacbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e773cb0be4d7481b99f4bc1d806c2190": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_890ef333e80140568fbaf6ddaf30f50d",
            "placeholder": "​",
            "style": "IPY_MODEL_3f7e107e2b1e474480989bdbde7e431b",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "e7ea7dfd8bbd4b4299d0d806c9e1059e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e878eb5c2afe4fab9f68af329e64bbad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8798fa091b54836b21c699de2b94caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e89117c5968244bb971f4edce7ffbc78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a7af47229d41f685887d9f52ff18cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8a88bdbbacf4095b91491ab4514af91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8bd356bdd604c40b98bbf420ab26264": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b259069439724a43a22052563e503534",
            "max": 646,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dc7025e871c4c1f85424896e6054015",
            "value": 646
          }
        },
        "e8c249f3c1e547ac97cc070dc8ba7090": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8efa08a51e34f4cb010e5dcc5ce1f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8f7501307f846c58cfa9d81e9160319": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f7e29cfcea4f558a56facdf7ba6b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e902067b2be445ebab16abbad4732a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd68b865b9c45b0be066ec544d4609b",
            "placeholder": "​",
            "style": "IPY_MODEL_a20276f34e05456fb077e47900d9e327",
            "value": " 190/190 [00:00&lt;00:00, 25.4kB/s]"
          }
        },
        "e90d58d8bd694acf840a4bef39d8f409": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e74a7d3fc8340d787d18341c7a0f6e8",
              "IPY_MODEL_069c3f345da6404b9b89a58c7ebef338",
              "IPY_MODEL_f18480a919f3499d8d757676e1c92f34"
            ],
            "layout": "IPY_MODEL_de2f9f2cc0d149caa7063f4764ecf41d"
          }
        },
        "e91a22164c9849fda3a5c801f87ed172": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92ae0b68b1f4793abe203769cbd212b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd50e03c6f9c4130a7a28e7f7a6189c5",
            "placeholder": "​",
            "style": "IPY_MODEL_02d83a14e1974a02933b6fb84b8fee10",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "e954bf7c16e043cfb611531b47a4cdd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e95e6163de9d4bd2af02f6e14140a648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e961068556c1445caaf44b31e997b5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e96f864d01cb4157b0ed9839be66df8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17976ebcf2e492c9d8346549c0d78a1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f148ffeb620e4b0f9386ad07a030a510",
            "value": 1
          }
        },
        "e99d9f2d829f4777966be8355c5e8296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9f0f1ae6e4b4d4d94e91051b1c0ff3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9fb77a2f2364045b89c39d25314210a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdd34f895bc94b37b50e7869a0db0e21",
            "placeholder": "​",
            "style": "IPY_MODEL_ec8516ddabe345dba6cfd280ee36e7cb",
            "value": " 368k/? [00:00&lt;00:00, 17.1MB/s]"
          }
        },
        "ea029b5137e84350ba46446599c515f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea45b3e9d8ed403a849a23003686202b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e89117c5968244bb971f4edce7ffbc78",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b9bb890b3d741369b4ca6890c289a1f",
            "value": 2
          }
        },
        "ea5dc8d06be042d99123fe29135cc458": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eabbc30930fa453ebdd9ab4cb0b706b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54fe6814eb7f48f591d3e1b2297a2365",
              "IPY_MODEL_549bad16e2414e5393280820e9890f68",
              "IPY_MODEL_6515798838c442d0a9525f933549ed9c"
            ],
            "layout": "IPY_MODEL_568bf7b486d447068a50c4f990d75249"
          }
        },
        "eabc9dbc04304d3f8bc76ea7772fbfb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaca4be07f1f40c3a8b60f82aec16d62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb4112735c3e4222828e401ace44730d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c4fe33b3d394774b95cacad4fafc474",
              "IPY_MODEL_7fb59f7d333f4ec88d444021b3534fd1",
              "IPY_MODEL_4ef56ac0025544a4aef80e3aac82aca1"
            ],
            "layout": "IPY_MODEL_b6fbf4cb4b974065a1b89595e80e2593"
          }
        },
        "eb6a8b7f7ea2414a9702698b5d952757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94146c327cce471b867c01e6607528a2",
            "placeholder": "​",
            "style": "IPY_MODEL_31f2a77ace8b4b2c9e4172e5553b1963",
            "value": " 116/116 [00:00&lt;00:00, 11.7kB/s]"
          }
        },
        "eb7d40b1f9ca44de9dcab34c916a688e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec5ec4e6c8904fcbbafcdf9dcc46db77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d84ceee84d9462699aa90d7d1a81eec",
            "placeholder": "​",
            "style": "IPY_MODEL_e8efa08a51e34f4cb010e5dcc5ce1f3c",
            "value": "Downloading (…)of-00002.safetensors: 100%"
          }
        },
        "ec6e53843fa3422f9174982083d53783": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d7d150fde1478b9ad79256fed54874",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c46c7aee4e22458795a875cc4f55da3a",
            "value": 2
          }
        },
        "ec8516ddabe345dba6cfd280ee36e7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec981e5dc68d4f38ae8557461d07076e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cca97c6ff0b4972beb76ac1e3ded196",
            "placeholder": "​",
            "style": "IPY_MODEL_cd1729fc4c1d43de83c1333dcb05c19f",
            "value": "Downloading model_O3.onnx: 100%"
          }
        },
        "ecaae07d704c4ce6a65003c1908dd9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d49fc935142b4bcaa849fa9836ce74c3",
            "max": 90326566,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a62588975df42c9978eb92d9100ac1d",
            "value": 90326566
          }
        },
        "ecc1c2eff0164a7fa60afc1825e871f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0385004be349ed950da812260f5f4c",
            "placeholder": "​",
            "style": "IPY_MODEL_e1d02549eb704476b389b010b7dd082d",
            "value": " 211k/? [00:00&lt;00:00, 13.3MB/s]"
          }
        },
        "ed37bfc8a4e64ea296ba8801ae0a2265": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed4bfa6a255246b295e81d71948603d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f5949efdf56409c8b0fab5da676ffb2",
            "placeholder": "​",
            "style": "IPY_MODEL_8bdebcdf79b5416ab353b4c7f66a21e8",
            "value": "Downloading openvino_model.bin: 100%"
          }
        },
        "ed8219c9458b4cd6af50fbc3c4215385": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_178eea154f394ef992eea375ce053ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_0a291b8e2e1245119542d93090b0023b",
            "value": "Downloading config.json: 100%"
          }
        },
        "edd3b6647ebd4f5f848e2dc037f8c3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b72bae7bcd45d19705a36d3ae0e50a",
            "placeholder": "​",
            "style": "IPY_MODEL_3a93149b9fc045aead269b10f96b6b57",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "edfa7f1f22444e2e87af496895974836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee2936eb2c494bc1843aaeca475d4fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f8085040cf84857af29218cabc52eea",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71d48b1031c340bb84e5aa14f183c4fe",
            "value": 2
          }
        },
        "ee4609a9e8f24d37b05613ffecbe81af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c233330728fa47fa85dd46c662a85da3",
            "placeholder": "​",
            "style": "IPY_MODEL_64301bcee191455eb109b4cc9fbe2aeb",
            "value": "Downloading tokenizer.json: "
          }
        },
        "ee6126e14e474bd0811f46fd7ba20ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee66aee457a94df09f79c82aad410448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_324518d0142b439db303e7390345422e",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e878eb5c2afe4fab9f68af329e64bbad",
            "value": 23026053
          }
        },
        "ef02eccba38b44d291b6aaddb154c31c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef0ced69039b4a22b6c7293b40f4abe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2953e4dbffcf4c359a301f0c20b7c9bd",
            "placeholder": "​",
            "style": "IPY_MODEL_66fae20cb5fe443bb3fc67f501b3a833",
            "value": "Downloading model.onnx: 100%"
          }
        },
        "ef0d5656fe2c4d08a228db5502e93af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acafcbf3322c4e9089b409168db06f57",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca8a5ab32fd94d6aba83ff7030986432",
            "value": 23026053
          }
        },
        "efb6a0b7346c403ba42a84d92a9d16e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38d8119e862d4642823b84553fc8ac67",
              "IPY_MODEL_d0247626449946978fba8feb81052ca6",
              "IPY_MODEL_66c475c2b5384bf7b573c65a2b58464f"
            ],
            "layout": "IPY_MODEL_a6fc099e97af4420abaecea8b7997c2e"
          }
        },
        "efb76c551bb14347b81f5ec94c9b3ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_930ae74d94ff4aa99652fed0ece2db5e",
            "placeholder": "​",
            "style": "IPY_MODEL_71eb8ad9448d438eba902551fd8c69ba",
            "value": " 349/349 [00:00&lt;00:00, 39.1kB/s]"
          }
        },
        "f0477415f78e4e3c9590deb5dd89e3a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0996c9bfc8c4ff8aee1731e4d8df14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66dbc1edfc2048d399462886420de59f",
            "placeholder": "​",
            "style": "IPY_MODEL_4329b9c9355143de9aefda5ff3442339",
            "value": "Downloading (…)_qint8_quantized.xml: "
          }
        },
        "f09e64f62669429cbf632fa07ebd59a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ddd082677ce42dd86ba5787af78c0f4",
              "IPY_MODEL_7c27afb10e294551a87faf613482960d",
              "IPY_MODEL_ac3d44713ac14ceeb9e5d85963f167df"
            ],
            "layout": "IPY_MODEL_797ed7936a92434ab666e9769804c14d"
          }
        },
        "f0a93c75544841df8a44bbbb65308f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0c95183354f406a937ec91baf47847c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0dce412e798474c9ea469ee08020ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f148ffeb620e4b0f9386ad07a030a510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f18372486ac14dd0a479706c27e64a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f54235a5d9b64a1b9855c37ae5d46e95",
              "IPY_MODEL_0da947241d4b48e9b87d7bc6bf1d6451",
              "IPY_MODEL_a62ecd41698f45d6bda57b260c3618e8"
            ],
            "layout": "IPY_MODEL_32d590a30b584e2daaf35aa41415c652"
          }
        },
        "f18480a919f3499d8d757676e1c92f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e9f9f10a8f74d7a8189db04779f3252",
            "placeholder": "​",
            "style": "IPY_MODEL_b32709ad61b546ea973c61f877eec282",
            "value": " 23.0M/23.0M [00:00&lt;00:00, 228MB/s]"
          }
        },
        "f210aafa99964807aac81d5c48834022": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2158488626d4208ac7ad75aa1e32287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2606f97087240dab23f994a553daafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f26c772aa920484c9183c7e8f844cdab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f27ad9ae80b6471383524788bf0e8eef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a5c5dc07474abcbdac1d451f27ef85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2c0073c07254195841a5a54817b1711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38412e3383a34014a9c4fdf2862fc58d",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_538c1a40cf694fec90c8030d41b909c4",
            "value": 23026053
          }
        },
        "f2c83afc96c040b5a06e32172fa5c619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2f0e483c1544876a9f96cf65f6382c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2fde1e327f643b3883769f744f2b80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3010c28daea47e9a3e1be7c0db0bc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec981e5dc68d4f38ae8557461d07076e",
              "IPY_MODEL_4b9c8a6cef124f5a97f6d383b0b722ab",
              "IPY_MODEL_d126d69e537e42d08855da886c15fbbc"
            ],
            "layout": "IPY_MODEL_cc40753724b644bebaefa73b4d8ed2c5"
          }
        },
        "f37d63649186471986697434d2d3472b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a3bb0e97594c74b5e6955f5a733fda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ae4f551c6a4d0db867741ce9974a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8614c733d1084fb5a9930834f7aa2ba2",
            "placeholder": "​",
            "style": "IPY_MODEL_0ee279a8b0ff469da74a9f3ab3f51a6e",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 284MB/s]"
          }
        },
        "f3afcaeed1874a54be7275b0e7d18806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d082ef4b8446809ad2235500d2bc64",
            "placeholder": "​",
            "style": "IPY_MODEL_ceb9821d6a3f4311991478dc34a65d69",
            "value": "Downloading openvino_model.xml: "
          }
        },
        "f3bbd5fdaf134ff2b927638250d380f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44f5689aa6443b7baf7592c7654e3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05629090422f41d0a5dd075dec2e6215",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7b7a81ce3794c82b71f4a798c0ae94e",
            "value": 1
          }
        },
        "f45c449f83c141d184163236ccb6c426": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfd8ac804a0e4497b288e9f7d8d88b87",
            "placeholder": "​",
            "style": "IPY_MODEL_ba8a15a0fc11491bbaf03b9db11cfb8f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f4ab92d24c5c4b39b43ed6800b053664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe955c6fbe3942eb92d34df78a0a340d",
              "IPY_MODEL_4ac93a96d1d649aa99c13ad6e2d3e230",
              "IPY_MODEL_e61cb74837d346339a3dac48c6b6ee33"
            ],
            "layout": "IPY_MODEL_f9fc54b202ff442ba96b1a38999e8f97"
          }
        },
        "f4ad40b0874149de9170a31171bcfcc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f505098deaf5434dba68eaa808166c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d8173c7650442890db6e84c810777d",
            "placeholder": "​",
            "style": "IPY_MODEL_399d5f1435d44853bcc8dcde38aa0da6",
            "value": " 350/350 [00:00&lt;00:00, 20.0kB/s]"
          }
        },
        "f51d94fe01ba47a08b9df8b64c3f0639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9721d6dfab9d42b8bff850e36961f22b",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e747b944c0714a3ca8395e15dc9aacbc",
            "value": 112
          }
        },
        "f5282d896f8247bdaeadc39b049387bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f54235a5d9b64a1b9855c37ae5d46e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_834809a1a8934fb0a4a3480329f96099",
            "placeholder": "​",
            "style": "IPY_MODEL_9543f9fbdcc34a64b177a601021d9299",
            "value": "Downloading modules.json: 100%"
          }
        },
        "f606184b714e4637bdb7c2be84a99540": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f622bbb32d324712b55f5ff913edc68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafb046befc2424a9c6b3d18b002099c",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea11c066c454c3f9e3dc145cd1db969",
            "value": "Downloading model_O2.onnx: 100%"
          }
        },
        "f639c230d94740fc8ee1d6f3d08622c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6491464b46f4f9f97b3dd5288854ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4502ca6ea067426ea288506ee093532e",
            "placeholder": "​",
            "style": "IPY_MODEL_7247ffd7d7d740eaabca5d82df0eb122",
            "value": " 2/2 [01:09&lt;00:00, 32.05s/it]"
          }
        },
        "f6550dd8d904418ab042151090738a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f69e6f06ff1c4bbcb4909b33b7558a11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a1bd4ce3bf476cb136470450790323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19c13990e4e94a5e811d33d23083bec8",
            "placeholder": "​",
            "style": "IPY_MODEL_1e1c2210876045f9a157535f430e77a8",
            "value": " 466k/? [00:00&lt;00:00, 20.8MB/s]"
          }
        },
        "f6b011f235b1414fae497d027989dde1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6cdc9172f80400dab1d7074738caeb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e869838c304085a4623f3f741b0f09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f71064670bbb43d3b5307da8c9fcb556": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f71de2b3646f430387d83ad4acd926fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7d59dd85f764e6aa69efb449e840448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7fea2b9f789438abf0cba04637af9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb4f3b1aac94eb187dd0d8986b3205c",
            "placeholder": "​",
            "style": "IPY_MODEL_4f130b3ab9744cff92875c199639eb65",
            "value": "Downloading config.json: 100%"
          }
        },
        "f8002cd60614482aaf5262c3b5bfd2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e281b1dff5e4afc86717302642dbf31",
            "placeholder": "​",
            "style": "IPY_MODEL_f916f359870d421bb289c16ba4942046",
            "value": " 1.84M/? [00:00&lt;00:00, 64.6MB/s]"
          }
        },
        "f80638e09b3a4e41b1c5bf558c6b84be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f828856d2f184015b2c122a481a3a052": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f842684899af42a887557e16f9fe1869": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f872e5c7ad4d445ca465d7543e367d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_029a42a215fe405796154508c1e59dbb",
              "IPY_MODEL_dfb2f9c743f14d368a67ca5784f53a2e",
              "IPY_MODEL_635da505b3784c0cbbb757b39e230189"
            ],
            "layout": "IPY_MODEL_ff4d1cdd581c4452a946e4cdaf5c4967"
          }
        },
        "f89c633efea047e78e49031e6c55b694": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c11d9d21d44ac19dfe03b1752648c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f900545332374c6dbf6ed32d20804b99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9046efb742444a994c5085da40e9e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc5b70a7bf8441fbcab42d464ce5113",
            "placeholder": "​",
            "style": "IPY_MODEL_196429f9ea73463cb22321b827fef7dc",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 292MB/s]"
          }
        },
        "f909ddad8f204206ad830ebcb1b4cf3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f916f359870d421bb289c16ba4942046": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f93f7ba8f13c45ea86aaaa612af608c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cf11fc63374447ca783b50233eec628",
            "max": 23026053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55ed30864aff43249eb5f91861c4ec09",
            "value": 23026053
          }
        },
        "f949115e02674a5b9b2b42ba117bc00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ef8a823951486fbfab571c64ad8a8c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_511d824e50b64f1f947f0c8536487f04",
            "value": 1
          }
        },
        "f9924518b6c643408a9159985440101e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99a3c23e6ac4cae93429d10c5d25eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ed2f0de1e644e97bddd2b7db30b18bd",
              "IPY_MODEL_24daf4fe0ee24a86bcf2bbe0bcd2b11f",
              "IPY_MODEL_9d9c2bc1c0b24981ae21b26a7a27f14f"
            ],
            "layout": "IPY_MODEL_e3c3fcfa2dd4426f9083a8e4060cd6ca"
          }
        },
        "f9af9d703e0a4f40b18ddb32c8cb1e64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9e7765331864ab1bfca3052b49ce653": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9fb38eb00d8499693cbc0b172855704": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9fc54b202ff442ba96b1a38999e8f97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ff5711fcc147e497231ab3fbaaff05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa3d4b8ebdef4d38aad4807306fb0d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa5c95af95434f689ab197e9948822da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0477415f78e4e3c9590deb5dd89e3a3",
            "max": 90405214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46e51e03792d4b7cbb6300bbb3ab83f6",
            "value": 90405214
          }
        },
        "faf5a994a28048468fca714783669e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb0d14ec849441c6adef6bd20a9a0116": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb1728c560894de48f9825c6e014c0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3d50a45047459cb65302a8d04887fd",
            "placeholder": "​",
            "style": "IPY_MODEL_253d80ccde82413abee06a8b90297089",
            "value": "Downloading model.onnx: 100%"
          }
        },
        "fb3d29e8735e477b943de9e85de59843": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4b3045806446cd94141b5336d62bda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb756bfcd778451a885d7decd0712c97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbce8382bb5d46f19f883f815a7c69dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62e6758384644f00bc16a3f273a03caa",
              "IPY_MODEL_00b4cf8b2b15482fbd606df261893e92",
              "IPY_MODEL_4efabe35061a4d31bb5b7bf6aa5acfaf"
            ],
            "layout": "IPY_MODEL_9075b3075fe8428f9a5c89336c291127"
          }
        },
        "fbe093f574044ca5a9bb0d8bd9ac0351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbe5120d4dbf4b06987dc72e3be30536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc01ba8433b94bc7ae9253c53976061d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc458d5904fc419eb7e95c8cee17f455": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb5e265ef0f4304aa74be5da0cff5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd50e03c6f9c4130a7a28e7f7a6189c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd88aa6c3b124896a02624637ab35161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda702e3812240b59ccf56099fb4a91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdadd988c345471b9328e946052c7050": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde3235287d542ccaf3088af8bf78950": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0b23b3c21d4950a0e8df9ac6731d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe10aa0808b74b2297d5c23606bf4676": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe2376c54fda4d3d82cf734065a21af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d54cd329f85444ea5d07af27e3bdb3b",
              "IPY_MODEL_703c3090a3174febbc3007a0d1ee8139",
              "IPY_MODEL_890af1b470284e3bab45e041978a86e4"
            ],
            "layout": "IPY_MODEL_dc4d8c42f42a4eeea9c870af30e34f6b"
          }
        },
        "fe41ec0ba2c744cda207131bff468694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe955c6fbe3942eb92d34df78a0a340d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6f45dacc2244384a12751f0e2615949",
            "placeholder": "​",
            "style": "IPY_MODEL_5cdf714ed91049f58f1ad4ea57608469",
            "value": "Downloading README.md: "
          }
        },
        "fea8133c8e5e4ebf8663b6cb8fd97c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79085e7e53984825a78d6ae75ec59672",
            "placeholder": "​",
            "style": "IPY_MODEL_edfa7f1f22444e2e87af496895974836",
            "value": " 1.59k/? [00:00&lt;00:00, 162kB/s]"
          }
        },
        "fec9edad0dcc4d4d80ed16e51e514bab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff395e16d9114575ab36ae6302f2b8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff4d1cdd581c4452a946e4cdaf5c4967": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb0a8a71c3749b2abc3fbafeb67ac8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17db3b8f5db9446684bf2cc5d65f0fbe",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8f7e29cfcea4f558a56facdf7ba6b72",
            "value": 2
          }
        },
        "ffc31f20dffd4fe184dff35cc1b93145": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffd2c837561443868a86d81432f9390f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50af68f3ea14412e96fbb59d9a565156",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9fc753799c541f2b36b8a3ca199d8ff",
            "value": 1
          }
        },
        "fffd1b1b97564479a3600e524ed97e90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a229a76bf2d490582ff9baee316b499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0bdfb4308e9473aa258d5f07b73be87",
              "IPY_MODEL_0164bb488a2f4159a858e8836d6dbc9f",
              "IPY_MODEL_21171de6dc1c499e940e2eef93ca9ef4"
            ],
            "layout": "IPY_MODEL_d76f124f54a949508f0d32c68ca58946"
          }
        },
        "f0bdfb4308e9473aa258d5f07b73be87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1181f9e2492d4d30888bb6371cbe9d18",
            "placeholder": "​",
            "style": "IPY_MODEL_099ccb8649e343859886ef3f1ba6cfdf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0164bb488a2f4159a858e8836d6dbc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd6dc7187dee424d817ef2fde4d155db",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb1bf262d0fb4954bf3c3b055989e026",
            "value": 2
          }
        },
        "21171de6dc1c499e940e2eef93ca9ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaf4f9b016604bd88da609cd40708b94",
            "placeholder": "​",
            "style": "IPY_MODEL_f74bdfb6030449649988316dd8fcfa80",
            "value": " 2/2 [00:59&lt;00:00, 27.46s/it]"
          }
        },
        "d76f124f54a949508f0d32c68ca58946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1181f9e2492d4d30888bb6371cbe9d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "099ccb8649e343859886ef3f1ba6cfdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6dc7187dee424d817ef2fde4d155db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb1bf262d0fb4954bf3c3b055989e026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaf4f9b016604bd88da609cd40708b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74bdfb6030449649988316dd8fcfa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90fd5ff9934946f580366c33cc32b8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_384bb512dcf84618a98d14764a390ba8",
              "IPY_MODEL_0f020033709e44549f912a249a6b52da",
              "IPY_MODEL_428974ef9b1748bcbadf634c8d23a253"
            ],
            "layout": "IPY_MODEL_f44a3bee8a8243bba40db74975986fc1"
          }
        },
        "384bb512dcf84618a98d14764a390ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786a158f3d58411e868954e98dc8f7ab",
            "placeholder": "​",
            "style": "IPY_MODEL_23ab49b129fb4d8e9b57923bb09c9669",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0f020033709e44549f912a249a6b52da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab02e6b745342c7802d8549d8f222f1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4acf8832e0f6494394f2af3b4f3bce58",
            "value": 2
          }
        },
        "428974ef9b1748bcbadf634c8d23a253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27170cf1aadd495a9e4d138b25978337",
            "placeholder": "​",
            "style": "IPY_MODEL_2204485f8d244817990180e6b157bf2b",
            "value": " 2/2 [01:10&lt;00:00, 31.91s/it]"
          }
        },
        "f44a3bee8a8243bba40db74975986fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786a158f3d58411e868954e98dc8f7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ab49b129fb4d8e9b57923bb09c9669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ab02e6b745342c7802d8549d8f222f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4acf8832e0f6494394f2af3b4f3bce58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27170cf1aadd495a9e4d138b25978337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2204485f8d244817990180e6b157bf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "015f311773fb4a09b40d46677f764c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_012bafda3cbe45bc83a47c6ca01a6b81",
              "IPY_MODEL_1f01111afce84d82a65dccf4b2ba5fa0",
              "IPY_MODEL_c86dde567c304a4eaa36b35df8af0fde"
            ],
            "layout": "IPY_MODEL_1f3bc8d7e72e43df881889c634ee4bfe"
          }
        },
        "012bafda3cbe45bc83a47c6ca01a6b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a375caa353e468a891f41e2abc3adab",
            "placeholder": "​",
            "style": "IPY_MODEL_e7535dc2e43e47f894d96ad56b9eac18",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1f01111afce84d82a65dccf4b2ba5fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610a7bae572c4e5f80eec672ac862792",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41c6ced0159f42aaa1967bea5eb7237c",
            "value": 2
          }
        },
        "c86dde567c304a4eaa36b35df8af0fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a05056fd57745488691556fcba5e2cb",
            "placeholder": "​",
            "style": "IPY_MODEL_fa5f4804912e4320bca4de46c0404cf1",
            "value": " 2/2 [01:00&lt;00:00, 27.95s/it]"
          }
        },
        "1f3bc8d7e72e43df881889c634ee4bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a375caa353e468a891f41e2abc3adab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7535dc2e43e47f894d96ad56b9eac18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "610a7bae572c4e5f80eec672ac862792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c6ced0159f42aaa1967bea5eb7237c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a05056fd57745488691556fcba5e2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5f4804912e4320bca4de46c0404cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}